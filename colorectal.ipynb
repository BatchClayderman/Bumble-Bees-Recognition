{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('01_PositiveID', '02_NegativeID', '03_Unverified', '04_Unprocessed')\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "rootPath = os.getcwd()+ os.sep\n",
    "if os.path.exists(\"data\"): # automatically recognize\n",
    "    rootPath += \"data\" + os.sep\n",
    "elif os.path.exists(\"dataset\"):\n",
    "    rootPath += \"dataset\" + os.sep\n",
    "else:\n",
    "    rootPath += input(\"Relative Folder: \").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").replace(os.sep, \"\") + os.sep\n",
    "#for dirname, _, filenames in os.walk(rootPath):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "classes = []\n",
    "for i in os.listdir(rootPath):\n",
    "    if os.path.isdir(rootPath + i) and not i.startswith(\"#\"):\n",
    "        classes.append(i)\n",
    "    assert(i.lower() != \".ipynb_checkpoints\")\n",
    "classes = tuple(classes)\n",
    "print(classes)\n",
    "class_count = len(classes)\n",
    "assert(class_count > 0)\n",
    "useNet = 50\n",
    "plt_color = \"green\"\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#['resnet18', 'resnet34'， 'resnet50'， 'resnet101', 'resnet152']\n",
    "if useNet == 18:\n",
    "    from torchvision.models.resnet import resnet18\n",
    "    resnet = resnet18(pretrained = True)\n",
    "elif useNet == 34:\n",
    "    from torchvision.models.resnet import resnet34\n",
    "    resnet = resnet34(pretrained = True)\n",
    "elif useNet == 50:\n",
    "    from torchvision.models.resnet import resnet50\n",
    "    resnet = resnet50(pretrained = True)\n",
    "elif useNet == 101:\n",
    "    from torchvision.models.resnet import resnet101\n",
    "    resnet = resnet101(pretrained = True)\n",
    "elif useNet == 152:\n",
    "    from torchvision.models.resnet import resnet152\n",
    "    resnet = resnet152(pretrained = True)\n",
    "else:\n",
    "    raise ModuleNotFoundError\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import *\n",
    "import torchvision.transforms as transforms\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import  SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing of data set and training set\n",
    "if useNet == 18 or useNet == 34:\n",
    "    PIL_transform = transforms.RandomApply([transforms.RandomHorizontalFlip(p = 1), transforms.RandomVerticalFlip(p = 1),\\\n",
    "        transforms.RandomRotation(45)], p = 0.5)\n",
    "elif useNet == 50 or useNet == 101 or useNet == 152:\n",
    "    PIL_transform = transforms.RandomApply([transforms.RandomHorizontalFlip(p = 1), transforms.RandomVerticalFlip(p = 1),\\\n",
    "        transforms.RandomRotation(45)], p = 0.4)\n",
    "else:\n",
    "    raise ModuleNotFoundError\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # resize to 256x256\n",
    "    PIL_transform,\n",
    "    transforms.RandomCrop((225, 225)),  # randomly cut to 224x224\n",
    "    #transforms.RandomHorizontalFlip(),  # flip horizontally\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.2225))  # Normalization, the value is given by Imagenet\n",
    "])\n",
    " \n",
    "# Processing of data set verification set\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    " \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU is better than CPU\n",
    "cell_dataset = datasets.ImageFolder(root = rootPath, transform = transform_train)\n",
    "\n",
    "#define dataloader\n",
    "dataset_loader = DataLoader(cell_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n",
    "\n",
    "split1 = int(0.1 * len(cell_dataset))\n",
    "split2 = int(0.9 * len(cell_dataset))\n",
    "index_list = list(range(len(cell_dataset)))\n",
    "np.random.shuffle(index_list) \n",
    "test_idx = index_list[:split1] + index_list[split2:]\n",
    "train_idx = index_list[split1:split2]\n",
    "\n",
    "## create training and validation sampler objects\n",
    "tr_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(test_idx)\n",
    "#trainset=cell_dataset[split1:split2]\n",
    "\n",
    "## create iterator objects for train and valid datasets\n",
    "trainloader = DataLoader(cell_dataset, batch_size = 16, sampler = tr_sampler,num_workers = 4)\n",
    "validloader = DataLoader(cell_dataset, batch_size = 16, sampler = val_sampler,num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().item()\n",
    "    return num_correct / total\n",
    " \n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    #scheduler.step()\n",
    "    model.train()\n",
    "    train_acc = 0.0\n",
    "    for batch_idx, (img, label) in enumerate(trainloader):\n",
    "        image = img.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        out = model(image)\n",
    "        #print('out:{}'.format(out))\n",
    "        #print(out.shape)\n",
    "        #print('label:{}'.format(label))\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        train_acc = get_acc(out, label)\n",
    "        print(\"Epoch:%d [%d|%d] loss:%f acc:%f\" % (epoch, batch_idx, len(trainloader), loss.mean(), train_acc))\n",
    "    scheduler.step()\n",
    " \n",
    " \n",
    "def val(epoch):\n",
    "    print(\"\\nValidation Epoch: %d\" % epoch)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img, label) in enumerate(validloader):\n",
    "            image = img.to(device)\n",
    "            label = label.to(device)\n",
    "            out = model(image)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += image.size(0)\n",
    "            correct += predicted.data.eq(label.data).cpu().sum()\n",
    "    print(\"Acc: %f \" % ((1.0 * correct.numpy()) / total))\n",
    "    return (1.0 * correct.numpy()) / total\n",
    " \n",
    " \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 5, stride = 2, padding = 2, bias = False)\n",
    "        self.resnet_layer = nn.Sequential(*list(model.children())[1:-1])# Remove the last layer of the model\n",
    "        if useNet == 18 or useNet == 34:\n",
    "            self.Linear_layer = nn.Linear(512, 8) # Add a full connection layer with modified parameters\n",
    "        elif useNet == 50 or useNet == 101 or useNet == 152:\n",
    "            self.Linear_layer = nn.Linear(2048, 32) # Add a full connection layer with modified parameters\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.resnet_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.Linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Epoch:0 [0|160] loss:4.137541 acc:0.000000\n",
      "Epoch:0 [1|160] loss:3.889085 acc:0.000000\n",
      "Epoch:0 [2|160] loss:3.674046 acc:0.000000\n",
      "Epoch:0 [3|160] loss:3.458415 acc:0.000000\n",
      "Epoch:0 [4|160] loss:3.234106 acc:0.062500\n",
      "Epoch:0 [5|160] loss:3.022512 acc:0.312500\n",
      "Epoch:0 [6|160] loss:2.787782 acc:0.687500\n",
      "Epoch:0 [7|160] loss:2.564481 acc:0.750000\n",
      "Epoch:0 [8|160] loss:2.294174 acc:0.875000\n",
      "Epoch:0 [9|160] loss:2.120922 acc:0.937500\n",
      "Epoch:0 [10|160] loss:1.936488 acc:0.937500\n",
      "Epoch:0 [11|160] loss:1.844241 acc:0.875000\n",
      "Epoch:0 [12|160] loss:1.446784 acc:1.000000\n",
      "Epoch:0 [13|160] loss:1.248541 acc:1.000000\n",
      "Epoch:0 [14|160] loss:1.309708 acc:0.875000\n",
      "Epoch:0 [15|160] loss:0.853637 acc:0.937500\n",
      "Epoch:0 [16|160] loss:0.669588 acc:1.000000\n",
      "Epoch:0 [17|160] loss:0.545931 acc:1.000000\n",
      "Epoch:0 [18|160] loss:0.469861 acc:1.000000\n",
      "Epoch:0 [19|160] loss:0.389025 acc:1.000000\n",
      "Epoch:0 [20|160] loss:0.329013 acc:1.000000\n",
      "Epoch:0 [21|160] loss:0.520338 acc:0.937500\n",
      "Epoch:0 [22|160] loss:0.211052 acc:1.000000\n",
      "Epoch:0 [23|160] loss:0.182002 acc:1.000000\n",
      "Epoch:0 [24|160] loss:0.143475 acc:1.000000\n",
      "Epoch:0 [25|160] loss:0.113574 acc:1.000000\n",
      "Epoch:0 [26|160] loss:0.097697 acc:1.000000\n",
      "Epoch:0 [27|160] loss:0.384750 acc:0.937500\n",
      "Epoch:0 [28|160] loss:0.502265 acc:0.937500\n",
      "Epoch:0 [29|160] loss:0.080223 acc:1.000000\n",
      "Epoch:0 [30|160] loss:0.070631 acc:1.000000\n",
      "Epoch:0 [31|160] loss:0.515337 acc:0.937500\n",
      "Epoch:0 [32|160] loss:0.435131 acc:0.937500\n",
      "Epoch:0 [33|160] loss:0.405103 acc:0.937500\n",
      "Epoch:0 [34|160] loss:0.053715 acc:1.000000\n",
      "Epoch:0 [35|160] loss:0.390349 acc:0.937500\n",
      "Epoch:0 [36|160] loss:0.367026 acc:0.937500\n",
      "Epoch:0 [37|160] loss:0.046651 acc:1.000000\n",
      "Epoch:0 [38|160] loss:0.045394 acc:1.000000\n",
      "Epoch:0 [39|160] loss:0.053600 acc:1.000000\n",
      "Epoch:0 [40|160] loss:0.052060 acc:1.000000\n",
      "Epoch:0 [41|160] loss:0.045041 acc:1.000000\n",
      "Epoch:0 [42|160] loss:0.430020 acc:0.937500\n",
      "Epoch:0 [43|160] loss:0.359067 acc:0.937500\n",
      "Epoch:0 [44|160] loss:0.042468 acc:1.000000\n",
      "Epoch:0 [45|160] loss:0.769423 acc:0.875000\n",
      "Epoch:0 [46|160] loss:0.031637 acc:1.000000\n",
      "Epoch:0 [47|160] loss:0.046787 acc:1.000000\n",
      "Epoch:0 [48|160] loss:0.033381 acc:1.000000\n",
      "Epoch:0 [49|160] loss:0.040882 acc:1.000000\n",
      "Epoch:0 [50|160] loss:0.315619 acc:0.937500\n",
      "Epoch:0 [51|160] loss:0.036836 acc:1.000000\n",
      "Epoch:0 [52|160] loss:0.033330 acc:1.000000\n",
      "Epoch:0 [53|160] loss:0.033033 acc:1.000000\n",
      "Epoch:0 [54|160] loss:0.037831 acc:1.000000\n",
      "Epoch:0 [55|160] loss:0.038851 acc:1.000000\n",
      "Epoch:0 [56|160] loss:0.242780 acc:0.937500\n",
      "Epoch:0 [57|160] loss:0.369628 acc:0.937500\n",
      "Epoch:0 [58|160] loss:0.880587 acc:0.875000\n",
      "Epoch:0 [59|160] loss:0.455168 acc:0.937500\n",
      "Epoch:0 [60|160] loss:0.201083 acc:0.937500\n",
      "Epoch:0 [61|160] loss:0.393941 acc:0.937500\n",
      "Epoch:0 [62|160] loss:0.536944 acc:0.937500\n",
      "Epoch:0 [63|160] loss:0.448062 acc:0.937500\n",
      "Epoch:0 [64|160] loss:0.317350 acc:0.937500\n",
      "Epoch:0 [65|160] loss:0.415004 acc:0.937500\n",
      "Epoch:0 [66|160] loss:0.439701 acc:0.937500\n",
      "Epoch:0 [67|160] loss:0.057415 acc:1.000000\n",
      "Epoch:0 [68|160] loss:0.287388 acc:0.937500\n",
      "Epoch:0 [69|160] loss:0.329425 acc:0.937500\n",
      "Epoch:0 [70|160] loss:0.059808 acc:1.000000\n",
      "Epoch:0 [71|160] loss:0.081731 acc:1.000000\n",
      "Epoch:0 [72|160] loss:0.309057 acc:0.937500\n",
      "Epoch:0 [73|160] loss:0.357758 acc:0.937500\n",
      "Epoch:0 [74|160] loss:0.296468 acc:0.937500\n",
      "Epoch:0 [75|160] loss:0.478101 acc:0.937500\n",
      "Epoch:0 [76|160] loss:0.054501 acc:1.000000\n",
      "Epoch:0 [77|160] loss:0.051576 acc:1.000000\n",
      "Epoch:0 [78|160] loss:0.055014 acc:1.000000\n",
      "Epoch:0 [79|160] loss:0.377043 acc:0.937500\n",
      "Epoch:0 [80|160] loss:0.056159 acc:1.000000\n",
      "Epoch:0 [81|160] loss:0.059558 acc:1.000000\n",
      "Epoch:0 [82|160] loss:0.454342 acc:0.875000\n",
      "Epoch:0 [83|160] loss:0.680936 acc:0.875000\n",
      "Epoch:0 [84|160] loss:0.484063 acc:0.937500\n",
      "Epoch:0 [85|160] loss:0.265409 acc:0.937500\n",
      "Epoch:0 [86|160] loss:0.071059 acc:1.000000\n",
      "Epoch:0 [87|160] loss:0.062356 acc:1.000000\n",
      "Epoch:0 [88|160] loss:0.657456 acc:0.875000\n",
      "Epoch:0 [89|160] loss:0.434894 acc:0.937500\n",
      "Epoch:0 [90|160] loss:0.054669 acc:1.000000\n",
      "Epoch:0 [91|160] loss:0.053521 acc:1.000000\n",
      "Epoch:0 [92|160] loss:0.053823 acc:1.000000\n",
      "Epoch:0 [93|160] loss:0.049948 acc:1.000000\n",
      "Epoch:0 [94|160] loss:0.574331 acc:0.875000\n",
      "Epoch:0 [95|160] loss:0.049196 acc:1.000000\n",
      "Epoch:0 [96|160] loss:0.052792 acc:1.000000\n",
      "Epoch:0 [97|160] loss:0.521570 acc:0.875000\n",
      "Epoch:0 [98|160] loss:0.337007 acc:0.937500\n",
      "Epoch:0 [99|160] loss:0.064760 acc:1.000000\n",
      "Epoch:0 [100|160] loss:0.320556 acc:0.937500\n",
      "Epoch:0 [101|160] loss:0.058155 acc:1.000000\n",
      "Epoch:0 [102|160] loss:0.328439 acc:0.937500\n",
      "Epoch:0 [103|160] loss:0.211340 acc:0.937500\n",
      "Epoch:0 [104|160] loss:0.058880 acc:1.000000\n",
      "Epoch:0 [105|160] loss:0.057756 acc:1.000000\n",
      "Epoch:0 [106|160] loss:0.057767 acc:1.000000\n",
      "Epoch:0 [107|160] loss:0.769954 acc:0.875000\n",
      "Epoch:0 [108|160] loss:0.256867 acc:0.937500\n",
      "Epoch:0 [109|160] loss:0.345563 acc:0.937500\n",
      "Epoch:0 [110|160] loss:0.047891 acc:1.000000\n",
      "Epoch:0 [111|160] loss:0.052498 acc:1.000000\n",
      "Epoch:0 [112|160] loss:0.049086 acc:1.000000\n",
      "Epoch:0 [113|160] loss:0.237553 acc:0.937500\n",
      "Epoch:0 [114|160] loss:0.046060 acc:1.000000\n",
      "Epoch:0 [115|160] loss:0.281229 acc:0.937500\n",
      "Epoch:0 [116|160] loss:0.052197 acc:1.000000\n",
      "Epoch:0 [117|160] loss:0.761718 acc:0.875000\n",
      "Epoch:0 [118|160] loss:0.064728 acc:1.000000\n",
      "Epoch:0 [119|160] loss:0.047839 acc:1.000000\n",
      "Epoch:0 [120|160] loss:0.066530 acc:1.000000\n",
      "Epoch:0 [121|160] loss:0.492323 acc:0.875000\n",
      "Epoch:0 [122|160] loss:0.058627 acc:1.000000\n",
      "Epoch:0 [123|160] loss:0.376553 acc:0.875000\n",
      "Epoch:0 [124|160] loss:0.047630 acc:1.000000\n",
      "Epoch:0 [125|160] loss:0.329226 acc:0.937500\n",
      "Epoch:0 [126|160] loss:0.577666 acc:0.875000\n",
      "Epoch:0 [127|160] loss:0.053526 acc:1.000000\n",
      "Epoch:0 [128|160] loss:0.053092 acc:1.000000\n",
      "Epoch:0 [129|160] loss:0.052765 acc:1.000000\n",
      "Epoch:0 [130|160] loss:0.229465 acc:0.937500\n",
      "Epoch:0 [131|160] loss:0.508684 acc:0.937500\n",
      "Epoch:0 [132|160] loss:0.683456 acc:0.875000\n",
      "Epoch:0 [133|160] loss:0.049685 acc:1.000000\n",
      "Epoch:0 [134|160] loss:0.347147 acc:0.937500\n",
      "Epoch:0 [135|160] loss:0.050643 acc:1.000000\n",
      "Epoch:0 [136|160] loss:0.344382 acc:0.937500\n",
      "Epoch:0 [137|160] loss:0.062687 acc:1.000000\n",
      "Epoch:0 [138|160] loss:0.058221 acc:1.000000\n",
      "Epoch:0 [139|160] loss:0.061540 acc:1.000000\n",
      "Epoch:0 [140|160] loss:0.052350 acc:1.000000\n",
      "Epoch:0 [141|160] loss:0.185494 acc:0.937500\n",
      "Epoch:0 [142|160] loss:0.067100 acc:1.000000\n",
      "Epoch:0 [143|160] loss:0.064698 acc:1.000000\n",
      "Epoch:0 [144|160] loss:0.055651 acc:1.000000\n",
      "Epoch:0 [145|160] loss:0.052555 acc:1.000000\n",
      "Epoch:0 [146|160] loss:0.044950 acc:1.000000\n",
      "Epoch:0 [147|160] loss:0.038790 acc:1.000000\n",
      "Epoch:0 [148|160] loss:0.038386 acc:1.000000\n",
      "Epoch:0 [149|160] loss:0.204311 acc:0.937500\n",
      "Epoch:0 [150|160] loss:0.241146 acc:0.937500\n",
      "Epoch:0 [151|160] loss:0.391961 acc:0.937500\n",
      "Epoch:0 [152|160] loss:0.714559 acc:0.875000\n",
      "Epoch:0 [153|160] loss:0.031403 acc:1.000000\n",
      "Epoch:0 [154|160] loss:0.031129 acc:1.000000\n",
      "Epoch:0 [155|160] loss:0.028904 acc:1.000000\n",
      "Epoch:0 [156|160] loss:0.022949 acc:1.000000\n",
      "Epoch:0 [157|160] loss:0.025839 acc:1.000000\n",
      "Epoch:0 [158|160] loss:0.267002 acc:0.937500\n",
      "Epoch:0 [159|160] loss:0.027404 acc:1.000000\n",
      "\n",
      "Validation Epoch: 0\n",
      "Acc: 0.974961 \n",
      "\n",
      "Epoch: 1\n",
      "Epoch:1 [0|160] loss:0.022121 acc:1.000000\n",
      "Epoch:1 [1|160] loss:0.024940 acc:1.000000\n",
      "Epoch:1 [2|160] loss:0.305509 acc:0.937500\n",
      "Epoch:1 [3|160] loss:0.313093 acc:0.937500\n",
      "Epoch:1 [4|160] loss:0.022141 acc:1.000000\n",
      "Epoch:1 [5|160] loss:0.636303 acc:0.875000\n",
      "Epoch:1 [6|160] loss:0.595273 acc:0.875000\n",
      "Epoch:1 [7|160] loss:0.518658 acc:0.875000\n",
      "Epoch:1 [8|160] loss:0.034152 acc:1.000000\n",
      "Epoch:1 [9|160] loss:0.033717 acc:1.000000\n",
      "Epoch:1 [10|160] loss:0.036384 acc:1.000000\n",
      "Epoch:1 [11|160] loss:0.058638 acc:1.000000\n",
      "Epoch:1 [12|160] loss:0.041671 acc:1.000000\n",
      "Epoch:1 [13|160] loss:0.210175 acc:0.937500\n",
      "Epoch:1 [14|160] loss:0.248856 acc:0.937500\n",
      "Epoch:1 [15|160] loss:0.050703 acc:1.000000\n",
      "Epoch:1 [16|160] loss:0.039956 acc:1.000000\n",
      "Epoch:1 [17|160] loss:0.178874 acc:0.937500\n",
      "Epoch:1 [18|160] loss:0.846174 acc:0.812500\n",
      "Epoch:1 [19|160] loss:0.177007 acc:0.937500\n",
      "Epoch:1 [20|160] loss:0.063056 acc:1.000000\n",
      "Epoch:1 [21|160] loss:0.056914 acc:1.000000\n",
      "Epoch:1 [22|160] loss:0.400941 acc:0.937500\n",
      "Epoch:1 [23|160] loss:0.048616 acc:1.000000\n",
      "Epoch:1 [24|160] loss:0.285428 acc:0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 [25|160] loss:0.055335 acc:1.000000\n",
      "Epoch:1 [26|160] loss:0.049942 acc:1.000000\n",
      "Epoch:1 [27|160] loss:0.045870 acc:1.000000\n",
      "Epoch:1 [28|160] loss:0.205977 acc:0.937500\n",
      "Epoch:1 [29|160] loss:0.053562 acc:1.000000\n",
      "Epoch:1 [30|160] loss:0.045035 acc:1.000000\n",
      "Epoch:1 [31|160] loss:0.039582 acc:1.000000\n",
      "Epoch:1 [32|160] loss:0.036245 acc:1.000000\n",
      "Epoch:1 [33|160] loss:0.678136 acc:0.875000\n",
      "Epoch:1 [34|160] loss:0.037300 acc:1.000000\n",
      "Epoch:1 [35|160] loss:0.035198 acc:1.000000\n",
      "Epoch:1 [36|160] loss:0.038468 acc:1.000000\n",
      "Epoch:1 [37|160] loss:0.032223 acc:1.000000\n",
      "Epoch:1 [38|160] loss:0.321024 acc:0.937500\n",
      "Epoch:1 [39|160] loss:0.035224 acc:1.000000\n",
      "Epoch:1 [40|160] loss:0.345980 acc:0.937500\n",
      "Epoch:1 [41|160] loss:0.030737 acc:1.000000\n",
      "Epoch:1 [42|160] loss:0.030974 acc:1.000000\n",
      "Epoch:1 [43|160] loss:0.303636 acc:0.937500\n",
      "Epoch:1 [44|160] loss:0.028531 acc:1.000000\n",
      "Epoch:1 [45|160] loss:1.073482 acc:0.812500\n",
      "Epoch:1 [46|160] loss:0.029930 acc:1.000000\n",
      "Epoch:1 [47|160] loss:0.534168 acc:0.875000\n",
      "Epoch:1 [48|160] loss:0.026413 acc:1.000000\n",
      "Epoch:1 [49|160] loss:0.030078 acc:1.000000\n",
      "Epoch:1 [50|160] loss:0.028976 acc:1.000000\n",
      "Epoch:1 [51|160] loss:0.028047 acc:1.000000\n",
      "Epoch:1 [52|160] loss:0.272035 acc:0.937500\n",
      "Epoch:1 [53|160] loss:0.032023 acc:1.000000\n",
      "Epoch:1 [54|160] loss:0.334394 acc:0.937500\n",
      "Epoch:1 [55|160] loss:0.033697 acc:1.000000\n",
      "Epoch:1 [56|160] loss:0.029692 acc:1.000000\n",
      "Epoch:1 [57|160] loss:0.035132 acc:1.000000\n",
      "Epoch:1 [58|160] loss:0.030868 acc:1.000000\n",
      "Epoch:1 [59|160] loss:0.285987 acc:0.937500\n",
      "Epoch:1 [60|160] loss:0.150109 acc:0.937500\n",
      "Epoch:1 [61|160] loss:0.032108 acc:1.000000\n",
      "Epoch:1 [62|160] loss:0.286076 acc:0.937500\n",
      "Epoch:1 [63|160] loss:0.327981 acc:0.937500\n",
      "Epoch:1 [64|160] loss:0.036360 acc:1.000000\n",
      "Epoch:1 [65|160] loss:0.038057 acc:1.000000\n",
      "Epoch:1 [66|160] loss:0.032596 acc:1.000000\n",
      "Epoch:1 [67|160] loss:0.032957 acc:1.000000\n",
      "Epoch:1 [68|160] loss:0.033933 acc:1.000000\n",
      "Epoch:1 [69|160] loss:0.268746 acc:0.937500\n",
      "Epoch:1 [70|160] loss:0.028864 acc:1.000000\n",
      "Epoch:1 [71|160] loss:0.032042 acc:1.000000\n",
      "Epoch:1 [72|160] loss:0.276281 acc:0.937500\n",
      "Epoch:1 [73|160] loss:0.030165 acc:1.000000\n",
      "Epoch:1 [74|160] loss:0.556951 acc:0.875000\n",
      "Epoch:1 [75|160] loss:0.031691 acc:1.000000\n",
      "Epoch:1 [76|160] loss:0.026636 acc:1.000000\n",
      "Epoch:1 [77|160] loss:0.269806 acc:0.937500\n",
      "Epoch:1 [78|160] loss:0.031075 acc:1.000000\n",
      "Epoch:1 [79|160] loss:0.348026 acc:0.937500\n",
      "Epoch:1 [80|160] loss:0.026668 acc:1.000000\n",
      "Epoch:1 [81|160] loss:0.028702 acc:1.000000\n",
      "Epoch:1 [82|160] loss:0.359395 acc:0.937500\n",
      "Epoch:1 [83|160] loss:0.527254 acc:0.875000\n",
      "Epoch:1 [84|160] loss:0.032639 acc:1.000000\n",
      "Epoch:1 [85|160] loss:0.315252 acc:0.937500\n",
      "Epoch:1 [86|160] loss:0.040359 acc:1.000000\n",
      "Epoch:1 [87|160] loss:0.030687 acc:1.000000\n",
      "Epoch:1 [88|160] loss:0.033708 acc:1.000000\n",
      "Epoch:1 [89|160] loss:0.031561 acc:1.000000\n",
      "Epoch:1 [90|160] loss:0.486742 acc:0.875000\n",
      "Epoch:1 [91|160] loss:0.033585 acc:1.000000\n",
      "Epoch:1 [92|160] loss:0.036555 acc:1.000000\n",
      "Epoch:1 [93|160] loss:0.036930 acc:1.000000\n",
      "Epoch:1 [94|160] loss:0.032752 acc:1.000000\n",
      "Epoch:1 [95|160] loss:0.309771 acc:0.937500\n",
      "Epoch:1 [96|160] loss:0.371468 acc:0.937500\n",
      "Epoch:1 [97|160] loss:0.035355 acc:1.000000\n",
      "Epoch:1 [98|160] loss:0.038344 acc:1.000000\n",
      "Epoch:1 [99|160] loss:0.398765 acc:0.937500\n",
      "Epoch:1 [100|160] loss:0.034965 acc:1.000000\n",
      "Epoch:1 [101|160] loss:0.294697 acc:0.937500\n",
      "Epoch:1 [102|160] loss:0.032709 acc:1.000000\n",
      "Epoch:1 [103|160] loss:0.033989 acc:1.000000\n",
      "Epoch:1 [104|160] loss:0.031502 acc:1.000000\n",
      "Epoch:1 [105|160] loss:0.398051 acc:0.937500\n",
      "Epoch:1 [106|160] loss:0.031058 acc:1.000000\n",
      "Epoch:1 [107|160] loss:0.027055 acc:1.000000\n",
      "Epoch:1 [108|160] loss:0.030973 acc:1.000000\n",
      "Epoch:1 [109|160] loss:0.028166 acc:1.000000\n",
      "Epoch:1 [110|160] loss:0.271929 acc:0.937500\n",
      "Epoch:1 [111|160] loss:0.025019 acc:1.000000\n",
      "Epoch:1 [112|160] loss:0.026218 acc:1.000000\n",
      "Epoch:1 [113|160] loss:0.026189 acc:1.000000\n",
      "Epoch:1 [114|160] loss:0.317998 acc:0.937500\n",
      "Epoch:1 [115|160] loss:0.852518 acc:0.812500\n",
      "Epoch:1 [116|160] loss:0.257293 acc:0.937500\n",
      "Epoch:1 [117|160] loss:0.029832 acc:1.000000\n",
      "Epoch:1 [118|160] loss:0.025464 acc:1.000000\n",
      "Epoch:1 [119|160] loss:0.027834 acc:1.000000\n",
      "Epoch:1 [120|160] loss:0.029567 acc:1.000000\n",
      "Epoch:1 [121|160] loss:0.024578 acc:1.000000\n",
      "Epoch:1 [122|160] loss:0.030831 acc:1.000000\n",
      "Epoch:1 [123|160] loss:0.028644 acc:1.000000\n",
      "Epoch:1 [124|160] loss:0.510123 acc:0.875000\n",
      "Epoch:1 [125|160] loss:0.029149 acc:1.000000\n",
      "Epoch:1 [126|160] loss:0.720905 acc:0.812500\n",
      "Epoch:1 [127|160] loss:0.025823 acc:1.000000\n",
      "Epoch:1 [128|160] loss:0.029094 acc:1.000000\n",
      "Epoch:1 [129|160] loss:0.348470 acc:0.937500\n",
      "Epoch:1 [130|160] loss:0.028627 acc:1.000000\n",
      "Epoch:1 [131|160] loss:0.038386 acc:1.000000\n",
      "Epoch:1 [132|160] loss:0.291435 acc:0.937500\n",
      "Epoch:1 [133|160] loss:0.046526 acc:1.000000\n",
      "Epoch:1 [134|160] loss:0.283462 acc:0.937500\n",
      "Epoch:1 [135|160] loss:0.041750 acc:1.000000\n",
      "Epoch:1 [136|160] loss:0.198206 acc:0.937500\n",
      "Epoch:1 [137|160] loss:0.479720 acc:0.875000\n",
      "Epoch:1 [138|160] loss:0.052836 acc:1.000000\n",
      "Epoch:1 [139|160] loss:0.040097 acc:1.000000\n",
      "Epoch:1 [140|160] loss:0.442501 acc:0.937500\n",
      "Epoch:1 [141|160] loss:0.339904 acc:0.937500\n",
      "Epoch:1 [142|160] loss:0.050022 acc:1.000000\n",
      "Epoch:1 [143|160] loss:0.085477 acc:0.937500\n",
      "Epoch:1 [144|160] loss:0.050227 acc:1.000000\n",
      "Epoch:1 [145|160] loss:0.304657 acc:0.937500\n",
      "Epoch:1 [146|160] loss:0.057953 acc:1.000000\n",
      "Epoch:1 [147|160] loss:0.071383 acc:1.000000\n",
      "Epoch:1 [148|160] loss:0.681586 acc:0.875000\n",
      "Epoch:1 [149|160] loss:0.050667 acc:1.000000\n",
      "Epoch:1 [150|160] loss:0.304140 acc:0.937500\n",
      "Epoch:1 [151|160] loss:0.349127 acc:0.937500\n",
      "Epoch:1 [152|160] loss:0.044383 acc:1.000000\n",
      "Epoch:1 [153|160] loss:0.050588 acc:1.000000\n",
      "Epoch:1 [154|160] loss:0.046583 acc:1.000000\n",
      "Epoch:1 [155|160] loss:0.363834 acc:0.937500\n",
      "Epoch:1 [156|160] loss:0.281499 acc:0.937500\n",
      "Epoch:1 [157|160] loss:0.333591 acc:0.937500\n",
      "Epoch:1 [158|160] loss:0.229052 acc:0.937500\n",
      "Epoch:1 [159|160] loss:0.562584 acc:0.833333\n",
      "\n",
      "Validation Epoch: 1\n",
      "Acc: 0.974961 \n",
      "\n",
      "Epoch: 2\n",
      "Epoch:2 [0|160] loss:0.034168 acc:1.000000\n",
      "Epoch:2 [1|160] loss:0.281306 acc:0.937500\n",
      "Epoch:2 [2|160] loss:0.038208 acc:1.000000\n",
      "Epoch:2 [3|160] loss:0.049305 acc:1.000000\n",
      "Epoch:2 [4|160] loss:0.445420 acc:0.937500\n",
      "Epoch:2 [5|160] loss:0.042832 acc:1.000000\n",
      "Epoch:2 [6|160] loss:0.044837 acc:1.000000\n",
      "Epoch:2 [7|160] loss:0.041989 acc:1.000000\n",
      "Epoch:2 [8|160] loss:0.039384 acc:1.000000\n",
      "Epoch:2 [9|160] loss:0.285133 acc:0.937500\n",
      "Epoch:2 [10|160] loss:0.383334 acc:0.875000\n",
      "Epoch:2 [11|160] loss:0.299987 acc:0.937500\n",
      "Epoch:2 [12|160] loss:0.038548 acc:1.000000\n",
      "Epoch:2 [13|160] loss:0.525738 acc:0.875000\n",
      "Epoch:2 [14|160] loss:0.243375 acc:0.937500\n",
      "Epoch:2 [15|160] loss:0.052269 acc:1.000000\n",
      "Epoch:2 [16|160] loss:0.136765 acc:0.937500\n",
      "Epoch:2 [17|160] loss:0.052563 acc:1.000000\n",
      "Epoch:2 [18|160] loss:0.218555 acc:0.937500\n",
      "Epoch:2 [19|160] loss:0.042804 acc:1.000000\n",
      "Epoch:2 [20|160] loss:0.055836 acc:1.000000\n",
      "Epoch:2 [21|160] loss:0.486607 acc:0.875000\n",
      "Epoch:2 [22|160] loss:0.050262 acc:1.000000\n",
      "Epoch:2 [23|160] loss:0.247882 acc:0.937500\n",
      "Epoch:2 [24|160] loss:0.512263 acc:0.875000\n",
      "Epoch:2 [25|160] loss:0.265207 acc:0.937500\n",
      "Epoch:2 [26|160] loss:0.050373 acc:1.000000\n",
      "Epoch:2 [27|160] loss:0.297787 acc:0.937500\n",
      "Epoch:2 [28|160] loss:0.052766 acc:1.000000\n",
      "Epoch:2 [29|160] loss:0.059977 acc:1.000000\n",
      "Epoch:2 [30|160] loss:0.302233 acc:0.937500\n",
      "Epoch:2 [31|160] loss:0.047866 acc:1.000000\n",
      "Epoch:2 [32|160] loss:0.051429 acc:1.000000\n",
      "Epoch:2 [33|160] loss:0.055024 acc:1.000000\n",
      "Epoch:2 [34|160] loss:0.042774 acc:1.000000\n",
      "Epoch:2 [35|160] loss:0.201458 acc:0.937500\n",
      "Epoch:2 [36|160] loss:0.531269 acc:0.875000\n",
      "Epoch:2 [37|160] loss:0.040281 acc:1.000000\n",
      "Epoch:2 [38|160] loss:0.033177 acc:1.000000\n",
      "Epoch:2 [39|160] loss:0.033753 acc:1.000000\n",
      "Epoch:2 [40|160] loss:0.453557 acc:0.875000\n",
      "Epoch:2 [41|160] loss:0.243451 acc:0.937500\n",
      "Epoch:2 [42|160] loss:0.039912 acc:1.000000\n",
      "Epoch:2 [43|160] loss:0.051375 acc:1.000000\n",
      "Epoch:2 [44|160] loss:0.508608 acc:0.875000\n",
      "Epoch:2 [45|160] loss:0.285031 acc:0.937500\n",
      "Epoch:2 [46|160] loss:0.037751 acc:1.000000\n",
      "Epoch:2 [47|160] loss:0.042265 acc:1.000000\n",
      "Epoch:2 [48|160] loss:0.185503 acc:0.937500\n",
      "Epoch:2 [49|160] loss:0.043312 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2 [50|160] loss:0.045019 acc:1.000000\n",
      "Epoch:2 [51|160] loss:0.031034 acc:1.000000\n",
      "Epoch:2 [52|160] loss:0.034788 acc:1.000000\n",
      "Epoch:2 [53|160] loss:0.037375 acc:1.000000\n",
      "Epoch:2 [54|160] loss:0.212079 acc:0.937500\n",
      "Epoch:2 [55|160] loss:0.037544 acc:1.000000\n",
      "Epoch:2 [56|160] loss:0.030943 acc:1.000000\n",
      "Epoch:2 [57|160] loss:0.033247 acc:1.000000\n",
      "Epoch:2 [58|160] loss:0.223271 acc:0.937500\n",
      "Epoch:2 [59|160] loss:0.025191 acc:1.000000\n",
      "Epoch:2 [60|160] loss:0.230001 acc:0.937500\n",
      "Epoch:2 [61|160] loss:0.024541 acc:1.000000\n",
      "Epoch:2 [62|160] loss:0.221786 acc:0.937500\n",
      "Epoch:2 [63|160] loss:0.024602 acc:1.000000\n",
      "Epoch:2 [64|160] loss:0.524422 acc:0.875000\n",
      "Epoch:2 [65|160] loss:0.023065 acc:1.000000\n",
      "Epoch:2 [66|160] loss:0.032522 acc:1.000000\n",
      "Epoch:2 [67|160] loss:0.030283 acc:1.000000\n",
      "Epoch:2 [68|160] loss:0.221135 acc:0.937500\n",
      "Epoch:2 [69|160] loss:0.030454 acc:1.000000\n",
      "Epoch:2 [70|160] loss:0.322632 acc:0.937500\n",
      "Epoch:2 [71|160] loss:0.743581 acc:0.875000\n",
      "Epoch:2 [72|160] loss:0.399380 acc:0.937500\n",
      "Epoch:2 [73|160] loss:0.035533 acc:1.000000\n",
      "Epoch:2 [74|160] loss:0.055318 acc:1.000000\n",
      "Epoch:2 [75|160] loss:0.216326 acc:0.937500\n",
      "Epoch:2 [76|160] loss:0.584111 acc:0.875000\n",
      "Epoch:2 [77|160] loss:0.189762 acc:0.937500\n",
      "Epoch:2 [78|160] loss:0.054223 acc:1.000000\n",
      "Epoch:2 [79|160] loss:0.040158 acc:1.000000\n",
      "Epoch:2 [80|160] loss:0.050002 acc:1.000000\n",
      "Epoch:2 [81|160] loss:0.074804 acc:1.000000\n",
      "Epoch:2 [82|160] loss:0.448230 acc:0.937500\n",
      "Epoch:2 [83|160] loss:0.354499 acc:0.875000\n",
      "Epoch:2 [84|160] loss:0.335201 acc:0.937500\n",
      "Epoch:2 [85|160] loss:0.231103 acc:0.937500\n",
      "Epoch:2 [86|160] loss:0.033906 acc:1.000000\n",
      "Epoch:2 [87|160] loss:0.219817 acc:0.937500\n",
      "Epoch:2 [88|160] loss:0.036535 acc:1.000000\n",
      "Epoch:2 [89|160] loss:0.439812 acc:0.875000\n",
      "Epoch:2 [90|160] loss:0.054202 acc:1.000000\n",
      "Epoch:2 [91|160] loss:0.033202 acc:1.000000\n",
      "Epoch:2 [92|160] loss:0.281806 acc:0.937500\n",
      "Epoch:2 [93|160] loss:0.040762 acc:1.000000\n",
      "Epoch:2 [94|160] loss:0.050860 acc:1.000000\n",
      "Epoch:2 [95|160] loss:0.035041 acc:1.000000\n",
      "Epoch:2 [96|160] loss:0.259434 acc:0.937500\n",
      "Epoch:2 [97|160] loss:0.316282 acc:0.937500\n",
      "Epoch:2 [98|160] loss:0.297991 acc:0.937500\n",
      "Epoch:2 [99|160] loss:0.028669 acc:1.000000\n",
      "Epoch:2 [100|160] loss:0.035237 acc:1.000000\n",
      "Epoch:2 [101|160] loss:0.035950 acc:1.000000\n",
      "Epoch:2 [102|160] loss:0.029535 acc:1.000000\n",
      "Epoch:2 [103|160] loss:0.482154 acc:0.875000\n",
      "Epoch:2 [104|160] loss:0.031061 acc:1.000000\n",
      "Epoch:2 [105|160] loss:0.030612 acc:1.000000\n",
      "Epoch:2 [106|160] loss:0.030607 acc:1.000000\n",
      "Epoch:2 [107|160] loss:0.035791 acc:1.000000\n",
      "Epoch:2 [108|160] loss:0.028855 acc:1.000000\n",
      "Epoch:2 [109|160] loss:0.697290 acc:0.875000\n",
      "Epoch:2 [110|160] loss:0.033074 acc:1.000000\n",
      "Epoch:2 [111|160] loss:0.034569 acc:1.000000\n",
      "Epoch:2 [112|160] loss:0.033617 acc:1.000000\n",
      "Epoch:2 [113|160] loss:0.184489 acc:0.937500\n",
      "Epoch:2 [114|160] loss:0.040060 acc:1.000000\n",
      "Epoch:2 [115|160] loss:0.229933 acc:0.937500\n",
      "Epoch:2 [116|160] loss:0.032850 acc:1.000000\n",
      "Epoch:2 [117|160] loss:0.229386 acc:0.937500\n",
      "Epoch:2 [118|160] loss:0.236826 acc:0.937500\n",
      "Epoch:2 [119|160] loss:0.026769 acc:1.000000\n",
      "Epoch:2 [120|160] loss:0.025574 acc:1.000000\n",
      "Epoch:2 [121|160] loss:0.446556 acc:0.937500\n",
      "Epoch:2 [122|160] loss:0.458028 acc:0.875000\n",
      "Epoch:2 [123|160] loss:0.036052 acc:1.000000\n",
      "Epoch:2 [124|160] loss:0.029250 acc:1.000000\n",
      "Epoch:2 [125|160] loss:0.201580 acc:0.937500\n",
      "Epoch:2 [126|160] loss:0.434748 acc:0.875000\n",
      "Epoch:2 [127|160] loss:0.044605 acc:1.000000\n",
      "Epoch:2 [128|160] loss:0.032256 acc:1.000000\n",
      "Epoch:2 [129|160] loss:0.047655 acc:1.000000\n",
      "Epoch:2 [130|160] loss:0.339473 acc:0.937500\n",
      "Epoch:2 [131|160] loss:0.057035 acc:1.000000\n",
      "Epoch:2 [132|160] loss:0.249080 acc:0.937500\n",
      "Epoch:2 [133|160] loss:0.543376 acc:0.875000\n",
      "Epoch:2 [134|160] loss:0.617331 acc:0.875000\n",
      "Epoch:2 [135|160] loss:0.467020 acc:0.875000\n",
      "Epoch:2 [136|160] loss:0.048466 acc:1.000000\n",
      "Epoch:2 [137|160] loss:0.049933 acc:1.000000\n",
      "Epoch:2 [138|160] loss:0.072113 acc:1.000000\n",
      "Epoch:2 [139|160] loss:0.051119 acc:1.000000\n",
      "Epoch:2 [140|160] loss:0.054991 acc:1.000000\n",
      "Epoch:2 [141|160] loss:0.201926 acc:0.937500\n",
      "Epoch:2 [142|160] loss:0.044988 acc:1.000000\n",
      "Epoch:2 [143|160] loss:0.059010 acc:1.000000\n",
      "Epoch:2 [144|160] loss:0.052428 acc:1.000000\n",
      "Epoch:2 [145|160] loss:0.047166 acc:1.000000\n",
      "Epoch:2 [146|160] loss:0.047987 acc:1.000000\n",
      "Epoch:2 [147|160] loss:0.197662 acc:0.937500\n",
      "Epoch:2 [148|160] loss:0.036371 acc:1.000000\n",
      "Epoch:2 [149|160] loss:0.029979 acc:1.000000\n",
      "Epoch:2 [150|160] loss:0.029090 acc:1.000000\n",
      "Epoch:2 [151|160] loss:0.029526 acc:1.000000\n",
      "Epoch:2 [152|160] loss:0.024753 acc:1.000000\n",
      "Epoch:2 [153|160] loss:0.025279 acc:1.000000\n",
      "Epoch:2 [154|160] loss:0.241900 acc:0.937500\n",
      "Epoch:2 [155|160] loss:0.026580 acc:1.000000\n",
      "Epoch:2 [156|160] loss:0.023395 acc:1.000000\n",
      "Epoch:2 [157|160] loss:0.024987 acc:1.000000\n",
      "Epoch:2 [158|160] loss:0.231650 acc:0.937500\n",
      "Epoch:2 [159|160] loss:0.017440 acc:1.000000\n",
      "\n",
      "Validation Epoch: 2\n",
      "Acc: 0.974961 \n",
      "\n",
      "Epoch: 3\n",
      "Epoch:3 [0|160] loss:0.017383 acc:1.000000\n",
      "Epoch:3 [1|160] loss:0.017041 acc:1.000000\n",
      "Epoch:3 [2|160] loss:0.017113 acc:1.000000\n",
      "Epoch:3 [3|160] loss:0.012968 acc:1.000000\n",
      "Epoch:3 [4|160] loss:0.650466 acc:0.875000\n",
      "Epoch:3 [5|160] loss:0.013355 acc:1.000000\n",
      "Epoch:3 [6|160] loss:0.338537 acc:0.937500\n",
      "Epoch:3 [7|160] loss:0.014538 acc:1.000000\n",
      "Epoch:3 [8|160] loss:0.012794 acc:1.000000\n",
      "Epoch:3 [9|160] loss:0.315154 acc:0.937500\n",
      "Epoch:3 [10|160] loss:0.214539 acc:0.937500\n",
      "Epoch:3 [11|160] loss:0.275530 acc:0.937500\n",
      "Epoch:3 [12|160] loss:0.018839 acc:1.000000\n",
      "Epoch:3 [13|160] loss:0.020578 acc:1.000000\n",
      "Epoch:3 [14|160] loss:0.462637 acc:0.875000\n",
      "Epoch:3 [15|160] loss:0.298273 acc:0.937500\n",
      "Epoch:3 [16|160] loss:0.033597 acc:1.000000\n",
      "Epoch:3 [17|160] loss:0.271975 acc:0.937500\n",
      "Epoch:3 [18|160] loss:0.372357 acc:0.937500\n",
      "Epoch:3 [19|160] loss:0.036191 acc:1.000000\n",
      "Epoch:3 [20|160] loss:0.043622 acc:1.000000\n",
      "Epoch:3 [21|160] loss:0.055252 acc:1.000000\n",
      "Epoch:3 [22|160] loss:0.037165 acc:1.000000\n",
      "Epoch:3 [23|160] loss:0.297351 acc:0.937500\n",
      "Epoch:3 [24|160] loss:0.032568 acc:1.000000\n",
      "Epoch:3 [25|160] loss:0.355487 acc:0.937500\n",
      "Epoch:3 [26|160] loss:0.034021 acc:1.000000\n",
      "Epoch:3 [27|160] loss:0.024129 acc:1.000000\n",
      "Epoch:3 [28|160] loss:0.022636 acc:1.000000\n",
      "Epoch:3 [29|160] loss:0.029409 acc:1.000000\n",
      "Epoch:3 [30|160] loss:0.224934 acc:0.937500\n",
      "Epoch:3 [31|160] loss:0.032352 acc:1.000000\n",
      "Epoch:3 [32|160] loss:0.261355 acc:0.937500\n",
      "Epoch:3 [33|160] loss:0.027013 acc:1.000000\n",
      "Epoch:3 [34|160] loss:0.197357 acc:0.937500\n",
      "Epoch:3 [35|160] loss:0.031233 acc:1.000000\n",
      "Epoch:3 [36|160] loss:0.028849 acc:1.000000\n",
      "Epoch:3 [37|160] loss:0.026311 acc:1.000000\n",
      "Epoch:3 [38|160] loss:0.431456 acc:0.875000\n",
      "Epoch:3 [39|160] loss:0.032208 acc:1.000000\n",
      "Epoch:3 [40|160] loss:0.037389 acc:1.000000\n",
      "Epoch:3 [41|160] loss:0.036895 acc:1.000000\n",
      "Epoch:3 [42|160] loss:0.362514 acc:0.937500\n",
      "Epoch:3 [43|160] loss:0.034972 acc:1.000000\n",
      "Epoch:3 [44|160] loss:0.026346 acc:1.000000\n",
      "Epoch:3 [45|160] loss:0.237089 acc:0.937500\n",
      "Epoch:3 [46|160] loss:0.028562 acc:1.000000\n",
      "Epoch:3 [47|160] loss:0.286804 acc:0.937500\n",
      "Epoch:3 [48|160] loss:0.022963 acc:1.000000\n",
      "Epoch:3 [49|160] loss:0.311709 acc:0.937500\n",
      "Epoch:3 [50|160] loss:0.021379 acc:1.000000\n",
      "Epoch:3 [51|160] loss:0.022341 acc:1.000000\n",
      "Epoch:3 [52|160] loss:0.263433 acc:0.937500\n",
      "Epoch:3 [53|160] loss:0.030640 acc:1.000000\n",
      "Epoch:3 [54|160] loss:0.028172 acc:1.000000\n",
      "Epoch:3 [55|160] loss:0.019721 acc:1.000000\n",
      "Epoch:3 [56|160] loss:0.281417 acc:0.937500\n",
      "Epoch:3 [57|160] loss:0.230877 acc:0.875000\n",
      "Epoch:3 [58|160] loss:0.129513 acc:0.937500\n",
      "Epoch:3 [59|160] loss:0.025799 acc:1.000000\n",
      "Epoch:3 [60|160] loss:0.021640 acc:1.000000\n",
      "Epoch:3 [61|160] loss:0.305322 acc:0.937500\n",
      "Epoch:3 [62|160] loss:0.295554 acc:0.937500\n",
      "Epoch:3 [63|160] loss:0.374501 acc:0.937500\n",
      "Epoch:3 [64|160] loss:0.025361 acc:1.000000\n",
      "Epoch:3 [65|160] loss:0.216346 acc:0.937500\n",
      "Epoch:3 [66|160] loss:0.024099 acc:1.000000\n",
      "Epoch:3 [67|160] loss:0.323747 acc:0.937500\n",
      "Epoch:3 [68|160] loss:0.527183 acc:0.875000\n",
      "Epoch:3 [69|160] loss:0.042570 acc:1.000000\n",
      "Epoch:3 [70|160] loss:0.041132 acc:1.000000\n",
      "Epoch:3 [71|160] loss:0.202769 acc:0.937500\n",
      "Epoch:3 [72|160] loss:0.174264 acc:0.937500\n",
      "Epoch:3 [73|160] loss:0.271880 acc:0.937500\n",
      "Epoch:3 [74|160] loss:0.071973 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3 [75|160] loss:0.073244 acc:1.000000\n",
      "Epoch:3 [76|160] loss:0.052391 acc:1.000000\n",
      "Epoch:3 [77|160] loss:0.042975 acc:1.000000\n",
      "Epoch:3 [78|160] loss:0.043832 acc:1.000000\n",
      "Epoch:3 [79|160] loss:0.232213 acc:0.937500\n",
      "Epoch:3 [80|160] loss:0.029559 acc:1.000000\n",
      "Epoch:3 [81|160] loss:0.029475 acc:1.000000\n",
      "Epoch:3 [82|160] loss:0.038979 acc:1.000000\n",
      "Epoch:3 [83|160] loss:0.343589 acc:0.875000\n",
      "Epoch:3 [84|160] loss:0.039466 acc:1.000000\n",
      "Epoch:3 [85|160] loss:0.035878 acc:1.000000\n",
      "Epoch:3 [86|160] loss:0.508083 acc:0.937500\n",
      "Epoch:3 [87|160] loss:0.520225 acc:0.937500\n",
      "Epoch:3 [88|160] loss:0.031463 acc:1.000000\n",
      "Epoch:3 [89|160] loss:0.343077 acc:0.937500\n",
      "Epoch:3 [90|160] loss:0.026218 acc:1.000000\n",
      "Epoch:3 [91|160] loss:0.231603 acc:0.937500\n",
      "Epoch:3 [92|160] loss:0.030820 acc:1.000000\n",
      "Epoch:3 [93|160] loss:0.020917 acc:1.000000\n",
      "Epoch:3 [94|160] loss:0.806829 acc:0.875000\n",
      "Epoch:3 [95|160] loss:0.026140 acc:1.000000\n",
      "Epoch:3 [96|160] loss:0.198774 acc:0.937500\n",
      "Epoch:3 [97|160] loss:0.028662 acc:1.000000\n",
      "Epoch:3 [98|160] loss:0.378923 acc:0.937500\n",
      "Epoch:3 [99|160] loss:0.026587 acc:1.000000\n",
      "Epoch:3 [100|160] loss:0.569850 acc:0.875000\n",
      "Epoch:3 [101|160] loss:0.286788 acc:0.937500\n",
      "Epoch:3 [102|160] loss:0.032474 acc:1.000000\n",
      "Epoch:3 [103|160] loss:0.030113 acc:1.000000\n",
      "Epoch:3 [104|160] loss:0.551272 acc:0.875000\n",
      "Epoch:3 [105|160] loss:0.037895 acc:1.000000\n",
      "Epoch:3 [106|160] loss:0.037091 acc:1.000000\n",
      "Epoch:3 [107|160] loss:0.042885 acc:1.000000\n",
      "Epoch:3 [108|160] loss:0.623787 acc:0.875000\n",
      "Epoch:3 [109|160] loss:0.042986 acc:1.000000\n",
      "Epoch:3 [110|160] loss:0.837428 acc:0.812500\n",
      "Epoch:3 [111|160] loss:0.046837 acc:1.000000\n",
      "Epoch:3 [112|160] loss:0.042565 acc:1.000000\n",
      "Epoch:3 [113|160] loss:0.046010 acc:1.000000\n",
      "Epoch:3 [114|160] loss:0.040517 acc:1.000000\n",
      "Epoch:3 [115|160] loss:0.208059 acc:0.937500\n",
      "Epoch:3 [116|160] loss:0.045809 acc:1.000000\n",
      "Epoch:3 [117|160] loss:0.048187 acc:1.000000\n",
      "Epoch:3 [118|160] loss:0.042624 acc:1.000000\n",
      "Epoch:3 [119|160] loss:0.035483 acc:1.000000\n",
      "Epoch:3 [120|160] loss:0.231875 acc:0.937500\n",
      "Epoch:3 [121|160] loss:0.209178 acc:0.937500\n",
      "Epoch:3 [122|160] loss:0.042289 acc:1.000000\n",
      "Epoch:3 [123|160] loss:0.039622 acc:1.000000\n",
      "Epoch:3 [124|160] loss:0.040367 acc:1.000000\n",
      "Epoch:3 [125|160] loss:0.717112 acc:0.812500\n",
      "Epoch:3 [126|160] loss:0.038081 acc:1.000000\n",
      "Epoch:3 [127|160] loss:0.192460 acc:0.937500\n",
      "Epoch:3 [128|160] loss:0.036332 acc:1.000000\n",
      "Epoch:3 [129|160] loss:0.407431 acc:0.875000\n",
      "Epoch:3 [130|160] loss:0.039554 acc:1.000000\n",
      "Epoch:3 [131|160] loss:0.631912 acc:0.875000\n",
      "Epoch:3 [132|160] loss:0.039041 acc:1.000000\n",
      "Epoch:3 [133|160] loss:0.041586 acc:1.000000\n",
      "Epoch:3 [134|160] loss:0.042839 acc:1.000000\n",
      "Epoch:3 [135|160] loss:0.044410 acc:1.000000\n",
      "Epoch:3 [136|160] loss:0.041037 acc:1.000000\n",
      "Epoch:3 [137|160] loss:0.359481 acc:0.937500\n",
      "Epoch:3 [138|160] loss:0.031394 acc:1.000000\n",
      "Epoch:3 [139|160] loss:0.037823 acc:1.000000\n",
      "Epoch:3 [140|160] loss:0.028672 acc:1.000000\n",
      "Epoch:3 [141|160] loss:0.028784 acc:1.000000\n",
      "Epoch:3 [142|160] loss:0.039652 acc:1.000000\n",
      "Epoch:3 [143|160] loss:0.042013 acc:1.000000\n",
      "Epoch:3 [144|160] loss:0.026883 acc:1.000000\n",
      "Epoch:3 [145|160] loss:0.023871 acc:1.000000\n",
      "Epoch:3 [146|160] loss:0.028329 acc:1.000000\n",
      "Epoch:3 [147|160] loss:0.024079 acc:1.000000\n",
      "Epoch:3 [148|160] loss:0.701328 acc:0.875000\n",
      "Epoch:3 [149|160] loss:0.580067 acc:0.875000\n",
      "Epoch:3 [150|160] loss:0.224398 acc:0.937500\n",
      "Epoch:3 [151|160] loss:0.023224 acc:1.000000\n",
      "Epoch:3 [152|160] loss:0.467395 acc:0.875000\n",
      "Epoch:3 [153|160] loss:0.025665 acc:1.000000\n",
      "Epoch:3 [154|160] loss:0.281612 acc:0.937500\n",
      "Epoch:3 [155|160] loss:0.268889 acc:0.937500\n",
      "Epoch:3 [156|160] loss:0.024035 acc:1.000000\n",
      "Epoch:3 [157|160] loss:0.351072 acc:0.937500\n",
      "Epoch:3 [158|160] loss:0.030318 acc:1.000000\n",
      "Epoch:3 [159|160] loss:0.359519 acc:0.916667\n",
      "\n",
      "Validation Epoch: 3\n",
      "Acc: 0.973396 \n",
      "\n",
      "Epoch: 4\n",
      "Epoch:4 [0|160] loss:0.459687 acc:0.875000\n",
      "Epoch:4 [1|160] loss:0.034577 acc:1.000000\n",
      "Epoch:4 [2|160] loss:0.343481 acc:0.875000\n",
      "Epoch:4 [3|160] loss:0.042358 acc:1.000000\n",
      "Epoch:4 [4|160] loss:0.334262 acc:0.937500\n",
      "Epoch:4 [5|160] loss:0.034311 acc:1.000000\n",
      "Epoch:4 [6|160] loss:0.241754 acc:0.937500\n",
      "Epoch:4 [7|160] loss:0.423487 acc:0.937500\n",
      "Epoch:4 [8|160] loss:0.039891 acc:1.000000\n",
      "Epoch:4 [9|160] loss:0.277814 acc:0.937500\n",
      "Epoch:4 [10|160] loss:0.218175 acc:0.937500\n",
      "Epoch:4 [11|160] loss:0.034775 acc:1.000000\n",
      "Epoch:4 [12|160] loss:0.155397 acc:0.937500\n",
      "Epoch:4 [13|160] loss:0.281557 acc:0.937500\n",
      "Epoch:4 [14|160] loss:0.043735 acc:1.000000\n",
      "Epoch:4 [15|160] loss:0.034977 acc:1.000000\n",
      "Epoch:4 [16|160] loss:0.033551 acc:1.000000\n",
      "Epoch:4 [17|160] loss:0.250341 acc:0.937500\n",
      "Epoch:4 [18|160] loss:0.239027 acc:0.937500\n",
      "Epoch:4 [19|160] loss:0.038828 acc:1.000000\n",
      "Epoch:4 [20|160] loss:0.035808 acc:1.000000\n",
      "Epoch:4 [21|160] loss:0.120134 acc:0.937500\n",
      "Epoch:4 [22|160] loss:0.043148 acc:1.000000\n",
      "Epoch:4 [23|160] loss:0.038721 acc:1.000000\n",
      "Epoch:4 [24|160] loss:0.306738 acc:0.875000\n",
      "Epoch:4 [25|160] loss:0.038448 acc:1.000000\n",
      "Epoch:4 [26|160] loss:0.035711 acc:1.000000\n",
      "Epoch:4 [27|160] loss:0.107608 acc:0.937500\n",
      "Epoch:4 [28|160] loss:0.166773 acc:0.937500\n",
      "Epoch:4 [29|160] loss:0.749845 acc:0.812500\n",
      "Epoch:4 [30|160] loss:0.236765 acc:0.937500\n",
      "Epoch:4 [31|160] loss:0.040880 acc:1.000000\n",
      "Epoch:4 [32|160] loss:0.238329 acc:0.937500\n",
      "Epoch:4 [33|160] loss:0.059253 acc:1.000000\n",
      "Epoch:4 [34|160] loss:0.039994 acc:1.000000\n",
      "Epoch:4 [35|160] loss:0.035742 acc:1.000000\n",
      "Epoch:4 [36|160] loss:0.036788 acc:1.000000\n",
      "Epoch:4 [37|160] loss:0.396864 acc:0.875000\n",
      "Epoch:4 [38|160] loss:0.046223 acc:1.000000\n",
      "Epoch:4 [39|160] loss:0.203199 acc:0.937500\n",
      "Epoch:4 [40|160] loss:0.272112 acc:0.937500\n",
      "Epoch:4 [41|160] loss:0.044468 acc:1.000000\n",
      "Epoch:4 [42|160] loss:0.317482 acc:0.875000\n",
      "Epoch:4 [43|160] loss:0.350997 acc:0.875000\n",
      "Epoch:4 [44|160] loss:0.032149 acc:1.000000\n",
      "Epoch:4 [45|160] loss:0.353000 acc:0.937500\n",
      "Epoch:4 [46|160] loss:0.221071 acc:0.937500\n",
      "Epoch:4 [47|160] loss:0.520062 acc:0.875000\n",
      "Epoch:4 [48|160] loss:0.042841 acc:1.000000\n",
      "Epoch:4 [49|160] loss:0.049202 acc:1.000000\n",
      "Epoch:4 [50|160] loss:0.042794 acc:1.000000\n",
      "Epoch:4 [51|160] loss:0.041086 acc:1.000000\n",
      "Epoch:4 [52|160] loss:0.047087 acc:1.000000\n",
      "Epoch:4 [53|160] loss:0.185105 acc:0.937500\n",
      "Epoch:4 [54|160] loss:0.160178 acc:0.937500\n",
      "Epoch:4 [55|160] loss:0.045828 acc:1.000000\n",
      "Epoch:4 [56|160] loss:0.443128 acc:0.875000\n",
      "Epoch:4 [57|160] loss:0.045621 acc:1.000000\n",
      "Epoch:4 [58|160] loss:0.051102 acc:1.000000\n",
      "Epoch:4 [59|160] loss:0.042461 acc:1.000000\n",
      "Epoch:4 [60|160] loss:0.051260 acc:1.000000\n",
      "Epoch:4 [61|160] loss:0.036783 acc:1.000000\n",
      "Epoch:4 [62|160] loss:0.305403 acc:0.875000\n",
      "Epoch:4 [63|160] loss:0.039990 acc:1.000000\n",
      "Epoch:4 [64|160] loss:0.431943 acc:0.875000\n",
      "Epoch:4 [65|160] loss:0.682837 acc:0.812500\n",
      "Epoch:4 [66|160] loss:0.040805 acc:1.000000\n",
      "Epoch:4 [67|160] loss:0.051540 acc:1.000000\n",
      "Epoch:4 [68|160] loss:0.036690 acc:1.000000\n",
      "Epoch:4 [69|160] loss:0.438370 acc:0.875000\n",
      "Epoch:4 [70|160] loss:0.143631 acc:0.937500\n",
      "Epoch:4 [71|160] loss:0.062878 acc:1.000000\n",
      "Epoch:4 [72|160] loss:0.118584 acc:0.937500\n",
      "Epoch:4 [73|160] loss:0.356250 acc:0.875000\n",
      "Epoch:4 [74|160] loss:0.097893 acc:0.937500\n",
      "Epoch:4 [75|160] loss:0.045691 acc:1.000000\n",
      "Epoch:4 [76|160] loss:0.038779 acc:1.000000\n",
      "Epoch:4 [77|160] loss:0.056446 acc:1.000000\n",
      "Epoch:4 [78|160] loss:0.046117 acc:1.000000\n",
      "Epoch:4 [79|160] loss:0.050901 acc:1.000000\n",
      "Epoch:4 [80|160] loss:0.064353 acc:1.000000\n",
      "Epoch:4 [81|160] loss:0.041639 acc:1.000000\n",
      "Epoch:4 [82|160] loss:0.042989 acc:1.000000\n",
      "Epoch:4 [83|160] loss:0.123147 acc:0.937500\n",
      "Epoch:4 [84|160] loss:0.038053 acc:1.000000\n",
      "Epoch:4 [85|160] loss:0.042920 acc:1.000000\n",
      "Epoch:4 [86|160] loss:0.037069 acc:1.000000\n",
      "Epoch:4 [87|160] loss:0.285843 acc:0.937500\n",
      "Epoch:4 [88|160] loss:0.032377 acc:1.000000\n",
      "Epoch:4 [89|160] loss:0.040230 acc:1.000000\n",
      "Epoch:4 [90|160] loss:0.511433 acc:0.875000\n",
      "Epoch:4 [91|160] loss:0.035578 acc:1.000000\n",
      "Epoch:4 [92|160] loss:0.039163 acc:1.000000\n",
      "Epoch:4 [93|160] loss:0.267036 acc:0.937500\n",
      "Epoch:4 [94|160] loss:0.030716 acc:1.000000\n",
      "Epoch:4 [95|160] loss:0.261510 acc:0.875000\n",
      "Epoch:4 [96|160] loss:0.180958 acc:0.937500\n",
      "Epoch:4 [97|160] loss:0.041748 acc:1.000000\n",
      "Epoch:4 [98|160] loss:0.033462 acc:1.000000\n",
      "Epoch:4 [99|160] loss:0.044042 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 [100|160] loss:0.334250 acc:0.937500\n",
      "Epoch:4 [101|160] loss:0.029573 acc:1.000000\n",
      "Epoch:4 [102|160] loss:0.027427 acc:1.000000\n",
      "Epoch:4 [103|160] loss:0.232132 acc:0.937500\n",
      "Epoch:4 [104|160] loss:0.037458 acc:1.000000\n",
      "Epoch:4 [105|160] loss:0.030318 acc:1.000000\n",
      "Epoch:4 [106|160] loss:0.026197 acc:1.000000\n",
      "Epoch:4 [107|160] loss:0.025568 acc:1.000000\n",
      "Epoch:4 [108|160] loss:0.037354 acc:1.000000\n",
      "Epoch:4 [109|160] loss:0.263037 acc:0.937500\n",
      "Epoch:4 [110|160] loss:0.022697 acc:1.000000\n",
      "Epoch:4 [111|160] loss:0.207889 acc:0.937500\n",
      "Epoch:4 [112|160] loss:0.160752 acc:0.937500\n",
      "Epoch:4 [113|160] loss:0.025889 acc:1.000000\n",
      "Epoch:4 [114|160] loss:0.078402 acc:0.937500\n",
      "Epoch:4 [115|160] loss:0.026145 acc:1.000000\n",
      "Epoch:4 [116|160] loss:0.110150 acc:0.937500\n",
      "Epoch:4 [117|160] loss:0.023457 acc:1.000000\n",
      "Epoch:4 [118|160] loss:0.290358 acc:0.937500\n",
      "Epoch:4 [119|160] loss:0.053802 acc:1.000000\n",
      "Epoch:4 [120|160] loss:0.028343 acc:1.000000\n",
      "Epoch:4 [121|160] loss:0.292856 acc:0.937500\n",
      "Epoch:4 [122|160] loss:0.074673 acc:0.937500\n",
      "Epoch:4 [123|160] loss:0.022640 acc:1.000000\n",
      "Epoch:4 [124|160] loss:0.025545 acc:1.000000\n",
      "Epoch:4 [125|160] loss:0.027617 acc:1.000000\n",
      "Epoch:4 [126|160] loss:0.023753 acc:1.000000\n",
      "Epoch:4 [127|160] loss:0.023377 acc:1.000000\n",
      "Epoch:4 [128|160] loss:0.025393 acc:1.000000\n",
      "Epoch:4 [129|160] loss:0.130259 acc:0.937500\n",
      "Epoch:4 [130|160] loss:0.349083 acc:0.937500\n",
      "Epoch:4 [131|160] loss:0.024184 acc:1.000000\n",
      "Epoch:4 [132|160] loss:0.020692 acc:1.000000\n",
      "Epoch:4 [133|160] loss:0.025346 acc:1.000000\n",
      "Epoch:4 [134|160] loss:0.020810 acc:1.000000\n",
      "Epoch:4 [135|160] loss:0.039884 acc:1.000000\n",
      "Epoch:4 [136|160] loss:0.026522 acc:1.000000\n",
      "Epoch:4 [137|160] loss:0.021611 acc:1.000000\n",
      "Epoch:4 [138|160] loss:0.031177 acc:1.000000\n",
      "Epoch:4 [139|160] loss:0.179558 acc:0.937500\n",
      "Epoch:4 [140|160] loss:0.023870 acc:1.000000\n",
      "Epoch:4 [141|160] loss:0.225764 acc:0.937500\n",
      "Epoch:4 [142|160] loss:0.024043 acc:1.000000\n",
      "Epoch:4 [143|160] loss:0.034865 acc:1.000000\n",
      "Epoch:4 [144|160] loss:0.021478 acc:1.000000\n",
      "Epoch:4 [145|160] loss:0.019988 acc:1.000000\n",
      "Epoch:4 [146|160] loss:0.024814 acc:1.000000\n",
      "Epoch:4 [147|160] loss:0.404925 acc:0.937500\n",
      "Epoch:4 [148|160] loss:0.020356 acc:1.000000\n",
      "Epoch:4 [149|160] loss:0.239956 acc:0.937500\n",
      "Epoch:4 [150|160] loss:0.020764 acc:1.000000\n",
      "Epoch:4 [151|160] loss:0.018914 acc:1.000000\n",
      "Epoch:4 [152|160] loss:0.093222 acc:0.937500\n",
      "Epoch:4 [153|160] loss:0.173921 acc:0.937500\n",
      "Epoch:4 [154|160] loss:0.028364 acc:1.000000\n",
      "Epoch:4 [155|160] loss:0.018772 acc:1.000000\n",
      "Epoch:4 [156|160] loss:0.020938 acc:1.000000\n",
      "Epoch:4 [157|160] loss:0.025462 acc:1.000000\n",
      "Epoch:4 [158|160] loss:0.250227 acc:0.937500\n",
      "Epoch:4 [159|160] loss:0.147309 acc:0.916667\n",
      "\n",
      "Validation Epoch: 4\n",
      "Acc: 0.978091 \n",
      "\n",
      "Epoch: 5\n",
      "Epoch:5 [0|160] loss:0.060268 acc:1.000000\n",
      "Epoch:5 [1|160] loss:0.022175 acc:1.000000\n",
      "Epoch:5 [2|160] loss:0.067713 acc:0.937500\n",
      "Epoch:5 [3|160] loss:0.111356 acc:0.937500\n",
      "Epoch:5 [4|160] loss:0.334699 acc:0.937500\n",
      "Epoch:5 [5|160] loss:0.027105 acc:1.000000\n",
      "Epoch:5 [6|160] loss:0.019018 acc:1.000000\n",
      "Epoch:5 [7|160] loss:0.298137 acc:0.937500\n",
      "Epoch:5 [8|160] loss:0.231553 acc:0.937500\n",
      "Epoch:5 [9|160] loss:0.314346 acc:0.875000\n",
      "Epoch:5 [10|160] loss:0.018013 acc:1.000000\n",
      "Epoch:5 [11|160] loss:0.020435 acc:1.000000\n",
      "Epoch:5 [12|160] loss:0.024864 acc:1.000000\n",
      "Epoch:5 [13|160] loss:0.018281 acc:1.000000\n",
      "Epoch:5 [14|160] loss:0.052384 acc:1.000000\n",
      "Epoch:5 [15|160] loss:0.081369 acc:0.937500\n",
      "Epoch:5 [16|160] loss:0.064390 acc:1.000000\n",
      "Epoch:5 [17|160] loss:0.017055 acc:1.000000\n",
      "Epoch:5 [18|160] loss:0.030446 acc:1.000000\n",
      "Epoch:5 [19|160] loss:0.061740 acc:0.937500\n",
      "Epoch:5 [20|160] loss:0.025392 acc:1.000000\n",
      "Epoch:5 [21|160] loss:0.022982 acc:1.000000\n",
      "Epoch:5 [22|160] loss:0.016853 acc:1.000000\n",
      "Epoch:5 [23|160] loss:0.022051 acc:1.000000\n",
      "Epoch:5 [24|160] loss:0.020869 acc:1.000000\n",
      "Epoch:5 [25|160] loss:0.035428 acc:1.000000\n",
      "Epoch:5 [26|160] loss:0.248121 acc:0.937500\n",
      "Epoch:5 [27|160] loss:0.019789 acc:1.000000\n",
      "Epoch:5 [28|160] loss:0.210712 acc:0.937500\n",
      "Epoch:5 [29|160] loss:0.338084 acc:0.937500\n",
      "Epoch:5 [30|160] loss:0.028767 acc:1.000000\n",
      "Epoch:5 [31|160] loss:0.022097 acc:1.000000\n",
      "Epoch:5 [32|160] loss:0.176445 acc:0.937500\n",
      "Epoch:5 [33|160] loss:0.025714 acc:1.000000\n",
      "Epoch:5 [34|160] loss:0.039373 acc:1.000000\n",
      "Epoch:5 [35|160] loss:0.161387 acc:0.937500\n",
      "Epoch:5 [36|160] loss:0.025789 acc:1.000000\n",
      "Epoch:5 [37|160] loss:0.051720 acc:1.000000\n",
      "Epoch:5 [38|160] loss:0.034175 acc:1.000000\n",
      "Epoch:5 [39|160] loss:0.022707 acc:1.000000\n",
      "Epoch:5 [40|160] loss:0.043732 acc:1.000000\n",
      "Epoch:5 [41|160] loss:0.035759 acc:1.000000\n",
      "Epoch:5 [42|160] loss:0.044971 acc:1.000000\n",
      "Epoch:5 [43|160] loss:0.022607 acc:1.000000\n",
      "Epoch:5 [44|160] loss:0.049771 acc:1.000000\n",
      "Epoch:5 [45|160] loss:0.060294 acc:0.937500\n",
      "Epoch:5 [46|160] loss:0.018157 acc:1.000000\n",
      "Epoch:5 [47|160] loss:0.022461 acc:1.000000\n",
      "Epoch:5 [48|160] loss:0.302480 acc:0.937500\n",
      "Epoch:5 [49|160] loss:0.220979 acc:0.937500\n",
      "Epoch:5 [50|160] loss:0.018340 acc:1.000000\n",
      "Epoch:5 [51|160] loss:0.200787 acc:0.937500\n",
      "Epoch:5 [52|160] loss:0.297600 acc:0.937500\n",
      "Epoch:5 [53|160] loss:0.272271 acc:0.937500\n",
      "Epoch:5 [54|160] loss:0.018322 acc:1.000000\n",
      "Epoch:5 [55|160] loss:0.024829 acc:1.000000\n",
      "Epoch:5 [56|160] loss:0.022480 acc:1.000000\n",
      "Epoch:5 [57|160] loss:0.088210 acc:0.937500\n",
      "Epoch:5 [58|160] loss:0.020917 acc:1.000000\n",
      "Epoch:5 [59|160] loss:0.020779 acc:1.000000\n",
      "Epoch:5 [60|160] loss:0.022206 acc:1.000000\n",
      "Epoch:5 [61|160] loss:0.024123 acc:1.000000\n",
      "Epoch:5 [62|160] loss:0.028458 acc:1.000000\n",
      "Epoch:5 [63|160] loss:0.127213 acc:0.937500\n",
      "Epoch:5 [64|160] loss:0.573444 acc:0.812500\n",
      "Epoch:5 [65|160] loss:0.017484 acc:1.000000\n",
      "Epoch:5 [66|160] loss:0.421968 acc:0.875000\n",
      "Epoch:5 [67|160] loss:0.026661 acc:1.000000\n",
      "Epoch:5 [68|160] loss:0.241803 acc:0.937500\n",
      "Epoch:5 [69|160] loss:0.315268 acc:0.937500\n",
      "Epoch:5 [70|160] loss:0.234135 acc:0.937500\n",
      "Epoch:5 [71|160] loss:0.032678 acc:1.000000\n",
      "Epoch:5 [72|160] loss:0.111057 acc:0.937500\n",
      "Epoch:5 [73|160] loss:0.032565 acc:1.000000\n",
      "Epoch:5 [74|160] loss:0.227608 acc:0.937500\n",
      "Epoch:5 [75|160] loss:0.139531 acc:0.937500\n",
      "Epoch:5 [76|160] loss:0.024441 acc:1.000000\n",
      "Epoch:5 [77|160] loss:0.032755 acc:1.000000\n",
      "Epoch:5 [78|160] loss:0.029306 acc:1.000000\n",
      "Epoch:5 [79|160] loss:0.269183 acc:0.937500\n",
      "Epoch:5 [80|160] loss:0.191561 acc:0.937500\n",
      "Epoch:5 [81|160] loss:0.028497 acc:1.000000\n",
      "Epoch:5 [82|160] loss:0.403791 acc:0.875000\n",
      "Epoch:5 [83|160] loss:0.048909 acc:1.000000\n",
      "Epoch:5 [84|160] loss:0.036173 acc:1.000000\n",
      "Epoch:5 [85|160] loss:0.017625 acc:1.000000\n",
      "Epoch:5 [86|160] loss:0.116284 acc:0.937500\n",
      "Epoch:5 [87|160] loss:0.284409 acc:0.875000\n",
      "Epoch:5 [88|160] loss:0.263734 acc:0.937500\n",
      "Epoch:5 [89|160] loss:0.142572 acc:0.937500\n",
      "Epoch:5 [90|160] loss:0.145923 acc:0.937500\n",
      "Epoch:5 [91|160] loss:0.039647 acc:1.000000\n",
      "Epoch:5 [92|160] loss:0.030900 acc:1.000000\n",
      "Epoch:5 [93|160] loss:0.046173 acc:1.000000\n",
      "Epoch:5 [94|160] loss:0.147528 acc:0.937500\n",
      "Epoch:5 [95|160] loss:0.162767 acc:0.937500\n",
      "Epoch:5 [96|160] loss:0.105608 acc:0.937500\n",
      "Epoch:5 [97|160] loss:0.040004 acc:1.000000\n",
      "Epoch:5 [98|160] loss:0.028146 acc:1.000000\n",
      "Epoch:5 [99|160] loss:0.053691 acc:1.000000\n",
      "Epoch:5 [100|160] loss:0.034479 acc:1.000000\n",
      "Epoch:5 [101|160] loss:0.248787 acc:0.937500\n",
      "Epoch:5 [102|160] loss:0.296904 acc:0.937500\n",
      "Epoch:5 [103|160] loss:0.298853 acc:0.875000\n",
      "Epoch:5 [104|160] loss:0.035212 acc:1.000000\n",
      "Epoch:5 [105|160] loss:0.346723 acc:0.875000\n",
      "Epoch:5 [106|160] loss:0.030018 acc:1.000000\n",
      "Epoch:5 [107|160] loss:0.062690 acc:1.000000\n",
      "Epoch:5 [108|160] loss:0.056388 acc:1.000000\n",
      "Epoch:5 [109|160] loss:0.027254 acc:1.000000\n",
      "Epoch:5 [110|160] loss:0.029649 acc:1.000000\n",
      "Epoch:5 [111|160] loss:0.026075 acc:1.000000\n",
      "Epoch:5 [112|160] loss:0.321977 acc:0.937500\n",
      "Epoch:5 [113|160] loss:0.154269 acc:0.937500\n",
      "Epoch:5 [114|160] loss:0.155945 acc:0.937500\n",
      "Epoch:5 [115|160] loss:0.036037 acc:1.000000\n",
      "Epoch:5 [116|160] loss:0.089513 acc:0.937500\n",
      "Epoch:5 [117|160] loss:0.085687 acc:0.937500\n",
      "Epoch:5 [118|160] loss:0.041017 acc:1.000000\n",
      "Epoch:5 [119|160] loss:0.068744 acc:1.000000\n",
      "Epoch:5 [120|160] loss:0.214515 acc:0.937500\n",
      "Epoch:5 [121|160] loss:0.047937 acc:1.000000\n",
      "Epoch:5 [122|160] loss:0.027369 acc:1.000000\n",
      "Epoch:5 [123|160] loss:0.031775 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5 [124|160] loss:0.198822 acc:0.937500\n",
      "Epoch:5 [125|160] loss:0.282783 acc:0.937500\n",
      "Epoch:5 [126|160] loss:0.240042 acc:0.937500\n",
      "Epoch:5 [127|160] loss:0.084421 acc:1.000000\n",
      "Epoch:5 [128|160] loss:0.033121 acc:1.000000\n",
      "Epoch:5 [129|160] loss:0.018051 acc:1.000000\n",
      "Epoch:5 [130|160] loss:0.028907 acc:1.000000\n",
      "Epoch:5 [131|160] loss:0.388883 acc:0.937500\n",
      "Epoch:5 [132|160] loss:0.325399 acc:0.937500\n",
      "Epoch:5 [133|160] loss:0.024987 acc:1.000000\n",
      "Epoch:5 [134|160] loss:0.019921 acc:1.000000\n",
      "Epoch:5 [135|160] loss:0.363078 acc:0.937500\n",
      "Epoch:5 [136|160] loss:0.049547 acc:1.000000\n",
      "Epoch:5 [137|160] loss:0.029779 acc:1.000000\n",
      "Epoch:5 [138|160] loss:0.038758 acc:1.000000\n",
      "Epoch:5 [139|160] loss:0.023361 acc:1.000000\n",
      "Epoch:5 [140|160] loss:0.027204 acc:1.000000\n",
      "Epoch:5 [141|160] loss:0.022423 acc:1.000000\n",
      "Epoch:5 [142|160] loss:0.512216 acc:0.875000\n",
      "Epoch:5 [143|160] loss:0.020993 acc:1.000000\n",
      "Epoch:5 [144|160] loss:0.265988 acc:0.875000\n",
      "Epoch:5 [145|160] loss:0.353521 acc:0.937500\n",
      "Epoch:5 [146|160] loss:0.023504 acc:1.000000\n",
      "Epoch:5 [147|160] loss:0.025620 acc:1.000000\n",
      "Epoch:5 [148|160] loss:0.456851 acc:0.875000\n",
      "Epoch:5 [149|160] loss:0.043350 acc:1.000000\n",
      "Epoch:5 [150|160] loss:0.343636 acc:0.875000\n",
      "Epoch:5 [151|160] loss:0.031550 acc:1.000000\n",
      "Epoch:5 [152|160] loss:0.026603 acc:1.000000\n",
      "Epoch:5 [153|160] loss:0.025940 acc:1.000000\n",
      "Epoch:5 [154|160] loss:0.039413 acc:1.000000\n",
      "Epoch:5 [155|160] loss:0.281730 acc:0.937500\n",
      "Epoch:5 [156|160] loss:0.196547 acc:0.937500\n",
      "Epoch:5 [157|160] loss:0.173036 acc:0.937500\n",
      "Epoch:5 [158|160] loss:0.024853 acc:1.000000\n",
      "Epoch:5 [159|160] loss:0.035852 acc:1.000000\n",
      "\n",
      "Validation Epoch: 5\n",
      "Acc: 0.974961 \n",
      "\n",
      "Epoch: 6\n",
      "Epoch:6 [0|160] loss:0.029330 acc:1.000000\n",
      "Epoch:6 [1|160] loss:0.146468 acc:0.937500\n",
      "Epoch:6 [2|160] loss:0.491217 acc:0.875000\n",
      "Epoch:6 [3|160] loss:0.021056 acc:1.000000\n",
      "Epoch:6 [4|160] loss:0.110168 acc:0.937500\n",
      "Epoch:6 [5|160] loss:0.038122 acc:1.000000\n",
      "Epoch:6 [6|160] loss:0.041942 acc:1.000000\n",
      "Epoch:6 [7|160] loss:0.037794 acc:1.000000\n",
      "Epoch:6 [8|160] loss:0.043442 acc:1.000000\n",
      "Epoch:6 [9|160] loss:0.038222 acc:1.000000\n",
      "Epoch:6 [10|160] loss:0.131611 acc:0.937500\n",
      "Epoch:6 [11|160] loss:0.023548 acc:1.000000\n",
      "Epoch:6 [12|160] loss:0.037486 acc:1.000000\n",
      "Epoch:6 [13|160] loss:0.031735 acc:1.000000\n",
      "Epoch:6 [14|160] loss:0.036869 acc:1.000000\n",
      "Epoch:6 [15|160] loss:0.142068 acc:0.937500\n",
      "Epoch:6 [16|160] loss:0.028172 acc:1.000000\n",
      "Epoch:6 [17|160] loss:0.203706 acc:0.937500\n",
      "Epoch:6 [18|160] loss:0.028141 acc:1.000000\n",
      "Epoch:6 [19|160] loss:0.182913 acc:0.937500\n",
      "Epoch:6 [20|160] loss:0.033113 acc:1.000000\n",
      "Epoch:6 [21|160] loss:0.030547 acc:1.000000\n",
      "Epoch:6 [22|160] loss:0.022142 acc:1.000000\n",
      "Epoch:6 [23|160] loss:0.025091 acc:1.000000\n",
      "Epoch:6 [24|160] loss:0.021445 acc:1.000000\n",
      "Epoch:6 [25|160] loss:0.016813 acc:1.000000\n",
      "Epoch:6 [26|160] loss:0.021106 acc:1.000000\n",
      "Epoch:6 [27|160] loss:0.017201 acc:1.000000\n",
      "Epoch:6 [28|160] loss:0.020092 acc:1.000000\n",
      "Epoch:6 [29|160] loss:0.200884 acc:0.937500\n",
      "Epoch:6 [30|160] loss:0.308929 acc:0.875000\n",
      "Epoch:6 [31|160] loss:0.021964 acc:1.000000\n",
      "Epoch:6 [32|160] loss:0.026195 acc:1.000000\n",
      "Epoch:6 [33|160] loss:0.177824 acc:0.937500\n",
      "Epoch:6 [34|160] loss:0.026350 acc:1.000000\n",
      "Epoch:6 [35|160] loss:0.019711 acc:1.000000\n",
      "Epoch:6 [36|160] loss:0.022043 acc:1.000000\n",
      "Epoch:6 [37|160] loss:0.018014 acc:1.000000\n",
      "Epoch:6 [38|160] loss:0.015782 acc:1.000000\n",
      "Epoch:6 [39|160] loss:0.208304 acc:0.937500\n",
      "Epoch:6 [40|160] loss:0.017548 acc:1.000000\n",
      "Epoch:6 [41|160] loss:0.023441 acc:1.000000\n",
      "Epoch:6 [42|160] loss:0.019088 acc:1.000000\n",
      "Epoch:6 [43|160] loss:0.016563 acc:1.000000\n",
      "Epoch:6 [44|160] loss:0.021347 acc:1.000000\n",
      "Epoch:6 [45|160] loss:0.020299 acc:1.000000\n",
      "Epoch:6 [46|160] loss:0.017684 acc:1.000000\n",
      "Epoch:6 [47|160] loss:0.021259 acc:1.000000\n",
      "Epoch:6 [48|160] loss:0.169877 acc:0.937500\n",
      "Epoch:6 [49|160] loss:0.019001 acc:1.000000\n",
      "Epoch:6 [50|160] loss:0.131699 acc:0.937500\n",
      "Epoch:6 [51|160] loss:0.250101 acc:0.937500\n",
      "Epoch:6 [52|160] loss:0.017957 acc:1.000000\n",
      "Epoch:6 [53|160] loss:0.025945 acc:1.000000\n",
      "Epoch:6 [54|160] loss:0.019847 acc:1.000000\n",
      "Epoch:6 [55|160] loss:0.018945 acc:1.000000\n",
      "Epoch:6 [56|160] loss:0.018283 acc:1.000000\n",
      "Epoch:6 [57|160] loss:0.375177 acc:0.937500\n",
      "Epoch:6 [58|160] loss:0.200487 acc:0.937500\n",
      "Epoch:6 [59|160] loss:0.019810 acc:1.000000\n",
      "Epoch:6 [60|160] loss:0.014766 acc:1.000000\n",
      "Epoch:6 [61|160] loss:0.014511 acc:1.000000\n",
      "Epoch:6 [62|160] loss:0.699717 acc:0.750000\n",
      "Epoch:6 [63|160] loss:0.170395 acc:0.937500\n",
      "Epoch:6 [64|160] loss:0.245064 acc:0.875000\n",
      "Epoch:6 [65|160] loss:0.018774 acc:1.000000\n",
      "Epoch:6 [66|160] loss:0.018820 acc:1.000000\n",
      "Epoch:6 [67|160] loss:0.020781 acc:1.000000\n",
      "Epoch:6 [68|160] loss:0.320098 acc:0.937500\n",
      "Epoch:6 [69|160] loss:0.022077 acc:1.000000\n",
      "Epoch:6 [70|160] loss:0.032707 acc:1.000000\n",
      "Epoch:6 [71|160] loss:0.036784 acc:1.000000\n",
      "Epoch:6 [72|160] loss:0.038059 acc:1.000000\n",
      "Epoch:6 [73|160] loss:0.024549 acc:1.000000\n",
      "Epoch:6 [74|160] loss:0.190971 acc:0.875000\n",
      "Epoch:6 [75|160] loss:0.024270 acc:1.000000\n",
      "Epoch:6 [76|160] loss:0.100235 acc:0.937500\n",
      "Epoch:6 [77|160] loss:0.025462 acc:1.000000\n",
      "Epoch:6 [78|160] loss:0.020881 acc:1.000000\n",
      "Epoch:6 [79|160] loss:0.221252 acc:0.937500\n",
      "Epoch:6 [80|160] loss:0.211718 acc:0.937500\n",
      "Epoch:6 [81|160] loss:0.197805 acc:0.937500\n",
      "Epoch:6 [82|160] loss:0.220870 acc:0.937500\n",
      "Epoch:6 [83|160] loss:0.329483 acc:0.937500\n",
      "Epoch:6 [84|160] loss:0.021194 acc:1.000000\n",
      "Epoch:6 [85|160] loss:0.034882 acc:1.000000\n",
      "Epoch:6 [86|160] loss:0.048265 acc:1.000000\n",
      "Epoch:6 [87|160] loss:0.051522 acc:1.000000\n",
      "Epoch:6 [88|160] loss:0.015987 acc:1.000000\n",
      "Epoch:6 [89|160] loss:0.031783 acc:1.000000\n",
      "Epoch:6 [90|160] loss:0.019364 acc:1.000000\n",
      "Epoch:6 [91|160] loss:0.025136 acc:1.000000\n",
      "Epoch:6 [92|160] loss:0.029516 acc:1.000000\n",
      "Epoch:6 [93|160] loss:0.185172 acc:0.937500\n",
      "Epoch:6 [94|160] loss:0.181321 acc:0.937500\n",
      "Epoch:6 [95|160] loss:0.017982 acc:1.000000\n",
      "Epoch:6 [96|160] loss:0.142848 acc:0.937500\n",
      "Epoch:6 [97|160] loss:0.028415 acc:1.000000\n",
      "Epoch:6 [98|160] loss:0.064528 acc:0.937500\n",
      "Epoch:6 [99|160] loss:0.020476 acc:1.000000\n",
      "Epoch:6 [100|160] loss:0.151995 acc:0.937500\n",
      "Epoch:6 [101|160] loss:0.205001 acc:0.875000\n",
      "Epoch:6 [102|160] loss:0.316210 acc:0.937500\n",
      "Epoch:6 [103|160] loss:0.014087 acc:1.000000\n",
      "Epoch:6 [104|160] loss:0.033293 acc:1.000000\n",
      "Epoch:6 [105|160] loss:0.050728 acc:1.000000\n",
      "Epoch:6 [106|160] loss:0.040061 acc:1.000000\n",
      "Epoch:6 [107|160] loss:0.210850 acc:0.937500\n",
      "Epoch:6 [108|160] loss:0.267966 acc:0.937500\n",
      "Epoch:6 [109|160] loss:0.048185 acc:1.000000\n",
      "Epoch:6 [110|160] loss:0.089057 acc:0.937500\n",
      "Epoch:6 [111|160] loss:0.019725 acc:1.000000\n",
      "Epoch:6 [112|160] loss:0.024627 acc:1.000000\n",
      "Epoch:6 [113|160] loss:0.068980 acc:1.000000\n",
      "Epoch:6 [114|160] loss:0.213238 acc:0.937500\n",
      "Epoch:6 [115|160] loss:0.021948 acc:1.000000\n",
      "Epoch:6 [116|160] loss:0.031396 acc:1.000000\n",
      "Epoch:6 [117|160] loss:0.125713 acc:0.937500\n",
      "Epoch:6 [118|160] loss:0.025700 acc:1.000000\n",
      "Epoch:6 [119|160] loss:0.119118 acc:0.937500\n",
      "Epoch:6 [120|160] loss:0.021929 acc:1.000000\n",
      "Epoch:6 [121|160] loss:0.029773 acc:1.000000\n",
      "Epoch:6 [122|160] loss:0.182352 acc:0.937500\n",
      "Epoch:6 [123|160] loss:0.184364 acc:0.937500\n",
      "Epoch:6 [124|160] loss:0.231627 acc:0.937500\n",
      "Epoch:6 [125|160] loss:0.034875 acc:1.000000\n",
      "Epoch:6 [126|160] loss:0.021977 acc:1.000000\n",
      "Epoch:6 [127|160] loss:0.020528 acc:1.000000\n",
      "Epoch:6 [128|160] loss:0.018389 acc:1.000000\n",
      "Epoch:6 [129|160] loss:0.024702 acc:1.000000\n",
      "Epoch:6 [130|160] loss:0.017092 acc:1.000000\n",
      "Epoch:6 [131|160] loss:0.211053 acc:0.937500\n",
      "Epoch:6 [132|160] loss:0.019686 acc:1.000000\n",
      "Epoch:6 [133|160] loss:0.021035 acc:1.000000\n",
      "Epoch:6 [134|160] loss:0.102413 acc:0.937500\n",
      "Epoch:6 [135|160] loss:0.197703 acc:0.937500\n",
      "Epoch:6 [136|160] loss:0.024483 acc:1.000000\n",
      "Epoch:6 [137|160] loss:0.258079 acc:0.937500\n",
      "Epoch:6 [138|160] loss:0.024417 acc:1.000000\n",
      "Epoch:6 [139|160] loss:0.023945 acc:1.000000\n",
      "Epoch:6 [140|160] loss:0.018822 acc:1.000000\n",
      "Epoch:6 [141|160] loss:0.302049 acc:0.875000\n",
      "Epoch:6 [142|160] loss:0.020949 acc:1.000000\n",
      "Epoch:6 [143|160] loss:0.214743 acc:0.875000\n",
      "Epoch:6 [144|160] loss:0.190176 acc:0.937500\n",
      "Epoch:6 [145|160] loss:0.176835 acc:0.937500\n",
      "Epoch:6 [146|160] loss:0.323367 acc:0.937500\n",
      "Epoch:6 [147|160] loss:0.536669 acc:0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6 [148|160] loss:0.191812 acc:0.937500\n",
      "Epoch:6 [149|160] loss:0.241805 acc:0.937500\n",
      "Epoch:6 [150|160] loss:0.380401 acc:0.875000\n",
      "Epoch:6 [151|160] loss:0.120420 acc:0.937500\n",
      "Epoch:6 [152|160] loss:0.022403 acc:1.000000\n",
      "Epoch:6 [153|160] loss:0.026113 acc:1.000000\n",
      "Epoch:6 [154|160] loss:0.044236 acc:1.000000\n",
      "Epoch:6 [155|160] loss:0.094823 acc:0.937500\n",
      "Epoch:6 [156|160] loss:0.042930 acc:1.000000\n",
      "Epoch:6 [157|160] loss:0.377687 acc:0.875000\n",
      "Epoch:6 [158|160] loss:0.153733 acc:0.875000\n",
      "Epoch:6 [159|160] loss:0.047745 acc:1.000000\n",
      "\n",
      "Validation Epoch: 6\n",
      "Acc: 0.956182 \n",
      "\n",
      "Epoch: 7\n",
      "Epoch:7 [0|160] loss:0.372273 acc:0.875000\n",
      "Epoch:7 [1|160] loss:0.088287 acc:0.937500\n",
      "Epoch:7 [2|160] loss:0.068868 acc:1.000000\n",
      "Epoch:7 [3|160] loss:0.141231 acc:0.937500\n",
      "Epoch:7 [4|160] loss:0.567156 acc:0.750000\n",
      "Epoch:7 [5|160] loss:0.277508 acc:0.937500\n",
      "Epoch:7 [6|160] loss:0.111201 acc:0.937500\n",
      "Epoch:7 [7|160] loss:0.535020 acc:0.875000\n",
      "Epoch:7 [8|160] loss:0.045546 acc:1.000000\n",
      "Epoch:7 [9|160] loss:0.218053 acc:0.875000\n",
      "Epoch:7 [10|160] loss:0.034959 acc:1.000000\n",
      "Epoch:7 [11|160] loss:0.041493 acc:1.000000\n",
      "Epoch:7 [12|160] loss:0.171602 acc:0.875000\n",
      "Epoch:7 [13|160] loss:0.045304 acc:1.000000\n",
      "Epoch:7 [14|160] loss:0.018966 acc:1.000000\n",
      "Epoch:7 [15|160] loss:0.049644 acc:1.000000\n",
      "Epoch:7 [16|160] loss:0.051523 acc:1.000000\n",
      "Epoch:7 [17|160] loss:0.063373 acc:1.000000\n",
      "Epoch:7 [18|160] loss:0.050128 acc:1.000000\n",
      "Epoch:7 [19|160] loss:0.055969 acc:1.000000\n",
      "Epoch:7 [20|160] loss:0.166365 acc:0.937500\n",
      "Epoch:7 [21|160] loss:0.120552 acc:0.937500\n",
      "Epoch:7 [22|160] loss:0.266971 acc:0.937500\n",
      "Epoch:7 [23|160] loss:0.031517 acc:1.000000\n",
      "Epoch:7 [24|160] loss:0.048962 acc:1.000000\n",
      "Epoch:7 [25|160] loss:0.146061 acc:0.937500\n",
      "Epoch:7 [26|160] loss:0.075323 acc:1.000000\n",
      "Epoch:7 [27|160] loss:0.155875 acc:0.937500\n",
      "Epoch:7 [28|160] loss:0.177724 acc:0.937500\n",
      "Epoch:7 [29|160] loss:0.036685 acc:1.000000\n",
      "Epoch:7 [30|160] loss:0.338011 acc:0.875000\n",
      "Epoch:7 [31|160] loss:0.189984 acc:0.937500\n",
      "Epoch:7 [32|160] loss:0.028732 acc:1.000000\n",
      "Epoch:7 [33|160] loss:0.062816 acc:1.000000\n",
      "Epoch:7 [34|160] loss:0.051695 acc:1.000000\n",
      "Epoch:7 [35|160] loss:0.043470 acc:1.000000\n",
      "Epoch:7 [36|160] loss:0.028672 acc:1.000000\n",
      "Epoch:7 [37|160] loss:0.030885 acc:1.000000\n",
      "Epoch:7 [38|160] loss:0.017243 acc:1.000000\n",
      "Epoch:7 [39|160] loss:0.022504 acc:1.000000\n",
      "Epoch:7 [40|160] loss:0.195920 acc:0.875000\n",
      "Epoch:7 [41|160] loss:0.029364 acc:1.000000\n",
      "Epoch:7 [42|160] loss:0.018681 acc:1.000000\n",
      "Epoch:7 [43|160] loss:0.033999 acc:1.000000\n",
      "Epoch:7 [44|160] loss:0.026112 acc:1.000000\n",
      "Epoch:7 [45|160] loss:0.025117 acc:1.000000\n",
      "Epoch:7 [46|160] loss:0.025314 acc:1.000000\n",
      "Epoch:7 [47|160] loss:0.141579 acc:0.937500\n",
      "Epoch:7 [48|160] loss:0.022196 acc:1.000000\n",
      "Epoch:7 [49|160] loss:0.117084 acc:0.937500\n",
      "Epoch:7 [50|160] loss:0.021742 acc:1.000000\n",
      "Epoch:7 [51|160] loss:0.022807 acc:1.000000\n",
      "Epoch:7 [52|160] loss:0.014666 acc:1.000000\n",
      "Epoch:7 [53|160] loss:0.017123 acc:1.000000\n",
      "Epoch:7 [54|160] loss:0.049797 acc:1.000000\n",
      "Epoch:7 [55|160] loss:0.042439 acc:1.000000\n",
      "Epoch:7 [56|160] loss:0.018470 acc:1.000000\n",
      "Epoch:7 [57|160] loss:0.028309 acc:1.000000\n",
      "Epoch:7 [58|160] loss:0.134107 acc:0.937500\n",
      "Epoch:7 [59|160] loss:0.049407 acc:1.000000\n",
      "Epoch:7 [60|160] loss:0.018328 acc:1.000000\n",
      "Epoch:7 [61|160] loss:0.160362 acc:0.937500\n",
      "Epoch:7 [62|160] loss:0.342198 acc:0.875000\n",
      "Epoch:7 [63|160] loss:0.016251 acc:1.000000\n",
      "Epoch:7 [64|160] loss:0.017910 acc:1.000000\n",
      "Epoch:7 [65|160] loss:0.297158 acc:0.937500\n",
      "Epoch:7 [66|160] loss:0.021737 acc:1.000000\n",
      "Epoch:7 [67|160] loss:0.019383 acc:1.000000\n",
      "Epoch:7 [68|160] loss:0.024123 acc:1.000000\n",
      "Epoch:7 [69|160] loss:0.149787 acc:0.937500\n",
      "Epoch:7 [70|160] loss:0.028299 acc:1.000000\n",
      "Epoch:7 [71|160] loss:0.254703 acc:0.875000\n",
      "Epoch:7 [72|160] loss:0.060844 acc:1.000000\n",
      "Epoch:7 [73|160] loss:0.239212 acc:0.937500\n",
      "Epoch:7 [74|160] loss:0.022839 acc:1.000000\n",
      "Epoch:7 [75|160] loss:0.018723 acc:1.000000\n",
      "Epoch:7 [76|160] loss:0.026291 acc:1.000000\n",
      "Epoch:7 [77|160] loss:0.015295 acc:1.000000\n",
      "Epoch:7 [78|160] loss:0.033982 acc:1.000000\n",
      "Epoch:7 [79|160] loss:0.047240 acc:1.000000\n",
      "Epoch:7 [80|160] loss:0.024702 acc:1.000000\n",
      "Epoch:7 [81|160] loss:0.042282 acc:1.000000\n",
      "Epoch:7 [82|160] loss:0.047094 acc:1.000000\n",
      "Epoch:7 [83|160] loss:0.160605 acc:0.937500\n",
      "Epoch:7 [84|160] loss:0.023088 acc:1.000000\n",
      "Epoch:7 [85|160] loss:0.019303 acc:1.000000\n",
      "Epoch:7 [86|160] loss:0.079971 acc:0.937500\n",
      "Epoch:7 [87|160] loss:0.015937 acc:1.000000\n",
      "Epoch:7 [88|160] loss:0.532881 acc:0.812500\n",
      "Epoch:7 [89|160] loss:0.054833 acc:1.000000\n",
      "Epoch:7 [90|160] loss:0.016152 acc:1.000000\n",
      "Epoch:7 [91|160] loss:0.143503 acc:0.937500\n",
      "Epoch:7 [92|160] loss:0.021875 acc:1.000000\n",
      "Epoch:7 [93|160] loss:0.023564 acc:1.000000\n",
      "Epoch:7 [94|160] loss:0.046702 acc:1.000000\n",
      "Epoch:7 [95|160] loss:0.016452 acc:1.000000\n",
      "Epoch:7 [96|160] loss:0.066629 acc:1.000000\n",
      "Epoch:7 [97|160] loss:0.120450 acc:0.937500\n",
      "Epoch:7 [98|160] loss:0.014826 acc:1.000000\n",
      "Epoch:7 [99|160] loss:0.022290 acc:1.000000\n",
      "Epoch:7 [100|160] loss:0.015857 acc:1.000000\n",
      "Epoch:7 [101|160] loss:0.028313 acc:1.000000\n",
      "Epoch:7 [102|160] loss:0.235634 acc:0.937500\n",
      "Epoch:7 [103|160] loss:0.022633 acc:1.000000\n",
      "Epoch:7 [104|160] loss:0.016097 acc:1.000000\n",
      "Epoch:7 [105|160] loss:0.014960 acc:1.000000\n",
      "Epoch:7 [106|160] loss:0.220236 acc:0.937500\n",
      "Epoch:7 [107|160] loss:0.231296 acc:0.937500\n",
      "Epoch:7 [108|160] loss:0.026884 acc:1.000000\n",
      "Epoch:7 [109|160] loss:0.016875 acc:1.000000\n",
      "Epoch:7 [110|160] loss:0.012772 acc:1.000000\n",
      "Epoch:7 [111|160] loss:0.027789 acc:1.000000\n",
      "Epoch:7 [112|160] loss:0.034027 acc:1.000000\n",
      "Epoch:7 [113|160] loss:0.021665 acc:1.000000\n",
      "Epoch:7 [114|160] loss:0.132228 acc:0.937500\n",
      "Epoch:7 [115|160] loss:0.025915 acc:1.000000\n",
      "Epoch:7 [116|160] loss:0.187078 acc:0.875000\n",
      "Epoch:7 [117|160] loss:0.319327 acc:0.937500\n",
      "Epoch:7 [118|160] loss:0.136246 acc:0.937500\n",
      "Epoch:7 [119|160] loss:0.186916 acc:0.937500\n",
      "Epoch:7 [120|160] loss:0.030731 acc:1.000000\n",
      "Epoch:7 [121|160] loss:0.017443 acc:1.000000\n",
      "Epoch:7 [122|160] loss:0.018897 acc:1.000000\n",
      "Epoch:7 [123|160] loss:0.047908 acc:1.000000\n",
      "Epoch:7 [124|160] loss:0.034223 acc:1.000000\n",
      "Epoch:7 [125|160] loss:0.123243 acc:0.937500\n",
      "Epoch:7 [126|160] loss:0.015534 acc:1.000000\n",
      "Epoch:7 [127|160] loss:0.226303 acc:0.937500\n",
      "Epoch:7 [128|160] loss:0.347198 acc:0.937500\n",
      "Epoch:7 [129|160] loss:0.364116 acc:0.875000\n",
      "Epoch:7 [130|160] loss:0.022429 acc:1.000000\n",
      "Epoch:7 [131|160] loss:0.052690 acc:1.000000\n",
      "Epoch:7 [132|160] loss:0.167217 acc:0.937500\n",
      "Epoch:7 [133|160] loss:0.011544 acc:1.000000\n",
      "Epoch:7 [134|160] loss:0.016632 acc:1.000000\n",
      "Epoch:7 [135|160] loss:0.022109 acc:1.000000\n",
      "Epoch:7 [136|160] loss:0.048541 acc:1.000000\n",
      "Epoch:7 [137|160] loss:0.022874 acc:1.000000\n",
      "Epoch:7 [138|160] loss:0.064540 acc:1.000000\n",
      "Epoch:7 [139|160] loss:0.413817 acc:0.937500\n",
      "Epoch:7 [140|160] loss:0.051712 acc:1.000000\n",
      "Epoch:7 [141|160] loss:0.015707 acc:1.000000\n",
      "Epoch:7 [142|160] loss:0.402914 acc:0.812500\n",
      "Epoch:7 [143|160] loss:0.022618 acc:1.000000\n",
      "Epoch:7 [144|160] loss:0.025243 acc:1.000000\n",
      "Epoch:7 [145|160] loss:0.032023 acc:1.000000\n",
      "Epoch:7 [146|160] loss:0.030151 acc:1.000000\n",
      "Epoch:7 [147|160] loss:0.029020 acc:1.000000\n",
      "Epoch:7 [148|160] loss:0.023206 acc:1.000000\n",
      "Epoch:7 [149|160] loss:0.033012 acc:1.000000\n",
      "Epoch:7 [150|160] loss:0.265407 acc:0.937500\n",
      "Epoch:7 [151|160] loss:0.028664 acc:1.000000\n",
      "Epoch:7 [152|160] loss:0.018618 acc:1.000000\n",
      "Epoch:7 [153|160] loss:0.023017 acc:1.000000\n",
      "Epoch:7 [154|160] loss:0.023866 acc:1.000000\n",
      "Epoch:7 [155|160] loss:0.323190 acc:0.875000\n",
      "Epoch:7 [156|160] loss:0.018453 acc:1.000000\n",
      "Epoch:7 [157|160] loss:0.256595 acc:0.937500\n",
      "Epoch:7 [158|160] loss:0.027332 acc:1.000000\n",
      "Epoch:7 [159|160] loss:0.021261 acc:1.000000\n",
      "\n",
      "Validation Epoch: 7\n",
      "Acc: 0.970266 \n",
      "\n",
      "Epoch: 8\n",
      "Epoch:8 [0|160] loss:0.018039 acc:1.000000\n",
      "Epoch:8 [1|160] loss:0.018112 acc:1.000000\n",
      "Epoch:8 [2|160] loss:0.228233 acc:0.875000\n",
      "Epoch:8 [3|160] loss:0.032606 acc:1.000000\n",
      "Epoch:8 [4|160] loss:0.438142 acc:0.875000\n",
      "Epoch:8 [5|160] loss:0.264167 acc:0.937500\n",
      "Epoch:8 [6|160] loss:0.057746 acc:1.000000\n",
      "Epoch:8 [7|160] loss:0.083590 acc:0.937500\n",
      "Epoch:8 [8|160] loss:0.027538 acc:1.000000\n",
      "Epoch:8 [9|160] loss:0.025942 acc:1.000000\n",
      "Epoch:8 [10|160] loss:0.036181 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8 [11|160] loss:0.045835 acc:1.000000\n",
      "Epoch:8 [12|160] loss:0.022698 acc:1.000000\n",
      "Epoch:8 [13|160] loss:0.028948 acc:1.000000\n",
      "Epoch:8 [14|160] loss:0.023481 acc:1.000000\n",
      "Epoch:8 [15|160] loss:0.044413 acc:1.000000\n",
      "Epoch:8 [16|160] loss:0.079900 acc:0.937500\n",
      "Epoch:8 [17|160] loss:0.066452 acc:0.937500\n",
      "Epoch:8 [18|160] loss:0.030834 acc:1.000000\n",
      "Epoch:8 [19|160] loss:0.032351 acc:1.000000\n",
      "Epoch:8 [20|160] loss:0.040817 acc:1.000000\n",
      "Epoch:8 [21|160] loss:0.037403 acc:1.000000\n",
      "Epoch:8 [22|160] loss:0.039987 acc:1.000000\n",
      "Epoch:8 [23|160] loss:0.023223 acc:1.000000\n",
      "Epoch:8 [24|160] loss:0.046232 acc:1.000000\n",
      "Epoch:8 [25|160] loss:0.211072 acc:0.937500\n",
      "Epoch:8 [26|160] loss:0.104849 acc:0.937500\n",
      "Epoch:8 [27|160] loss:0.160764 acc:0.937500\n",
      "Epoch:8 [28|160] loss:0.401005 acc:0.875000\n",
      "Epoch:8 [29|160] loss:0.014646 acc:1.000000\n",
      "Epoch:8 [30|160] loss:0.132567 acc:0.875000\n",
      "Epoch:8 [31|160] loss:0.213627 acc:0.875000\n",
      "Epoch:8 [32|160] loss:0.024862 acc:1.000000\n",
      "Epoch:8 [33|160] loss:0.057273 acc:0.937500\n",
      "Epoch:8 [34|160] loss:0.497384 acc:0.875000\n",
      "Epoch:8 [35|160] loss:0.031536 acc:1.000000\n",
      "Epoch:8 [36|160] loss:0.049594 acc:1.000000\n",
      "Epoch:8 [37|160] loss:0.022591 acc:1.000000\n",
      "Epoch:8 [38|160] loss:0.107315 acc:0.937500\n",
      "Epoch:8 [39|160] loss:0.150275 acc:0.937500\n",
      "Epoch:8 [40|160] loss:0.354630 acc:0.875000\n",
      "Epoch:8 [41|160] loss:0.024798 acc:1.000000\n",
      "Epoch:8 [42|160] loss:0.101788 acc:0.937500\n",
      "Epoch:8 [43|160] loss:0.056352 acc:1.000000\n",
      "Epoch:8 [44|160] loss:0.040357 acc:1.000000\n",
      "Epoch:8 [45|160] loss:0.034093 acc:1.000000\n",
      "Epoch:8 [46|160] loss:0.038207 acc:1.000000\n",
      "Epoch:8 [47|160] loss:0.017402 acc:1.000000\n",
      "Epoch:8 [48|160] loss:0.023857 acc:1.000000\n",
      "Epoch:8 [49|160] loss:0.021820 acc:1.000000\n",
      "Epoch:8 [50|160] loss:0.026819 acc:1.000000\n",
      "Epoch:8 [51|160] loss:0.032056 acc:1.000000\n",
      "Epoch:8 [52|160] loss:0.018277 acc:1.000000\n",
      "Epoch:8 [53|160] loss:0.321259 acc:0.875000\n",
      "Epoch:8 [54|160] loss:0.305634 acc:0.937500\n",
      "Epoch:8 [55|160] loss:0.247924 acc:0.937500\n",
      "Epoch:8 [56|160] loss:0.030929 acc:1.000000\n",
      "Epoch:8 [57|160] loss:0.027757 acc:1.000000\n",
      "Epoch:8 [58|160] loss:0.017211 acc:1.000000\n",
      "Epoch:8 [59|160] loss:0.140160 acc:0.875000\n",
      "Epoch:8 [60|160] loss:0.051617 acc:1.000000\n",
      "Epoch:8 [61|160] loss:0.061910 acc:1.000000\n",
      "Epoch:8 [62|160] loss:0.021176 acc:1.000000\n",
      "Epoch:8 [63|160] loss:0.016102 acc:1.000000\n",
      "Epoch:8 [64|160] loss:0.049771 acc:1.000000\n",
      "Epoch:8 [65|160] loss:0.017486 acc:1.000000\n",
      "Epoch:8 [66|160] loss:0.126259 acc:0.937500\n",
      "Epoch:8 [67|160] loss:0.066320 acc:0.937500\n",
      "Epoch:8 [68|160] loss:0.017868 acc:1.000000\n",
      "Epoch:8 [69|160] loss:0.029504 acc:1.000000\n",
      "Epoch:8 [70|160] loss:0.032195 acc:1.000000\n",
      "Epoch:8 [71|160] loss:0.022227 acc:1.000000\n",
      "Epoch:8 [72|160] loss:0.024572 acc:1.000000\n",
      "Epoch:8 [73|160] loss:0.145367 acc:0.937500\n",
      "Epoch:8 [74|160] loss:0.020859 acc:1.000000\n",
      "Epoch:8 [75|160] loss:0.016591 acc:1.000000\n",
      "Epoch:8 [76|160] loss:0.115499 acc:0.937500\n",
      "Epoch:8 [77|160] loss:0.018594 acc:1.000000\n",
      "Epoch:8 [78|160] loss:0.041523 acc:1.000000\n",
      "Epoch:8 [79|160] loss:0.017667 acc:1.000000\n",
      "Epoch:8 [80|160] loss:0.047264 acc:1.000000\n",
      "Epoch:8 [81|160] loss:0.032216 acc:1.000000\n",
      "Epoch:8 [82|160] loss:0.010475 acc:1.000000\n",
      "Epoch:8 [83|160] loss:0.168672 acc:0.937500\n",
      "Epoch:8 [84|160] loss:0.013457 acc:1.000000\n",
      "Epoch:8 [85|160] loss:0.042031 acc:1.000000\n",
      "Epoch:8 [86|160] loss:0.171796 acc:0.937500\n",
      "Epoch:8 [87|160] loss:0.090118 acc:0.937500\n",
      "Epoch:8 [88|160] loss:0.032710 acc:1.000000\n",
      "Epoch:8 [89|160] loss:0.047995 acc:1.000000\n",
      "Epoch:8 [90|160] loss:0.113135 acc:0.937500\n",
      "Epoch:8 [91|160] loss:0.016866 acc:1.000000\n",
      "Epoch:8 [92|160] loss:0.038076 acc:1.000000\n",
      "Epoch:8 [93|160] loss:0.049254 acc:1.000000\n",
      "Epoch:8 [94|160] loss:0.025546 acc:1.000000\n",
      "Epoch:8 [95|160] loss:0.026188 acc:1.000000\n",
      "Epoch:8 [96|160] loss:0.015209 acc:1.000000\n",
      "Epoch:8 [97|160] loss:0.037845 acc:1.000000\n",
      "Epoch:8 [98|160] loss:0.023539 acc:1.000000\n",
      "Epoch:8 [99|160] loss:0.019065 acc:1.000000\n",
      "Epoch:8 [100|160] loss:0.025711 acc:1.000000\n",
      "Epoch:8 [101|160] loss:0.032895 acc:1.000000\n",
      "Epoch:8 [102|160] loss:0.027729 acc:1.000000\n",
      "Epoch:8 [103|160] loss:0.020171 acc:1.000000\n",
      "Epoch:8 [104|160] loss:0.021957 acc:1.000000\n",
      "Epoch:8 [105|160] loss:0.026950 acc:1.000000\n",
      "Epoch:8 [106|160] loss:0.355161 acc:0.937500\n",
      "Epoch:8 [107|160] loss:0.012444 acc:1.000000\n",
      "Epoch:8 [108|160] loss:0.016515 acc:1.000000\n",
      "Epoch:8 [109|160] loss:0.018123 acc:1.000000\n",
      "Epoch:8 [110|160] loss:0.017781 acc:1.000000\n",
      "Epoch:8 [111|160] loss:0.125101 acc:0.937500\n",
      "Epoch:8 [112|160] loss:0.033127 acc:1.000000\n",
      "Epoch:8 [113|160] loss:0.020380 acc:1.000000\n",
      "Epoch:8 [114|160] loss:0.023421 acc:1.000000\n",
      "Epoch:8 [115|160] loss:0.297109 acc:0.875000\n",
      "Epoch:8 [116|160] loss:0.029147 acc:1.000000\n",
      "Epoch:8 [117|160] loss:0.022834 acc:1.000000\n",
      "Epoch:8 [118|160] loss:0.029595 acc:1.000000\n",
      "Epoch:8 [119|160] loss:0.392960 acc:0.937500\n",
      "Epoch:8 [120|160] loss:0.017769 acc:1.000000\n",
      "Epoch:8 [121|160] loss:0.018238 acc:1.000000\n",
      "Epoch:8 [122|160] loss:0.008562 acc:1.000000\n",
      "Epoch:8 [123|160] loss:0.301312 acc:0.937500\n",
      "Epoch:8 [124|160] loss:0.015346 acc:1.000000\n",
      "Epoch:8 [125|160] loss:0.012761 acc:1.000000\n",
      "Epoch:8 [126|160] loss:0.015465 acc:1.000000\n",
      "Epoch:8 [127|160] loss:0.210747 acc:0.937500\n",
      "Epoch:8 [128|160] loss:0.091000 acc:0.937500\n",
      "Epoch:8 [129|160] loss:0.014125 acc:1.000000\n",
      "Epoch:8 [130|160] loss:0.016082 acc:1.000000\n",
      "Epoch:8 [131|160] loss:0.015593 acc:1.000000\n",
      "Epoch:8 [132|160] loss:0.221633 acc:0.937500\n",
      "Epoch:8 [133|160] loss:0.264239 acc:0.875000\n",
      "Epoch:8 [134|160] loss:0.011046 acc:1.000000\n",
      "Epoch:8 [135|160] loss:0.012598 acc:1.000000\n",
      "Epoch:8 [136|160] loss:0.011195 acc:1.000000\n",
      "Epoch:8 [137|160] loss:0.032069 acc:1.000000\n",
      "Epoch:8 [138|160] loss:0.079876 acc:1.000000\n",
      "Epoch:8 [139|160] loss:0.022035 acc:1.000000\n",
      "Epoch:8 [140|160] loss:0.028689 acc:1.000000\n",
      "Epoch:8 [141|160] loss:0.021765 acc:1.000000\n",
      "Epoch:8 [142|160] loss:0.088583 acc:0.937500\n",
      "Epoch:8 [143|160] loss:0.175904 acc:0.937500\n",
      "Epoch:8 [144|160] loss:0.026176 acc:1.000000\n",
      "Epoch:8 [145|160] loss:0.028057 acc:1.000000\n",
      "Epoch:8 [146|160] loss:0.022356 acc:1.000000\n",
      "Epoch:8 [147|160] loss:0.024187 acc:1.000000\n",
      "Epoch:8 [148|160] loss:0.025590 acc:1.000000\n",
      "Epoch:8 [149|160] loss:0.033723 acc:1.000000\n",
      "Epoch:8 [150|160] loss:0.051685 acc:1.000000\n",
      "Epoch:8 [151|160] loss:0.155087 acc:0.937500\n",
      "Epoch:8 [152|160] loss:0.030401 acc:1.000000\n",
      "Epoch:8 [153|160] loss:0.094988 acc:0.937500\n",
      "Epoch:8 [154|160] loss:0.012511 acc:1.000000\n",
      "Epoch:8 [155|160] loss:0.227743 acc:0.875000\n",
      "Epoch:8 [156|160] loss:0.037659 acc:1.000000\n",
      "Epoch:8 [157|160] loss:0.030371 acc:1.000000\n",
      "Epoch:8 [158|160] loss:0.024234 acc:1.000000\n",
      "Epoch:8 [159|160] loss:0.067079 acc:0.916667\n",
      "\n",
      "Validation Epoch: 8\n",
      "Acc: 0.970266 \n",
      "\n",
      "Epoch: 9\n",
      "Epoch:9 [0|160] loss:0.041720 acc:1.000000\n",
      "Epoch:9 [1|160] loss:0.072602 acc:1.000000\n",
      "Epoch:9 [2|160] loss:0.026518 acc:1.000000\n",
      "Epoch:9 [3|160] loss:0.156320 acc:0.937500\n",
      "Epoch:9 [4|160] loss:0.209115 acc:0.937500\n",
      "Epoch:9 [5|160] loss:0.031453 acc:1.000000\n",
      "Epoch:9 [6|160] loss:0.033423 acc:1.000000\n",
      "Epoch:9 [7|160] loss:0.026412 acc:1.000000\n",
      "Epoch:9 [8|160] loss:0.010278 acc:1.000000\n",
      "Epoch:9 [9|160] loss:0.091323 acc:0.937500\n",
      "Epoch:9 [10|160] loss:0.076015 acc:0.937500\n",
      "Epoch:9 [11|160] loss:0.028969 acc:1.000000\n",
      "Epoch:9 [12|160] loss:0.061912 acc:1.000000\n",
      "Epoch:9 [13|160] loss:0.014595 acc:1.000000\n",
      "Epoch:9 [14|160] loss:0.027702 acc:1.000000\n",
      "Epoch:9 [15|160] loss:0.024877 acc:1.000000\n",
      "Epoch:9 [16|160] loss:0.012666 acc:1.000000\n",
      "Epoch:9 [17|160] loss:0.013168 acc:1.000000\n",
      "Epoch:9 [18|160] loss:0.024493 acc:1.000000\n",
      "Epoch:9 [19|160] loss:0.078496 acc:0.937500\n",
      "Epoch:9 [20|160] loss:0.076389 acc:1.000000\n",
      "Epoch:9 [21|160] loss:0.018527 acc:1.000000\n",
      "Epoch:9 [22|160] loss:0.015282 acc:1.000000\n",
      "Epoch:9 [23|160] loss:0.584418 acc:0.875000\n",
      "Epoch:9 [24|160] loss:0.016464 acc:1.000000\n",
      "Epoch:9 [25|160] loss:0.012242 acc:1.000000\n",
      "Epoch:9 [26|160] loss:0.036363 acc:1.000000\n",
      "Epoch:9 [27|160] loss:0.060938 acc:0.937500\n",
      "Epoch:9 [28|160] loss:0.033485 acc:1.000000\n",
      "Epoch:9 [29|160] loss:0.021366 acc:1.000000\n",
      "Epoch:9 [30|160] loss:0.023762 acc:1.000000\n",
      "Epoch:9 [31|160] loss:0.010028 acc:1.000000\n",
      "Epoch:9 [32|160] loss:0.024951 acc:1.000000\n",
      "Epoch:9 [33|160] loss:0.154080 acc:0.937500\n",
      "Epoch:9 [34|160] loss:0.018763 acc:1.000000\n",
      "Epoch:9 [35|160] loss:0.076374 acc:0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9 [36|160] loss:0.015256 acc:1.000000\n",
      "Epoch:9 [37|160] loss:0.019117 acc:1.000000\n",
      "Epoch:9 [38|160] loss:0.022695 acc:1.000000\n",
      "Epoch:9 [39|160] loss:0.153873 acc:0.875000\n",
      "Epoch:9 [40|160] loss:0.068678 acc:0.937500\n",
      "Epoch:9 [41|160] loss:0.022710 acc:1.000000\n",
      "Epoch:9 [42|160] loss:0.188775 acc:0.937500\n",
      "Epoch:9 [43|160] loss:0.017435 acc:1.000000\n",
      "Epoch:9 [44|160] loss:0.019552 acc:1.000000\n",
      "Epoch:9 [45|160] loss:0.008456 acc:1.000000\n",
      "Epoch:9 [46|160] loss:0.015009 acc:1.000000\n",
      "Epoch:9 [47|160] loss:0.125884 acc:0.937500\n",
      "Epoch:9 [48|160] loss:0.022961 acc:1.000000\n",
      "Epoch:9 [49|160] loss:0.035706 acc:1.000000\n",
      "Epoch:9 [50|160] loss:0.015732 acc:1.000000\n",
      "Epoch:9 [51|160] loss:0.012065 acc:1.000000\n",
      "Epoch:9 [52|160] loss:0.118173 acc:0.937500\n",
      "Epoch:9 [53|160] loss:0.019158 acc:1.000000\n",
      "Epoch:9 [54|160] loss:0.037576 acc:1.000000\n",
      "Epoch:9 [55|160] loss:0.348260 acc:0.937500\n",
      "Epoch:9 [56|160] loss:0.024832 acc:1.000000\n",
      "Epoch:9 [57|160] loss:0.015307 acc:1.000000\n",
      "Epoch:9 [58|160] loss:0.017599 acc:1.000000\n",
      "Epoch:9 [59|160] loss:0.016023 acc:1.000000\n",
      "Epoch:9 [60|160] loss:0.026748 acc:1.000000\n",
      "Epoch:9 [61|160] loss:0.014205 acc:1.000000\n",
      "Epoch:9 [62|160] loss:0.025225 acc:1.000000\n",
      "Epoch:9 [63|160] loss:0.029377 acc:1.000000\n",
      "Epoch:9 [64|160] loss:0.038708 acc:1.000000\n",
      "Epoch:9 [65|160] loss:0.013727 acc:1.000000\n",
      "Epoch:9 [66|160] loss:0.010783 acc:1.000000\n",
      "Epoch:9 [67|160] loss:0.035358 acc:1.000000\n",
      "Epoch:9 [68|160] loss:0.009750 acc:1.000000\n",
      "Epoch:9 [69|160] loss:0.020411 acc:1.000000\n",
      "Epoch:9 [70|160] loss:0.200796 acc:0.937500\n",
      "Epoch:9 [71|160] loss:0.011837 acc:1.000000\n",
      "Epoch:9 [72|160] loss:0.032503 acc:1.000000\n",
      "Epoch:9 [73|160] loss:0.015846 acc:1.000000\n",
      "Epoch:9 [74|160] loss:0.013027 acc:1.000000\n",
      "Epoch:9 [75|160] loss:0.180246 acc:0.937500\n",
      "Epoch:9 [76|160] loss:0.023839 acc:1.000000\n",
      "Epoch:9 [77|160] loss:0.030772 acc:1.000000\n",
      "Epoch:9 [78|160] loss:0.050244 acc:1.000000\n",
      "Epoch:9 [79|160] loss:0.023955 acc:1.000000\n",
      "Epoch:9 [80|160] loss:0.010963 acc:1.000000\n",
      "Epoch:9 [81|160] loss:0.010865 acc:1.000000\n",
      "Epoch:9 [82|160] loss:0.050267 acc:1.000000\n",
      "Epoch:9 [83|160] loss:0.098291 acc:0.937500\n",
      "Epoch:9 [84|160] loss:0.010946 acc:1.000000\n",
      "Epoch:9 [85|160] loss:0.122607 acc:0.937500\n",
      "Epoch:9 [86|160] loss:0.158612 acc:0.937500\n",
      "Epoch:9 [87|160] loss:0.027601 acc:1.000000\n",
      "Epoch:9 [88|160] loss:0.206819 acc:0.937500\n",
      "Epoch:9 [89|160] loss:0.017903 acc:1.000000\n",
      "Epoch:9 [90|160] loss:0.010254 acc:1.000000\n",
      "Epoch:9 [91|160] loss:0.012040 acc:1.000000\n",
      "Epoch:9 [92|160] loss:0.013957 acc:1.000000\n",
      "Epoch:9 [93|160] loss:0.038163 acc:1.000000\n",
      "Epoch:9 [94|160] loss:0.013030 acc:1.000000\n",
      "Epoch:9 [95|160] loss:0.044060 acc:1.000000\n",
      "Epoch:9 [96|160] loss:0.017048 acc:1.000000\n",
      "Epoch:9 [97|160] loss:0.019713 acc:1.000000\n",
      "Epoch:9 [98|160] loss:0.011504 acc:1.000000\n",
      "Epoch:9 [99|160] loss:0.128838 acc:0.937500\n",
      "Epoch:9 [100|160] loss:0.015294 acc:1.000000\n",
      "Epoch:9 [101|160] loss:0.025334 acc:1.000000\n",
      "Epoch:9 [102|160] loss:0.118902 acc:0.937500\n",
      "Epoch:9 [103|160] loss:0.016645 acc:1.000000\n",
      "Epoch:9 [104|160] loss:0.028666 acc:1.000000\n",
      "Epoch:9 [105|160] loss:0.303474 acc:0.937500\n",
      "Epoch:9 [106|160] loss:0.338266 acc:0.875000\n",
      "Epoch:9 [107|160] loss:0.373864 acc:0.937500\n",
      "Epoch:9 [108|160] loss:0.017857 acc:1.000000\n",
      "Epoch:9 [109|160] loss:0.132920 acc:0.937500\n",
      "Epoch:9 [110|160] loss:0.038654 acc:1.000000\n",
      "Epoch:9 [111|160] loss:0.016696 acc:1.000000\n",
      "Epoch:9 [112|160] loss:0.045443 acc:1.000000\n",
      "Epoch:9 [113|160] loss:0.012795 acc:1.000000\n",
      "Epoch:9 [114|160] loss:0.015179 acc:1.000000\n",
      "Epoch:9 [115|160] loss:0.024578 acc:1.000000\n",
      "Epoch:9 [116|160] loss:0.035466 acc:1.000000\n",
      "Epoch:9 [117|160] loss:0.122956 acc:0.937500\n",
      "Epoch:9 [118|160] loss:0.020384 acc:1.000000\n",
      "Epoch:9 [119|160] loss:0.016939 acc:1.000000\n",
      "Epoch:9 [120|160] loss:0.123345 acc:0.937500\n",
      "Epoch:9 [121|160] loss:0.024007 acc:1.000000\n",
      "Epoch:9 [122|160] loss:0.009717 acc:1.000000\n",
      "Epoch:9 [123|160] loss:0.019835 acc:1.000000\n",
      "Epoch:9 [124|160] loss:0.017665 acc:1.000000\n",
      "Epoch:9 [125|160] loss:0.033117 acc:1.000000\n",
      "Epoch:9 [126|160] loss:0.013588 acc:1.000000\n",
      "Epoch:9 [127|160] loss:0.034949 acc:1.000000\n",
      "Epoch:9 [128|160] loss:0.044027 acc:1.000000\n",
      "Epoch:9 [129|160] loss:0.121547 acc:0.937500\n",
      "Epoch:9 [130|160] loss:0.037865 acc:1.000000\n",
      "Epoch:9 [131|160] loss:0.553639 acc:0.875000\n",
      "Epoch:9 [132|160] loss:0.010544 acc:1.000000\n",
      "Epoch:9 [133|160] loss:0.023077 acc:1.000000\n",
      "Epoch:9 [134|160] loss:0.056774 acc:0.937500\n",
      "Epoch:9 [135|160] loss:0.071990 acc:0.937500\n",
      "Epoch:9 [136|160] loss:0.022734 acc:1.000000\n",
      "Epoch:9 [137|160] loss:0.032530 acc:1.000000\n",
      "Epoch:9 [138|160] loss:0.014400 acc:1.000000\n",
      "Epoch:9 [139|160] loss:0.129572 acc:0.937500\n",
      "Epoch:9 [140|160] loss:0.015366 acc:1.000000\n",
      "Epoch:9 [141|160] loss:0.016089 acc:1.000000\n",
      "Epoch:9 [142|160] loss:0.020274 acc:1.000000\n",
      "Epoch:9 [143|160] loss:0.012958 acc:1.000000\n",
      "Epoch:9 [144|160] loss:0.369075 acc:0.875000\n",
      "Epoch:9 [145|160] loss:0.015315 acc:1.000000\n",
      "Epoch:9 [146|160] loss:0.110678 acc:0.937500\n",
      "Epoch:9 [147|160] loss:0.190265 acc:0.875000\n",
      "Epoch:9 [148|160] loss:0.060140 acc:1.000000\n",
      "Epoch:9 [149|160] loss:0.023041 acc:1.000000\n",
      "Epoch:9 [150|160] loss:0.025508 acc:1.000000\n",
      "Epoch:9 [151|160] loss:0.015603 acc:1.000000\n",
      "Epoch:9 [152|160] loss:0.012899 acc:1.000000\n",
      "Epoch:9 [153|160] loss:0.026958 acc:1.000000\n",
      "Epoch:9 [154|160] loss:0.406262 acc:0.937500\n",
      "Epoch:9 [155|160] loss:0.105188 acc:0.937500\n",
      "Epoch:9 [156|160] loss:0.043258 acc:1.000000\n",
      "Epoch:9 [157|160] loss:0.266959 acc:0.875000\n",
      "Epoch:9 [158|160] loss:0.121305 acc:0.937500\n",
      "Epoch:9 [159|160] loss:0.074911 acc:0.916667\n",
      "\n",
      "Validation Epoch: 9\n",
      "Acc: 0.973396 \n",
      "\n",
      "Epoch: 10\n",
      "Epoch:10 [0|160] loss:0.021704 acc:1.000000\n",
      "Epoch:10 [1|160] loss:0.027983 acc:1.000000\n",
      "Epoch:10 [2|160] loss:0.015846 acc:1.000000\n",
      "Epoch:10 [3|160] loss:0.170445 acc:0.937500\n",
      "Epoch:10 [4|160] loss:0.060523 acc:0.937500\n",
      "Epoch:10 [5|160] loss:0.032399 acc:1.000000\n",
      "Epoch:10 [6|160] loss:0.052131 acc:1.000000\n",
      "Epoch:10 [7|160] loss:0.023541 acc:1.000000\n",
      "Epoch:10 [8|160] loss:0.016962 acc:1.000000\n",
      "Epoch:10 [9|160] loss:0.015177 acc:1.000000\n",
      "Epoch:10 [10|160] loss:0.118037 acc:0.937500\n",
      "Epoch:10 [11|160] loss:0.036586 acc:1.000000\n",
      "Epoch:10 [12|160] loss:0.527903 acc:0.875000\n",
      "Epoch:10 [13|160] loss:0.114085 acc:0.937500\n",
      "Epoch:10 [14|160] loss:0.204211 acc:0.937500\n",
      "Epoch:10 [15|160] loss:0.021229 acc:1.000000\n",
      "Epoch:10 [16|160] loss:0.025771 acc:1.000000\n",
      "Epoch:10 [17|160] loss:0.145972 acc:0.937500\n",
      "Epoch:10 [18|160] loss:0.163589 acc:0.875000\n",
      "Epoch:10 [19|160] loss:0.018660 acc:1.000000\n",
      "Epoch:10 [20|160] loss:0.167059 acc:0.875000\n",
      "Epoch:10 [21|160] loss:0.012694 acc:1.000000\n",
      "Epoch:10 [22|160] loss:0.026962 acc:1.000000\n",
      "Epoch:10 [23|160] loss:0.024147 acc:1.000000\n",
      "Epoch:10 [24|160] loss:0.023453 acc:1.000000\n",
      "Epoch:10 [25|160] loss:0.127049 acc:0.937500\n",
      "Epoch:10 [26|160] loss:0.045436 acc:1.000000\n",
      "Epoch:10 [27|160] loss:0.022835 acc:1.000000\n",
      "Epoch:10 [28|160] loss:0.053115 acc:1.000000\n",
      "Epoch:10 [29|160] loss:0.016683 acc:1.000000\n",
      "Epoch:10 [30|160] loss:0.105238 acc:0.937500\n",
      "Epoch:10 [31|160] loss:0.118429 acc:0.937500\n",
      "Epoch:10 [32|160] loss:0.256587 acc:0.937500\n",
      "Epoch:10 [33|160] loss:0.017316 acc:1.000000\n",
      "Epoch:10 [34|160] loss:0.021810 acc:1.000000\n",
      "Epoch:10 [35|160] loss:0.030864 acc:1.000000\n",
      "Epoch:10 [36|160] loss:0.016811 acc:1.000000\n",
      "Epoch:10 [37|160] loss:0.013983 acc:1.000000\n",
      "Epoch:10 [38|160] loss:0.030786 acc:1.000000\n",
      "Epoch:10 [39|160] loss:0.020498 acc:1.000000\n",
      "Epoch:10 [40|160] loss:0.020074 acc:1.000000\n",
      "Epoch:10 [41|160] loss:0.011037 acc:1.000000\n",
      "Epoch:10 [42|160] loss:0.027381 acc:1.000000\n",
      "Epoch:10 [43|160] loss:0.053872 acc:1.000000\n",
      "Epoch:10 [44|160] loss:0.023990 acc:1.000000\n",
      "Epoch:10 [45|160] loss:0.017180 acc:1.000000\n",
      "Epoch:10 [46|160] loss:0.056357 acc:1.000000\n",
      "Epoch:10 [47|160] loss:0.019224 acc:1.000000\n",
      "Epoch:10 [48|160] loss:0.026248 acc:1.000000\n",
      "Epoch:10 [49|160] loss:0.024957 acc:1.000000\n",
      "Epoch:10 [50|160] loss:0.020583 acc:1.000000\n",
      "Epoch:10 [51|160] loss:0.014545 acc:1.000000\n",
      "Epoch:10 [52|160] loss:0.021127 acc:1.000000\n",
      "Epoch:10 [53|160] loss:0.026132 acc:1.000000\n",
      "Epoch:10 [54|160] loss:0.151987 acc:0.937500\n",
      "Epoch:10 [55|160] loss:0.031735 acc:1.000000\n",
      "Epoch:10 [56|160] loss:0.015355 acc:1.000000\n",
      "Epoch:10 [57|160] loss:0.059727 acc:1.000000\n",
      "Epoch:10 [58|160] loss:0.056615 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10 [59|160] loss:0.097131 acc:0.937500\n",
      "Epoch:10 [60|160] loss:0.032680 acc:1.000000\n",
      "Epoch:10 [61|160] loss:0.009181 acc:1.000000\n",
      "Epoch:10 [62|160] loss:0.022839 acc:1.000000\n",
      "Epoch:10 [63|160] loss:0.012576 acc:1.000000\n",
      "Epoch:10 [64|160] loss:0.185452 acc:0.937500\n",
      "Epoch:10 [65|160] loss:0.038509 acc:1.000000\n",
      "Epoch:10 [66|160] loss:0.007831 acc:1.000000\n",
      "Epoch:10 [67|160] loss:0.012039 acc:1.000000\n",
      "Epoch:10 [68|160] loss:0.183998 acc:0.937500\n",
      "Epoch:10 [69|160] loss:0.016813 acc:1.000000\n",
      "Epoch:10 [70|160] loss:0.139643 acc:0.937500\n",
      "Epoch:10 [71|160] loss:0.052636 acc:0.937500\n",
      "Epoch:10 [72|160] loss:0.018568 acc:1.000000\n",
      "Epoch:10 [73|160] loss:0.026950 acc:1.000000\n",
      "Epoch:10 [74|160] loss:0.026327 acc:1.000000\n",
      "Epoch:10 [75|160] loss:0.011972 acc:1.000000\n",
      "Epoch:10 [76|160] loss:0.011586 acc:1.000000\n",
      "Epoch:10 [77|160] loss:0.046805 acc:1.000000\n",
      "Epoch:10 [78|160] loss:0.067594 acc:0.937500\n",
      "Epoch:10 [79|160] loss:0.013066 acc:1.000000\n",
      "Epoch:10 [80|160] loss:0.084999 acc:1.000000\n",
      "Epoch:10 [81|160] loss:0.017390 acc:1.000000\n",
      "Epoch:10 [82|160] loss:0.022652 acc:1.000000\n",
      "Epoch:10 [83|160] loss:0.024774 acc:1.000000\n",
      "Epoch:10 [84|160] loss:0.015304 acc:1.000000\n",
      "Epoch:10 [85|160] loss:0.014748 acc:1.000000\n",
      "Epoch:10 [86|160] loss:0.201457 acc:0.875000\n",
      "Epoch:10 [87|160] loss:0.279727 acc:0.937500\n",
      "Epoch:10 [88|160] loss:0.014848 acc:1.000000\n",
      "Epoch:10 [89|160] loss:0.023285 acc:1.000000\n",
      "Epoch:10 [90|160] loss:0.147581 acc:0.937500\n",
      "Epoch:10 [91|160] loss:0.015072 acc:1.000000\n",
      "Epoch:10 [92|160] loss:0.107592 acc:0.937500\n",
      "Epoch:10 [93|160] loss:0.053750 acc:1.000000\n",
      "Epoch:10 [94|160] loss:0.009243 acc:1.000000\n",
      "Epoch:10 [95|160] loss:0.018524 acc:1.000000\n",
      "Epoch:10 [96|160] loss:0.018648 acc:1.000000\n",
      "Epoch:10 [97|160] loss:0.020910 acc:1.000000\n",
      "Epoch:10 [98|160] loss:0.008858 acc:1.000000\n",
      "Epoch:10 [99|160] loss:0.073301 acc:0.937500\n",
      "Epoch:10 [100|160] loss:0.008585 acc:1.000000\n",
      "Epoch:10 [101|160] loss:0.056542 acc:1.000000\n",
      "Epoch:10 [102|160] loss:0.156441 acc:0.937500\n",
      "Epoch:10 [103|160] loss:0.084026 acc:0.937500\n",
      "Epoch:10 [104|160] loss:0.034258 acc:1.000000\n",
      "Epoch:10 [105|160] loss:0.161396 acc:0.937500\n",
      "Epoch:10 [106|160] loss:0.022289 acc:1.000000\n",
      "Epoch:10 [107|160] loss:0.014478 acc:1.000000\n",
      "Epoch:10 [108|160] loss:0.016083 acc:1.000000\n",
      "Epoch:10 [109|160] loss:0.020858 acc:1.000000\n",
      "Epoch:10 [110|160] loss:0.032418 acc:1.000000\n",
      "Epoch:10 [111|160] loss:0.011079 acc:1.000000\n",
      "Epoch:10 [112|160] loss:0.032675 acc:1.000000\n",
      "Epoch:10 [113|160] loss:0.031848 acc:1.000000\n",
      "Epoch:10 [114|160] loss:0.014336 acc:1.000000\n",
      "Epoch:10 [115|160] loss:0.145581 acc:0.937500\n",
      "Epoch:10 [116|160] loss:0.032005 acc:1.000000\n",
      "Epoch:10 [117|160] loss:0.014953 acc:1.000000\n",
      "Epoch:10 [118|160] loss:0.011327 acc:1.000000\n",
      "Epoch:10 [119|160] loss:0.009876 acc:1.000000\n",
      "Epoch:10 [120|160] loss:0.009786 acc:1.000000\n",
      "Epoch:10 [121|160] loss:0.010695 acc:1.000000\n",
      "Epoch:10 [122|160] loss:0.135037 acc:0.875000\n",
      "Epoch:10 [123|160] loss:0.011941 acc:1.000000\n",
      "Epoch:10 [124|160] loss:0.031609 acc:1.000000\n",
      "Epoch:10 [125|160] loss:0.015243 acc:1.000000\n",
      "Epoch:10 [126|160] loss:0.271447 acc:0.937500\n",
      "Epoch:10 [127|160] loss:0.014290 acc:1.000000\n",
      "Epoch:10 [128|160] loss:0.033476 acc:1.000000\n",
      "Epoch:10 [129|160] loss:0.093924 acc:0.937500\n",
      "Epoch:10 [130|160] loss:0.024860 acc:1.000000\n",
      "Epoch:10 [131|160] loss:0.016950 acc:1.000000\n",
      "Epoch:10 [132|160] loss:0.032451 acc:1.000000\n",
      "Epoch:10 [133|160] loss:0.019783 acc:1.000000\n",
      "Epoch:10 [134|160] loss:0.047980 acc:1.000000\n",
      "Epoch:10 [135|160] loss:0.013274 acc:1.000000\n",
      "Epoch:10 [136|160] loss:0.125852 acc:0.937500\n",
      "Epoch:10 [137|160] loss:0.016989 acc:1.000000\n",
      "Epoch:10 [138|160] loss:0.045362 acc:1.000000\n",
      "Epoch:10 [139|160] loss:0.012825 acc:1.000000\n",
      "Epoch:10 [140|160] loss:0.008440 acc:1.000000\n",
      "Epoch:10 [141|160] loss:0.201712 acc:0.937500\n",
      "Epoch:10 [142|160] loss:0.137148 acc:0.937500\n",
      "Epoch:10 [143|160] loss:0.059595 acc:0.937500\n",
      "Epoch:10 [144|160] loss:0.211649 acc:0.875000\n",
      "Epoch:10 [145|160] loss:0.061381 acc:1.000000\n",
      "Epoch:10 [146|160] loss:0.018062 acc:1.000000\n",
      "Epoch:10 [147|160] loss:0.394552 acc:0.937500\n",
      "Epoch:10 [148|160] loss:0.010182 acc:1.000000\n",
      "Epoch:10 [149|160] loss:0.034927 acc:1.000000\n",
      "Epoch:10 [150|160] loss:0.012160 acc:1.000000\n",
      "Epoch:10 [151|160] loss:0.019865 acc:1.000000\n",
      "Epoch:10 [152|160] loss:0.016654 acc:1.000000\n",
      "Epoch:10 [153|160] loss:0.009490 acc:1.000000\n",
      "Epoch:10 [154|160] loss:0.019940 acc:1.000000\n",
      "Epoch:10 [155|160] loss:0.013276 acc:1.000000\n",
      "Epoch:10 [156|160] loss:0.023743 acc:1.000000\n",
      "Epoch:10 [157|160] loss:0.015931 acc:1.000000\n",
      "Epoch:10 [158|160] loss:0.012439 acc:1.000000\n",
      "Epoch:10 [159|160] loss:0.019096 acc:1.000000\n",
      "\n",
      "Validation Epoch: 10\n",
      "Acc: 0.968701 \n",
      "\n",
      "Epoch: 11\n",
      "Epoch:11 [0|160] loss:0.010969 acc:1.000000\n",
      "Epoch:11 [1|160] loss:0.033370 acc:1.000000\n",
      "Epoch:11 [2|160] loss:0.009142 acc:1.000000\n",
      "Epoch:11 [3|160] loss:0.015506 acc:1.000000\n",
      "Epoch:11 [4|160] loss:0.014931 acc:1.000000\n",
      "Epoch:11 [5|160] loss:0.018056 acc:1.000000\n",
      "Epoch:11 [6|160] loss:0.016295 acc:1.000000\n",
      "Epoch:11 [7|160] loss:0.013941 acc:1.000000\n",
      "Epoch:11 [8|160] loss:0.073997 acc:0.937500\n",
      "Epoch:11 [9|160] loss:0.018995 acc:1.000000\n",
      "Epoch:11 [10|160] loss:0.097623 acc:0.937500\n",
      "Epoch:11 [11|160] loss:0.023120 acc:1.000000\n",
      "Epoch:11 [12|160] loss:0.026682 acc:1.000000\n",
      "Epoch:11 [13|160] loss:0.018808 acc:1.000000\n",
      "Epoch:11 [14|160] loss:0.010680 acc:1.000000\n",
      "Epoch:11 [15|160] loss:0.037729 acc:1.000000\n",
      "Epoch:11 [16|160] loss:0.020948 acc:1.000000\n",
      "Epoch:11 [17|160] loss:0.057023 acc:1.000000\n",
      "Epoch:11 [18|160] loss:0.027096 acc:1.000000\n",
      "Epoch:11 [19|160] loss:0.022365 acc:1.000000\n",
      "Epoch:11 [20|160] loss:0.036912 acc:1.000000\n",
      "Epoch:11 [21|160] loss:0.037203 acc:1.000000\n",
      "Epoch:11 [22|160] loss:0.022014 acc:1.000000\n",
      "Epoch:11 [23|160] loss:0.028357 acc:1.000000\n",
      "Epoch:11 [24|160] loss:0.015420 acc:1.000000\n",
      "Epoch:11 [25|160] loss:0.193602 acc:0.937500\n",
      "Epoch:11 [26|160] loss:0.012464 acc:1.000000\n",
      "Epoch:11 [27|160] loss:0.113472 acc:0.937500\n",
      "Epoch:11 [28|160] loss:0.021487 acc:1.000000\n",
      "Epoch:11 [29|160] loss:0.037743 acc:1.000000\n",
      "Epoch:11 [30|160] loss:0.009345 acc:1.000000\n",
      "Epoch:11 [31|160] loss:0.014555 acc:1.000000\n",
      "Epoch:11 [32|160] loss:0.028225 acc:1.000000\n",
      "Epoch:11 [33|160] loss:0.008865 acc:1.000000\n",
      "Epoch:11 [34|160] loss:0.019573 acc:1.000000\n",
      "Epoch:11 [35|160] loss:0.068744 acc:0.937500\n",
      "Epoch:11 [36|160] loss:0.021681 acc:1.000000\n",
      "Epoch:11 [37|160] loss:0.012244 acc:1.000000\n",
      "Epoch:11 [38|160] loss:0.049147 acc:1.000000\n",
      "Epoch:11 [39|160] loss:0.025310 acc:1.000000\n",
      "Epoch:11 [40|160] loss:0.022209 acc:1.000000\n",
      "Epoch:11 [41|160] loss:0.082629 acc:0.937500\n",
      "Epoch:11 [42|160] loss:0.016969 acc:1.000000\n",
      "Epoch:11 [43|160] loss:0.399132 acc:0.937500\n",
      "Epoch:11 [44|160] loss:0.010316 acc:1.000000\n",
      "Epoch:11 [45|160] loss:0.014417 acc:1.000000\n",
      "Epoch:11 [46|160] loss:0.288496 acc:0.937500\n",
      "Epoch:11 [47|160] loss:0.030288 acc:1.000000\n",
      "Epoch:11 [48|160] loss:0.012029 acc:1.000000\n",
      "Epoch:11 [49|160] loss:0.024497 acc:1.000000\n",
      "Epoch:11 [50|160] loss:0.019280 acc:1.000000\n",
      "Epoch:11 [51|160] loss:0.008447 acc:1.000000\n",
      "Epoch:11 [52|160] loss:0.016064 acc:1.000000\n",
      "Epoch:11 [53|160] loss:0.348933 acc:0.937500\n",
      "Epoch:11 [54|160] loss:0.035581 acc:1.000000\n",
      "Epoch:11 [55|160] loss:0.015136 acc:1.000000\n",
      "Epoch:11 [56|160] loss:0.021737 acc:1.000000\n",
      "Epoch:11 [57|160] loss:0.009473 acc:1.000000\n",
      "Epoch:11 [58|160] loss:0.215674 acc:0.937500\n",
      "Epoch:11 [59|160] loss:0.013963 acc:1.000000\n",
      "Epoch:11 [60|160] loss:0.017762 acc:1.000000\n",
      "Epoch:11 [61|160] loss:0.012584 acc:1.000000\n",
      "Epoch:11 [62|160] loss:0.014335 acc:1.000000\n",
      "Epoch:11 [63|160] loss:0.008191 acc:1.000000\n",
      "Epoch:11 [64|160] loss:0.294156 acc:0.937500\n",
      "Epoch:11 [65|160] loss:0.014115 acc:1.000000\n",
      "Epoch:11 [66|160] loss:0.014002 acc:1.000000\n",
      "Epoch:11 [67|160] loss:0.431064 acc:0.875000\n",
      "Epoch:11 [68|160] loss:0.221144 acc:0.937500\n",
      "Epoch:11 [69|160] loss:0.031457 acc:1.000000\n",
      "Epoch:11 [70|160] loss:0.174233 acc:0.937500\n",
      "Epoch:11 [71|160] loss:0.070479 acc:0.937500\n",
      "Epoch:11 [72|160] loss:0.024642 acc:1.000000\n",
      "Epoch:11 [73|160] loss:0.012013 acc:1.000000\n",
      "Epoch:11 [74|160] loss:0.023308 acc:1.000000\n",
      "Epoch:11 [75|160] loss:0.029497 acc:1.000000\n",
      "Epoch:11 [76|160] loss:0.035583 acc:1.000000\n",
      "Epoch:11 [77|160] loss:0.029731 acc:1.000000\n",
      "Epoch:11 [78|160] loss:0.023634 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11 [79|160] loss:0.033423 acc:1.000000\n",
      "Epoch:11 [80|160] loss:0.025449 acc:1.000000\n",
      "Epoch:11 [81|160] loss:0.009978 acc:1.000000\n",
      "Epoch:11 [82|160] loss:0.011489 acc:1.000000\n",
      "Epoch:11 [83|160] loss:0.016865 acc:1.000000\n",
      "Epoch:11 [84|160] loss:0.015740 acc:1.000000\n",
      "Epoch:11 [85|160] loss:0.019741 acc:1.000000\n",
      "Epoch:11 [86|160] loss:0.011967 acc:1.000000\n",
      "Epoch:11 [87|160] loss:0.099736 acc:0.937500\n",
      "Epoch:11 [88|160] loss:0.124298 acc:0.937500\n",
      "Epoch:11 [89|160] loss:0.017736 acc:1.000000\n",
      "Epoch:11 [90|160] loss:0.098877 acc:0.937500\n",
      "Epoch:11 [91|160] loss:0.016379 acc:1.000000\n",
      "Epoch:11 [92|160] loss:0.033091 acc:1.000000\n",
      "Epoch:11 [93|160] loss:0.035587 acc:1.000000\n",
      "Epoch:11 [94|160] loss:0.059829 acc:0.937500\n",
      "Epoch:11 [95|160] loss:0.012149 acc:1.000000\n",
      "Epoch:11 [96|160] loss:0.012813 acc:1.000000\n",
      "Epoch:11 [97|160] loss:0.019863 acc:1.000000\n",
      "Epoch:11 [98|160] loss:0.128491 acc:0.937500\n",
      "Epoch:11 [99|160] loss:0.210962 acc:0.875000\n",
      "Epoch:11 [100|160] loss:0.281315 acc:0.937500\n",
      "Epoch:11 [101|160] loss:0.057335 acc:0.937500\n",
      "Epoch:11 [102|160] loss:0.165288 acc:0.937500\n",
      "Epoch:11 [103|160] loss:0.026127 acc:1.000000\n",
      "Epoch:11 [104|160] loss:0.036380 acc:1.000000\n",
      "Epoch:11 [105|160] loss:0.009924 acc:1.000000\n",
      "Epoch:11 [106|160] loss:0.013874 acc:1.000000\n",
      "Epoch:11 [107|160] loss:0.021516 acc:1.000000\n",
      "Epoch:11 [108|160] loss:0.008588 acc:1.000000\n",
      "Epoch:11 [109|160] loss:0.013543 acc:1.000000\n",
      "Epoch:11 [110|160] loss:0.028860 acc:1.000000\n",
      "Epoch:11 [111|160] loss:0.032589 acc:1.000000\n",
      "Epoch:11 [112|160] loss:0.016748 acc:1.000000\n",
      "Epoch:11 [113|160] loss:0.012178 acc:1.000000\n",
      "Epoch:11 [114|160] loss:0.018407 acc:1.000000\n",
      "Epoch:11 [115|160] loss:0.012404 acc:1.000000\n",
      "Epoch:11 [116|160] loss:0.010840 acc:1.000000\n",
      "Epoch:11 [117|160] loss:0.024395 acc:1.000000\n",
      "Epoch:11 [118|160] loss:0.112434 acc:0.937500\n",
      "Epoch:11 [119|160] loss:0.099778 acc:0.937500\n",
      "Epoch:11 [120|160] loss:0.060144 acc:1.000000\n",
      "Epoch:11 [121|160] loss:0.016814 acc:1.000000\n",
      "Epoch:11 [122|160] loss:0.012687 acc:1.000000\n",
      "Epoch:11 [123|160] loss:0.027159 acc:1.000000\n",
      "Epoch:11 [124|160] loss:0.019803 acc:1.000000\n",
      "Epoch:11 [125|160] loss:0.239061 acc:0.937500\n",
      "Epoch:11 [126|160] loss:0.011739 acc:1.000000\n",
      "Epoch:11 [127|160] loss:0.010761 acc:1.000000\n",
      "Epoch:11 [128|160] loss:0.020539 acc:1.000000\n",
      "Epoch:11 [129|160] loss:0.035551 acc:1.000000\n",
      "Epoch:11 [130|160] loss:0.045661 acc:1.000000\n",
      "Epoch:11 [131|160] loss:0.304246 acc:0.937500\n",
      "Epoch:11 [132|160] loss:0.016179 acc:1.000000\n",
      "Epoch:11 [133|160] loss:0.013600 acc:1.000000\n",
      "Epoch:11 [134|160] loss:0.008118 acc:1.000000\n",
      "Epoch:11 [135|160] loss:0.074676 acc:0.937500\n",
      "Epoch:11 [136|160] loss:0.212909 acc:0.937500\n",
      "Epoch:11 [137|160] loss:0.021899 acc:1.000000\n",
      "Epoch:11 [138|160] loss:0.013108 acc:1.000000\n",
      "Epoch:11 [139|160] loss:0.011656 acc:1.000000\n",
      "Epoch:11 [140|160] loss:0.016547 acc:1.000000\n",
      "Epoch:11 [141|160] loss:0.103400 acc:0.937500\n",
      "Epoch:11 [142|160] loss:0.025876 acc:1.000000\n",
      "Epoch:11 [143|160] loss:0.011207 acc:1.000000\n",
      "Epoch:11 [144|160] loss:0.214279 acc:0.937500\n",
      "Epoch:11 [145|160] loss:0.015200 acc:1.000000\n",
      "Epoch:11 [146|160] loss:0.243225 acc:0.937500\n",
      "Epoch:11 [147|160] loss:0.013737 acc:1.000000\n",
      "Epoch:11 [148|160] loss:0.093055 acc:0.937500\n",
      "Epoch:11 [149|160] loss:0.050188 acc:1.000000\n",
      "Epoch:11 [150|160] loss:0.089919 acc:0.937500\n",
      "Epoch:11 [151|160] loss:0.017187 acc:1.000000\n",
      "Epoch:11 [152|160] loss:0.007269 acc:1.000000\n",
      "Epoch:11 [153|160] loss:0.047052 acc:1.000000\n",
      "Epoch:11 [154|160] loss:0.244584 acc:0.875000\n",
      "Epoch:11 [155|160] loss:0.054949 acc:1.000000\n",
      "Epoch:11 [156|160] loss:0.019586 acc:1.000000\n",
      "Epoch:11 [157|160] loss:0.013126 acc:1.000000\n",
      "Epoch:11 [158|160] loss:0.079787 acc:0.937500\n",
      "Epoch:11 [159|160] loss:0.010508 acc:1.000000\n",
      "\n",
      "Validation Epoch: 11\n",
      "Acc: 0.973396 \n",
      "\n",
      "Epoch: 12\n",
      "Epoch:12 [0|160] loss:0.126079 acc:0.937500\n",
      "Epoch:12 [1|160] loss:0.017800 acc:1.000000\n",
      "Epoch:12 [2|160] loss:0.014451 acc:1.000000\n",
      "Epoch:12 [3|160] loss:0.044298 acc:1.000000\n",
      "Epoch:12 [4|160] loss:0.022935 acc:1.000000\n",
      "Epoch:12 [5|160] loss:0.043751 acc:1.000000\n",
      "Epoch:12 [6|160] loss:0.021248 acc:1.000000\n",
      "Epoch:12 [7|160] loss:0.017731 acc:1.000000\n",
      "Epoch:12 [8|160] loss:0.016447 acc:1.000000\n",
      "Epoch:12 [9|160] loss:0.006479 acc:1.000000\n",
      "Epoch:12 [10|160] loss:0.009148 acc:1.000000\n",
      "Epoch:12 [11|160] loss:0.017734 acc:1.000000\n",
      "Epoch:12 [12|160] loss:0.011245 acc:1.000000\n",
      "Epoch:12 [13|160] loss:0.013376 acc:1.000000\n",
      "Epoch:12 [14|160] loss:0.029540 acc:1.000000\n",
      "Epoch:12 [15|160] loss:0.012170 acc:1.000000\n",
      "Epoch:12 [16|160] loss:0.013516 acc:1.000000\n",
      "Epoch:12 [17|160] loss:0.017289 acc:1.000000\n",
      "Epoch:12 [18|160] loss:0.020526 acc:1.000000\n",
      "Epoch:12 [19|160] loss:0.093520 acc:0.937500\n",
      "Epoch:12 [20|160] loss:0.021765 acc:1.000000\n",
      "Epoch:12 [21|160] loss:0.064788 acc:0.937500\n",
      "Epoch:12 [22|160] loss:0.013299 acc:1.000000\n",
      "Epoch:12 [23|160] loss:0.017798 acc:1.000000\n",
      "Epoch:12 [24|160] loss:0.018581 acc:1.000000\n",
      "Epoch:12 [25|160] loss:0.044740 acc:1.000000\n",
      "Epoch:12 [26|160] loss:0.008900 acc:1.000000\n",
      "Epoch:12 [27|160] loss:0.022086 acc:1.000000\n",
      "Epoch:12 [28|160] loss:0.011835 acc:1.000000\n",
      "Epoch:12 [29|160] loss:0.012718 acc:1.000000\n",
      "Epoch:12 [30|160] loss:0.012471 acc:1.000000\n",
      "Epoch:12 [31|160] loss:0.012598 acc:1.000000\n",
      "Epoch:12 [32|160] loss:0.074277 acc:0.937500\n",
      "Epoch:12 [33|160] loss:0.021990 acc:1.000000\n",
      "Epoch:12 [34|160] loss:0.030254 acc:1.000000\n",
      "Epoch:12 [35|160] loss:0.119015 acc:0.937500\n",
      "Epoch:12 [36|160] loss:0.045267 acc:1.000000\n",
      "Epoch:12 [37|160] loss:0.011968 acc:1.000000\n",
      "Epoch:12 [38|160] loss:0.015115 acc:1.000000\n",
      "Epoch:12 [39|160] loss:0.014050 acc:1.000000\n",
      "Epoch:12 [40|160] loss:0.089709 acc:0.937500\n",
      "Epoch:12 [41|160] loss:0.016850 acc:1.000000\n",
      "Epoch:12 [42|160] loss:0.038979 acc:1.000000\n",
      "Epoch:12 [43|160] loss:0.172688 acc:0.937500\n",
      "Epoch:12 [44|160] loss:0.010061 acc:1.000000\n",
      "Epoch:12 [45|160] loss:0.009278 acc:1.000000\n",
      "Epoch:12 [46|160] loss:0.088886 acc:0.937500\n",
      "Epoch:12 [47|160] loss:0.006643 acc:1.000000\n",
      "Epoch:12 [48|160] loss:0.015076 acc:1.000000\n",
      "Epoch:12 [49|160] loss:0.068306 acc:0.937500\n",
      "Epoch:12 [50|160] loss:0.049254 acc:1.000000\n",
      "Epoch:12 [51|160] loss:0.019681 acc:1.000000\n",
      "Epoch:12 [52|160] loss:0.238266 acc:0.937500\n",
      "Epoch:12 [53|160] loss:0.010018 acc:1.000000\n",
      "Epoch:12 [54|160] loss:0.026537 acc:1.000000\n",
      "Epoch:12 [55|160] loss:0.046128 acc:1.000000\n",
      "Epoch:12 [56|160] loss:0.011694 acc:1.000000\n",
      "Epoch:12 [57|160] loss:0.023098 acc:1.000000\n",
      "Epoch:12 [58|160] loss:0.021200 acc:1.000000\n",
      "Epoch:12 [59|160] loss:0.148168 acc:0.937500\n",
      "Epoch:12 [60|160] loss:0.210564 acc:0.937500\n",
      "Epoch:12 [61|160] loss:0.061345 acc:0.937500\n",
      "Epoch:12 [62|160] loss:0.041163 acc:1.000000\n",
      "Epoch:12 [63|160] loss:0.030009 acc:1.000000\n",
      "Epoch:12 [64|160] loss:0.027376 acc:1.000000\n",
      "Epoch:12 [65|160] loss:0.013230 acc:1.000000\n",
      "Epoch:12 [66|160] loss:0.018818 acc:1.000000\n",
      "Epoch:12 [67|160] loss:0.036176 acc:1.000000\n",
      "Epoch:12 [68|160] loss:0.021088 acc:1.000000\n",
      "Epoch:12 [69|160] loss:0.019721 acc:1.000000\n",
      "Epoch:12 [70|160] loss:0.070740 acc:0.937500\n",
      "Epoch:12 [71|160] loss:0.014907 acc:1.000000\n",
      "Epoch:12 [72|160] loss:0.014975 acc:1.000000\n",
      "Epoch:12 [73|160] loss:0.026211 acc:1.000000\n",
      "Epoch:12 [74|160] loss:0.055764 acc:0.937500\n",
      "Epoch:12 [75|160] loss:0.087899 acc:0.937500\n",
      "Epoch:12 [76|160] loss:0.021122 acc:1.000000\n",
      "Epoch:12 [77|160] loss:0.111514 acc:0.937500\n",
      "Epoch:12 [78|160] loss:0.086141 acc:0.937500\n",
      "Epoch:12 [79|160] loss:0.229283 acc:0.937500\n",
      "Epoch:12 [80|160] loss:0.016040 acc:1.000000\n",
      "Epoch:12 [81|160] loss:0.051276 acc:1.000000\n",
      "Epoch:12 [82|160] loss:0.013308 acc:1.000000\n",
      "Epoch:12 [83|160] loss:0.034163 acc:1.000000\n",
      "Epoch:12 [84|160] loss:0.192219 acc:0.937500\n",
      "Epoch:12 [85|160] loss:0.034892 acc:1.000000\n",
      "Epoch:12 [86|160] loss:0.014436 acc:1.000000\n",
      "Epoch:12 [87|160] loss:0.014436 acc:1.000000\n",
      "Epoch:12 [88|160] loss:0.008618 acc:1.000000\n",
      "Epoch:12 [89|160] loss:0.009782 acc:1.000000\n",
      "Epoch:12 [90|160] loss:0.018016 acc:1.000000\n",
      "Epoch:12 [91|160] loss:0.022620 acc:1.000000\n",
      "Epoch:12 [92|160] loss:0.009624 acc:1.000000\n",
      "Epoch:12 [93|160] loss:0.021136 acc:1.000000\n",
      "Epoch:12 [94|160] loss:0.064619 acc:0.937500\n",
      "Epoch:12 [95|160] loss:0.009618 acc:1.000000\n",
      "Epoch:12 [96|160] loss:0.012728 acc:1.000000\n",
      "Epoch:12 [97|160] loss:0.014284 acc:1.000000\n",
      "Epoch:12 [98|160] loss:0.016101 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12 [99|160] loss:0.013686 acc:1.000000\n",
      "Epoch:12 [100|160] loss:0.012134 acc:1.000000\n",
      "Epoch:12 [101|160] loss:0.028105 acc:1.000000\n",
      "Epoch:12 [102|160] loss:0.247902 acc:0.937500\n",
      "Epoch:12 [103|160] loss:0.071599 acc:0.937500\n",
      "Epoch:12 [104|160] loss:0.026895 acc:1.000000\n",
      "Epoch:12 [105|160] loss:0.042253 acc:1.000000\n",
      "Epoch:12 [106|160] loss:0.017083 acc:1.000000\n",
      "Epoch:12 [107|160] loss:0.011895 acc:1.000000\n",
      "Epoch:12 [108|160] loss:0.032139 acc:1.000000\n",
      "Epoch:12 [109|160] loss:0.026253 acc:1.000000\n",
      "Epoch:12 [110|160] loss:0.036266 acc:1.000000\n",
      "Epoch:12 [111|160] loss:0.012175 acc:1.000000\n",
      "Epoch:12 [112|160] loss:0.023974 acc:1.000000\n",
      "Epoch:12 [113|160] loss:0.016182 acc:1.000000\n",
      "Epoch:12 [114|160] loss:0.023551 acc:1.000000\n",
      "Epoch:12 [115|160] loss:0.038861 acc:1.000000\n",
      "Epoch:12 [116|160] loss:0.124762 acc:0.937500\n",
      "Epoch:12 [117|160] loss:0.010450 acc:1.000000\n",
      "Epoch:12 [118|160] loss:0.015293 acc:1.000000\n",
      "Epoch:12 [119|160] loss:0.206042 acc:0.937500\n",
      "Epoch:12 [120|160] loss:0.015616 acc:1.000000\n",
      "Epoch:12 [121|160] loss:0.145787 acc:0.937500\n",
      "Epoch:12 [122|160] loss:0.009878 acc:1.000000\n",
      "Epoch:12 [123|160] loss:0.027628 acc:1.000000\n",
      "Epoch:12 [124|160] loss:0.013986 acc:1.000000\n",
      "Epoch:12 [125|160] loss:0.028196 acc:1.000000\n",
      "Epoch:12 [126|160] loss:0.014921 acc:1.000000\n",
      "Epoch:12 [127|160] loss:0.013747 acc:1.000000\n",
      "Epoch:12 [128|160] loss:0.267959 acc:0.937500\n",
      "Epoch:12 [129|160] loss:0.023595 acc:1.000000\n",
      "Epoch:12 [130|160] loss:0.050915 acc:1.000000\n",
      "Epoch:12 [131|160] loss:0.014039 acc:1.000000\n",
      "Epoch:12 [132|160] loss:0.042574 acc:1.000000\n",
      "Epoch:12 [133|160] loss:0.012215 acc:1.000000\n",
      "Epoch:12 [134|160] loss:0.016205 acc:1.000000\n",
      "Epoch:12 [135|160] loss:0.061032 acc:0.937500\n",
      "Epoch:12 [136|160] loss:0.012447 acc:1.000000\n",
      "Epoch:12 [137|160] loss:0.017102 acc:1.000000\n",
      "Epoch:12 [138|160] loss:0.009050 acc:1.000000\n",
      "Epoch:12 [139|160] loss:0.013309 acc:1.000000\n",
      "Epoch:12 [140|160] loss:0.011471 acc:1.000000\n",
      "Epoch:12 [141|160] loss:0.018311 acc:1.000000\n",
      "Epoch:12 [142|160] loss:0.015900 acc:1.000000\n",
      "Epoch:12 [143|160] loss:0.010944 acc:1.000000\n",
      "Epoch:12 [144|160] loss:0.020964 acc:1.000000\n",
      "Epoch:12 [145|160] loss:0.011664 acc:1.000000\n",
      "Epoch:12 [146|160] loss:0.106123 acc:0.937500\n",
      "Epoch:12 [147|160] loss:0.025423 acc:1.000000\n",
      "Epoch:12 [148|160] loss:0.014292 acc:1.000000\n",
      "Epoch:12 [149|160] loss:0.018772 acc:1.000000\n",
      "Epoch:12 [150|160] loss:0.028021 acc:1.000000\n",
      "Epoch:12 [151|160] loss:0.023280 acc:1.000000\n",
      "Epoch:12 [152|160] loss:0.028153 acc:1.000000\n",
      "Epoch:12 [153|160] loss:0.010497 acc:1.000000\n",
      "Epoch:12 [154|160] loss:0.022035 acc:1.000000\n",
      "Epoch:12 [155|160] loss:0.033999 acc:1.000000\n",
      "Epoch:12 [156|160] loss:0.014578 acc:1.000000\n",
      "Epoch:12 [157|160] loss:0.023115 acc:1.000000\n",
      "Epoch:12 [158|160] loss:0.016826 acc:1.000000\n",
      "Epoch:12 [159|160] loss:0.046667 acc:1.000000\n",
      "\n",
      "Validation Epoch: 12\n",
      "Acc: 0.971831 \n",
      "\n",
      "Epoch: 13\n",
      "Epoch:13 [0|160] loss:0.008386 acc:1.000000\n",
      "Epoch:13 [1|160] loss:0.009084 acc:1.000000\n",
      "Epoch:13 [2|160] loss:0.013712 acc:1.000000\n",
      "Epoch:13 [3|160] loss:0.020341 acc:1.000000\n",
      "Epoch:13 [4|160] loss:0.019911 acc:1.000000\n",
      "Epoch:13 [5|160] loss:0.014078 acc:1.000000\n",
      "Epoch:13 [6|160] loss:0.008980 acc:1.000000\n",
      "Epoch:13 [7|160] loss:0.021871 acc:1.000000\n",
      "Epoch:13 [8|160] loss:0.380385 acc:0.875000\n",
      "Epoch:13 [9|160] loss:0.007893 acc:1.000000\n",
      "Epoch:13 [10|160] loss:0.011464 acc:1.000000\n",
      "Epoch:13 [11|160] loss:0.286718 acc:0.937500\n",
      "Epoch:13 [12|160] loss:0.010180 acc:1.000000\n",
      "Epoch:13 [13|160] loss:0.020299 acc:1.000000\n",
      "Epoch:13 [14|160] loss:0.068474 acc:0.937500\n",
      "Epoch:13 [15|160] loss:0.064724 acc:0.937500\n",
      "Epoch:13 [16|160] loss:0.206362 acc:0.937500\n",
      "Epoch:13 [17|160] loss:0.028998 acc:1.000000\n",
      "Epoch:13 [18|160] loss:0.040913 acc:1.000000\n",
      "Epoch:13 [19|160] loss:0.017228 acc:1.000000\n",
      "Epoch:13 [20|160] loss:0.025726 acc:1.000000\n",
      "Epoch:13 [21|160] loss:0.008932 acc:1.000000\n",
      "Epoch:13 [22|160] loss:0.009627 acc:1.000000\n",
      "Epoch:13 [23|160] loss:0.011063 acc:1.000000\n",
      "Epoch:13 [24|160] loss:0.017381 acc:1.000000\n",
      "Epoch:13 [25|160] loss:0.013210 acc:1.000000\n",
      "Epoch:13 [26|160] loss:0.008440 acc:1.000000\n",
      "Epoch:13 [27|160] loss:0.031282 acc:1.000000\n",
      "Epoch:13 [28|160] loss:0.013302 acc:1.000000\n",
      "Epoch:13 [29|160] loss:0.035432 acc:1.000000\n",
      "Epoch:13 [30|160] loss:0.281998 acc:0.937500\n",
      "Epoch:13 [31|160] loss:0.010481 acc:1.000000\n",
      "Epoch:13 [32|160] loss:0.010370 acc:1.000000\n",
      "Epoch:13 [33|160] loss:0.019820 acc:1.000000\n",
      "Epoch:13 [34|160] loss:0.041205 acc:1.000000\n",
      "Epoch:13 [35|160] loss:0.036129 acc:1.000000\n",
      "Epoch:13 [36|160] loss:0.012883 acc:1.000000\n",
      "Epoch:13 [37|160] loss:0.023781 acc:1.000000\n",
      "Epoch:13 [38|160] loss:0.023915 acc:1.000000\n",
      "Epoch:13 [39|160] loss:0.010153 acc:1.000000\n",
      "Epoch:13 [40|160] loss:0.060878 acc:0.937500\n",
      "Epoch:13 [41|160] loss:0.009935 acc:1.000000\n",
      "Epoch:13 [42|160] loss:0.012876 acc:1.000000\n",
      "Epoch:13 [43|160] loss:0.074033 acc:1.000000\n",
      "Epoch:13 [44|160] loss:0.024737 acc:1.000000\n",
      "Epoch:13 [45|160] loss:0.188783 acc:0.937500\n",
      "Epoch:13 [46|160] loss:0.012355 acc:1.000000\n",
      "Epoch:13 [47|160] loss:0.045023 acc:1.000000\n",
      "Epoch:13 [48|160] loss:0.019832 acc:1.000000\n",
      "Epoch:13 [49|160] loss:0.121510 acc:0.937500\n",
      "Epoch:13 [50|160] loss:0.008612 acc:1.000000\n",
      "Epoch:13 [51|160] loss:0.011945 acc:1.000000\n",
      "Epoch:13 [52|160] loss:0.008546 acc:1.000000\n",
      "Epoch:13 [53|160] loss:0.010066 acc:1.000000\n",
      "Epoch:13 [54|160] loss:0.010594 acc:1.000000\n",
      "Epoch:13 [55|160] loss:0.020800 acc:1.000000\n",
      "Epoch:13 [56|160] loss:0.008811 acc:1.000000\n",
      "Epoch:13 [57|160] loss:0.317607 acc:0.937500\n",
      "Epoch:13 [58|160] loss:0.011958 acc:1.000000\n",
      "Epoch:13 [59|160] loss:0.025973 acc:1.000000\n",
      "Epoch:13 [60|160] loss:0.053164 acc:1.000000\n",
      "Epoch:13 [61|160] loss:0.013769 acc:1.000000\n",
      "Epoch:13 [62|160] loss:0.008336 acc:1.000000\n",
      "Epoch:13 [63|160] loss:0.070413 acc:0.937500\n",
      "Epoch:13 [64|160] loss:0.014361 acc:1.000000\n",
      "Epoch:13 [65|160] loss:0.012068 acc:1.000000\n",
      "Epoch:13 [66|160] loss:0.197910 acc:0.937500\n",
      "Epoch:13 [67|160] loss:0.036262 acc:1.000000\n",
      "Epoch:13 [68|160] loss:0.021668 acc:1.000000\n",
      "Epoch:13 [69|160] loss:0.007818 acc:1.000000\n",
      "Epoch:13 [70|160] loss:0.021461 acc:1.000000\n",
      "Epoch:13 [71|160] loss:0.019633 acc:1.000000\n",
      "Epoch:13 [72|160] loss:0.041448 acc:1.000000\n",
      "Epoch:13 [73|160] loss:0.072737 acc:0.937500\n",
      "Epoch:13 [74|160] loss:0.117470 acc:0.937500\n",
      "Epoch:13 [75|160] loss:0.022675 acc:1.000000\n",
      "Epoch:13 [76|160] loss:0.019024 acc:1.000000\n",
      "Epoch:13 [77|160] loss:0.012480 acc:1.000000\n",
      "Epoch:13 [78|160] loss:0.015430 acc:1.000000\n",
      "Epoch:13 [79|160] loss:0.010915 acc:1.000000\n",
      "Epoch:13 [80|160] loss:0.020696 acc:1.000000\n",
      "Epoch:13 [81|160] loss:0.054565 acc:1.000000\n",
      "Epoch:13 [82|160] loss:0.012859 acc:1.000000\n",
      "Epoch:13 [83|160] loss:0.021643 acc:1.000000\n",
      "Epoch:13 [84|160] loss:0.034029 acc:1.000000\n",
      "Epoch:13 [85|160] loss:0.007841 acc:1.000000\n",
      "Epoch:13 [86|160] loss:0.018776 acc:1.000000\n",
      "Epoch:13 [87|160] loss:0.009371 acc:1.000000\n",
      "Epoch:13 [88|160] loss:0.016921 acc:1.000000\n",
      "Epoch:13 [89|160] loss:0.033065 acc:1.000000\n",
      "Epoch:13 [90|160] loss:0.017910 acc:1.000000\n",
      "Epoch:13 [91|160] loss:0.011962 acc:1.000000\n",
      "Epoch:13 [92|160] loss:0.005020 acc:1.000000\n",
      "Epoch:13 [93|160] loss:0.082095 acc:0.937500\n",
      "Epoch:13 [94|160] loss:0.040285 acc:1.000000\n",
      "Epoch:13 [95|160] loss:0.020687 acc:1.000000\n",
      "Epoch:13 [96|160] loss:0.208002 acc:0.937500\n",
      "Epoch:13 [97|160] loss:0.122645 acc:0.937500\n",
      "Epoch:13 [98|160] loss:0.009628 acc:1.000000\n",
      "Epoch:13 [99|160] loss:0.023916 acc:1.000000\n",
      "Epoch:13 [100|160] loss:0.149018 acc:0.937500\n",
      "Epoch:13 [101|160] loss:0.021395 acc:1.000000\n",
      "Epoch:13 [102|160] loss:0.029392 acc:1.000000\n",
      "Epoch:13 [103|160] loss:0.021321 acc:1.000000\n",
      "Epoch:13 [104|160] loss:0.011136 acc:1.000000\n",
      "Epoch:13 [105|160] loss:0.058648 acc:1.000000\n",
      "Epoch:13 [106|160] loss:0.009906 acc:1.000000\n",
      "Epoch:13 [107|160] loss:0.014841 acc:1.000000\n",
      "Epoch:13 [108|160] loss:0.127110 acc:0.937500\n",
      "Epoch:13 [109|160] loss:0.010640 acc:1.000000\n",
      "Epoch:13 [110|160] loss:0.059068 acc:0.937500\n",
      "Epoch:13 [111|160] loss:0.012091 acc:1.000000\n",
      "Epoch:13 [112|160] loss:0.021469 acc:1.000000\n",
      "Epoch:13 [113|160] loss:0.012888 acc:1.000000\n",
      "Epoch:13 [114|160] loss:0.011795 acc:1.000000\n",
      "Epoch:13 [115|160] loss:0.036277 acc:1.000000\n",
      "Epoch:13 [116|160] loss:0.012608 acc:1.000000\n",
      "Epoch:13 [117|160] loss:0.026103 acc:1.000000\n",
      "Epoch:13 [118|160] loss:0.012565 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13 [119|160] loss:0.020153 acc:1.000000\n",
      "Epoch:13 [120|160] loss:0.009943 acc:1.000000\n",
      "Epoch:13 [121|160] loss:0.054235 acc:1.000000\n",
      "Epoch:13 [122|160] loss:0.033386 acc:1.000000\n",
      "Epoch:13 [123|160] loss:0.058126 acc:0.937500\n",
      "Epoch:13 [124|160] loss:0.018239 acc:1.000000\n",
      "Epoch:13 [125|160] loss:0.010389 acc:1.000000\n",
      "Epoch:13 [126|160] loss:0.011517 acc:1.000000\n",
      "Epoch:13 [127|160] loss:0.016887 acc:1.000000\n",
      "Epoch:13 [128|160] loss:0.020930 acc:1.000000\n",
      "Epoch:13 [129|160] loss:0.010798 acc:1.000000\n",
      "Epoch:13 [130|160] loss:0.008438 acc:1.000000\n",
      "Epoch:13 [131|160] loss:0.014386 acc:1.000000\n",
      "Epoch:13 [132|160] loss:0.011521 acc:1.000000\n",
      "Epoch:13 [133|160] loss:0.015489 acc:1.000000\n",
      "Epoch:13 [134|160] loss:0.016399 acc:1.000000\n",
      "Epoch:13 [135|160] loss:0.024929 acc:1.000000\n",
      "Epoch:13 [136|160] loss:0.134357 acc:0.937500\n",
      "Epoch:13 [137|160] loss:0.012082 acc:1.000000\n",
      "Epoch:13 [138|160] loss:0.011024 acc:1.000000\n",
      "Epoch:13 [139|160] loss:0.147549 acc:0.937500\n",
      "Epoch:13 [140|160] loss:0.011942 acc:1.000000\n",
      "Epoch:13 [141|160] loss:0.016908 acc:1.000000\n",
      "Epoch:13 [142|160] loss:0.018296 acc:1.000000\n",
      "Epoch:13 [143|160] loss:0.012707 acc:1.000000\n",
      "Epoch:13 [144|160] loss:0.011414 acc:1.000000\n",
      "Epoch:13 [145|160] loss:0.436758 acc:0.875000\n",
      "Epoch:13 [146|160] loss:0.012365 acc:1.000000\n",
      "Epoch:13 [147|160] loss:0.015697 acc:1.000000\n",
      "Epoch:13 [148|160] loss:0.022269 acc:1.000000\n",
      "Epoch:13 [149|160] loss:0.099527 acc:0.937500\n",
      "Epoch:13 [150|160] loss:0.306754 acc:0.937500\n",
      "Epoch:13 [151|160] loss:0.010594 acc:1.000000\n",
      "Epoch:13 [152|160] loss:0.008751 acc:1.000000\n",
      "Epoch:13 [153|160] loss:0.017927 acc:1.000000\n",
      "Epoch:13 [154|160] loss:0.009018 acc:1.000000\n",
      "Epoch:13 [155|160] loss:0.034011 acc:1.000000\n",
      "Epoch:13 [156|160] loss:0.013462 acc:1.000000\n",
      "Epoch:13 [157|160] loss:0.016282 acc:1.000000\n",
      "Epoch:13 [158|160] loss:0.009103 acc:1.000000\n",
      "Epoch:13 [159|160] loss:0.007611 acc:1.000000\n",
      "\n",
      "Validation Epoch: 13\n",
      "Acc: 0.964006 \n",
      "\n",
      "Epoch: 14\n",
      "Epoch:14 [0|160] loss:0.032402 acc:1.000000\n",
      "Epoch:14 [1|160] loss:0.018695 acc:1.000000\n",
      "Epoch:14 [2|160] loss:0.032315 acc:1.000000\n",
      "Epoch:14 [3|160] loss:0.027382 acc:1.000000\n",
      "Epoch:14 [4|160] loss:0.034774 acc:1.000000\n",
      "Epoch:14 [5|160] loss:0.015139 acc:1.000000\n",
      "Epoch:14 [6|160] loss:0.007892 acc:1.000000\n",
      "Epoch:14 [7|160] loss:0.012680 acc:1.000000\n",
      "Epoch:14 [8|160] loss:0.035988 acc:1.000000\n",
      "Epoch:14 [9|160] loss:0.011112 acc:1.000000\n",
      "Epoch:14 [10|160] loss:0.052283 acc:1.000000\n",
      "Epoch:14 [11|160] loss:0.060276 acc:0.937500\n",
      "Epoch:14 [12|160] loss:0.013045 acc:1.000000\n",
      "Epoch:14 [13|160] loss:0.014851 acc:1.000000\n",
      "Epoch:14 [14|160] loss:0.010333 acc:1.000000\n",
      "Epoch:14 [15|160] loss:0.042700 acc:1.000000\n",
      "Epoch:14 [16|160] loss:0.015166 acc:1.000000\n",
      "Epoch:14 [17|160] loss:0.004267 acc:1.000000\n",
      "Epoch:14 [18|160] loss:0.006967 acc:1.000000\n",
      "Epoch:14 [19|160] loss:0.056571 acc:1.000000\n",
      "Epoch:14 [20|160] loss:0.114619 acc:0.937500\n",
      "Epoch:14 [21|160] loss:0.013227 acc:1.000000\n",
      "Epoch:14 [22|160] loss:0.009944 acc:1.000000\n",
      "Epoch:14 [23|160] loss:0.054754 acc:1.000000\n",
      "Epoch:14 [24|160] loss:0.042059 acc:1.000000\n",
      "Epoch:14 [25|160] loss:0.020165 acc:1.000000\n",
      "Epoch:14 [26|160] loss:0.012529 acc:1.000000\n",
      "Epoch:14 [27|160] loss:0.007396 acc:1.000000\n",
      "Epoch:14 [28|160] loss:0.048757 acc:1.000000\n",
      "Epoch:14 [29|160] loss:0.009829 acc:1.000000\n",
      "Epoch:14 [30|160] loss:0.033867 acc:1.000000\n",
      "Epoch:14 [31|160] loss:0.009122 acc:1.000000\n",
      "Epoch:14 [32|160] loss:0.015835 acc:1.000000\n",
      "Epoch:14 [33|160] loss:0.011086 acc:1.000000\n",
      "Epoch:14 [34|160] loss:0.016671 acc:1.000000\n",
      "Epoch:14 [35|160] loss:0.017341 acc:1.000000\n",
      "Epoch:14 [36|160] loss:0.228566 acc:0.875000\n",
      "Epoch:14 [37|160] loss:0.013212 acc:1.000000\n",
      "Epoch:14 [38|160] loss:0.026577 acc:1.000000\n",
      "Epoch:14 [39|160] loss:0.014633 acc:1.000000\n",
      "Epoch:14 [40|160] loss:0.010167 acc:1.000000\n",
      "Epoch:14 [41|160] loss:0.102750 acc:0.937500\n",
      "Epoch:14 [42|160] loss:0.011698 acc:1.000000\n",
      "Epoch:14 [43|160] loss:0.010995 acc:1.000000\n",
      "Epoch:14 [44|160] loss:0.012543 acc:1.000000\n",
      "Epoch:14 [45|160] loss:0.193695 acc:0.937500\n",
      "Epoch:14 [46|160] loss:0.015160 acc:1.000000\n",
      "Epoch:14 [47|160] loss:0.012881 acc:1.000000\n",
      "Epoch:14 [48|160] loss:0.062878 acc:0.937500\n",
      "Epoch:14 [49|160] loss:0.116043 acc:0.937500\n",
      "Epoch:14 [50|160] loss:0.016270 acc:1.000000\n",
      "Epoch:14 [51|160] loss:0.007945 acc:1.000000\n",
      "Epoch:14 [52|160] loss:0.007276 acc:1.000000\n",
      "Epoch:14 [53|160] loss:0.084606 acc:0.937500\n",
      "Epoch:14 [54|160] loss:0.014698 acc:1.000000\n",
      "Epoch:14 [55|160] loss:0.017312 acc:1.000000\n",
      "Epoch:14 [56|160] loss:0.020819 acc:1.000000\n",
      "Epoch:14 [57|160] loss:0.009544 acc:1.000000\n",
      "Epoch:14 [58|160] loss:0.008833 acc:1.000000\n",
      "Epoch:14 [59|160] loss:0.008175 acc:1.000000\n",
      "Epoch:14 [60|160] loss:0.008762 acc:1.000000\n",
      "Epoch:14 [61|160] loss:0.368066 acc:0.937500\n",
      "Epoch:14 [62|160] loss:0.033456 acc:1.000000\n",
      "Epoch:14 [63|160] loss:0.239539 acc:0.937500\n",
      "Epoch:14 [64|160] loss:0.015119 acc:1.000000\n",
      "Epoch:14 [65|160] loss:0.010390 acc:1.000000\n",
      "Epoch:14 [66|160] loss:0.006166 acc:1.000000\n",
      "Epoch:14 [67|160] loss:0.038172 acc:1.000000\n",
      "Epoch:14 [68|160] loss:0.012542 acc:1.000000\n",
      "Epoch:14 [69|160] loss:0.018594 acc:1.000000\n",
      "Epoch:14 [70|160] loss:0.025323 acc:1.000000\n",
      "Epoch:14 [71|160] loss:0.025180 acc:1.000000\n",
      "Epoch:14 [72|160] loss:0.017613 acc:1.000000\n",
      "Epoch:14 [73|160] loss:0.014603 acc:1.000000\n",
      "Epoch:14 [74|160] loss:0.192809 acc:0.937500\n",
      "Epoch:14 [75|160] loss:0.011872 acc:1.000000\n",
      "Epoch:14 [76|160] loss:0.010841 acc:1.000000\n",
      "Epoch:14 [77|160] loss:0.006323 acc:1.000000\n",
      "Epoch:14 [78|160] loss:0.009321 acc:1.000000\n",
      "Epoch:14 [79|160] loss:0.011490 acc:1.000000\n",
      "Epoch:14 [80|160] loss:0.022977 acc:1.000000\n",
      "Epoch:14 [81|160] loss:0.020249 acc:1.000000\n",
      "Epoch:14 [82|160] loss:0.025316 acc:1.000000\n",
      "Epoch:14 [83|160] loss:0.005952 acc:1.000000\n",
      "Epoch:14 [84|160] loss:0.008148 acc:1.000000\n",
      "Epoch:14 [85|160] loss:0.011362 acc:1.000000\n",
      "Epoch:14 [86|160] loss:0.019363 acc:1.000000\n",
      "Epoch:14 [87|160] loss:0.013952 acc:1.000000\n",
      "Epoch:14 [88|160] loss:0.006999 acc:1.000000\n",
      "Epoch:14 [89|160] loss:0.016527 acc:1.000000\n",
      "Epoch:14 [90|160] loss:0.014317 acc:1.000000\n",
      "Epoch:14 [91|160] loss:0.013364 acc:1.000000\n",
      "Epoch:14 [92|160] loss:0.012514 acc:1.000000\n",
      "Epoch:14 [93|160] loss:0.010391 acc:1.000000\n",
      "Epoch:14 [94|160] loss:0.012777 acc:1.000000\n",
      "Epoch:14 [95|160] loss:0.030547 acc:1.000000\n",
      "Epoch:14 [96|160] loss:0.243230 acc:0.875000\n",
      "Epoch:14 [97|160] loss:0.016671 acc:1.000000\n",
      "Epoch:14 [98|160] loss:0.017100 acc:1.000000\n",
      "Epoch:14 [99|160] loss:0.013424 acc:1.000000\n",
      "Epoch:14 [100|160] loss:0.013695 acc:1.000000\n",
      "Epoch:14 [101|160] loss:0.022901 acc:1.000000\n",
      "Epoch:14 [102|160] loss:0.112947 acc:0.937500\n",
      "Epoch:14 [103|160] loss:0.009632 acc:1.000000\n",
      "Epoch:14 [104|160] loss:0.009205 acc:1.000000\n",
      "Epoch:14 [105|160] loss:0.018533 acc:1.000000\n",
      "Epoch:14 [106|160] loss:0.018100 acc:1.000000\n",
      "Epoch:14 [107|160] loss:0.008444 acc:1.000000\n",
      "Epoch:14 [108|160] loss:0.017398 acc:1.000000\n",
      "Epoch:14 [109|160] loss:0.050400 acc:1.000000\n",
      "Epoch:14 [110|160] loss:0.043113 acc:1.000000\n",
      "Epoch:14 [111|160] loss:0.133709 acc:0.937500\n",
      "Epoch:14 [112|160] loss:0.027754 acc:1.000000\n",
      "Epoch:14 [113|160] loss:0.101861 acc:0.937500\n",
      "Epoch:14 [114|160] loss:0.095927 acc:0.937500\n",
      "Epoch:14 [115|160] loss:0.013376 acc:1.000000\n",
      "Epoch:14 [116|160] loss:0.007585 acc:1.000000\n",
      "Epoch:14 [117|160] loss:0.010234 acc:1.000000\n",
      "Epoch:14 [118|160] loss:0.036835 acc:1.000000\n",
      "Epoch:14 [119|160] loss:0.233446 acc:0.937500\n",
      "Epoch:14 [120|160] loss:0.094118 acc:0.937500\n",
      "Epoch:14 [121|160] loss:0.008262 acc:1.000000\n",
      "Epoch:14 [122|160] loss:0.020553 acc:1.000000\n",
      "Epoch:14 [123|160] loss:0.067149 acc:0.937500\n",
      "Epoch:14 [124|160] loss:0.007325 acc:1.000000\n",
      "Epoch:14 [125|160] loss:0.062721 acc:0.937500\n",
      "Epoch:14 [126|160] loss:0.009009 acc:1.000000\n",
      "Epoch:14 [127|160] loss:0.052086 acc:1.000000\n",
      "Epoch:14 [128|160] loss:0.041555 acc:1.000000\n",
      "Epoch:14 [129|160] loss:0.008523 acc:1.000000\n",
      "Epoch:14 [130|160] loss:0.052983 acc:1.000000\n",
      "Epoch:14 [131|160] loss:0.021110 acc:1.000000\n",
      "Epoch:14 [132|160] loss:0.009358 acc:1.000000\n",
      "Epoch:14 [133|160] loss:0.047626 acc:1.000000\n",
      "Epoch:14 [134|160] loss:0.019560 acc:1.000000\n",
      "Epoch:14 [135|160] loss:0.006818 acc:1.000000\n",
      "Epoch:14 [136|160] loss:0.029977 acc:1.000000\n",
      "Epoch:14 [137|160] loss:0.019989 acc:1.000000\n",
      "Epoch:14 [138|160] loss:0.011385 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14 [139|160] loss:0.028091 acc:1.000000\n",
      "Epoch:14 [140|160] loss:0.095746 acc:0.937500\n",
      "Epoch:14 [141|160] loss:0.014213 acc:1.000000\n",
      "Epoch:14 [142|160] loss:0.104938 acc:0.937500\n",
      "Epoch:14 [143|160] loss:0.010443 acc:1.000000\n",
      "Epoch:14 [144|160] loss:0.013091 acc:1.000000\n",
      "Epoch:14 [145|160] loss:0.016805 acc:1.000000\n",
      "Epoch:14 [146|160] loss:0.042612 acc:1.000000\n",
      "Epoch:14 [147|160] loss:0.033264 acc:1.000000\n",
      "Epoch:14 [148|160] loss:0.021353 acc:1.000000\n",
      "Epoch:14 [149|160] loss:0.008968 acc:1.000000\n",
      "Epoch:14 [150|160] loss:0.030627 acc:1.000000\n",
      "Epoch:14 [151|160] loss:0.243287 acc:0.937500\n",
      "Epoch:14 [152|160] loss:0.016512 acc:1.000000\n",
      "Epoch:14 [153|160] loss:0.020726 acc:1.000000\n",
      "Epoch:14 [154|160] loss:0.015992 acc:1.000000\n",
      "Epoch:14 [155|160] loss:0.013911 acc:1.000000\n",
      "Epoch:14 [156|160] loss:0.008621 acc:1.000000\n",
      "Epoch:14 [157|160] loss:0.037359 acc:1.000000\n",
      "Epoch:14 [158|160] loss:0.043058 acc:1.000000\n",
      "Epoch:14 [159|160] loss:0.009841 acc:1.000000\n",
      "\n",
      "Validation Epoch: 14\n",
      "Acc: 0.970266 \n",
      "\n",
      "Epoch: 15\n",
      "Epoch:15 [0|160] loss:0.012659 acc:1.000000\n",
      "Epoch:15 [1|160] loss:0.013183 acc:1.000000\n",
      "Epoch:15 [2|160] loss:0.017186 acc:1.000000\n",
      "Epoch:15 [3|160] loss:0.104244 acc:0.937500\n",
      "Epoch:15 [4|160] loss:0.014298 acc:1.000000\n",
      "Epoch:15 [5|160] loss:0.008330 acc:1.000000\n",
      "Epoch:15 [6|160] loss:0.020489 acc:1.000000\n",
      "Epoch:15 [7|160] loss:0.023709 acc:1.000000\n",
      "Epoch:15 [8|160] loss:0.182128 acc:0.937500\n",
      "Epoch:15 [9|160] loss:0.012431 acc:1.000000\n",
      "Epoch:15 [10|160] loss:0.023692 acc:1.000000\n",
      "Epoch:15 [11|160] loss:0.405527 acc:0.875000\n",
      "Epoch:15 [12|160] loss:0.044363 acc:1.000000\n",
      "Epoch:15 [13|160] loss:0.090197 acc:0.937500\n",
      "Epoch:15 [14|160] loss:0.010172 acc:1.000000\n",
      "Epoch:15 [15|160] loss:0.047440 acc:1.000000\n",
      "Epoch:15 [16|160] loss:0.013515 acc:1.000000\n",
      "Epoch:15 [17|160] loss:0.013286 acc:1.000000\n",
      "Epoch:15 [18|160] loss:0.012065 acc:1.000000\n",
      "Epoch:15 [19|160] loss:0.212070 acc:0.937500\n",
      "Epoch:15 [20|160] loss:0.010296 acc:1.000000\n",
      "Epoch:15 [21|160] loss:0.020382 acc:1.000000\n",
      "Epoch:15 [22|160] loss:0.012909 acc:1.000000\n",
      "Epoch:15 [23|160] loss:0.016647 acc:1.000000\n",
      "Epoch:15 [24|160] loss:0.025195 acc:1.000000\n",
      "Epoch:15 [25|160] loss:0.010958 acc:1.000000\n",
      "Epoch:15 [26|160] loss:0.006829 acc:1.000000\n",
      "Epoch:15 [27|160] loss:0.012014 acc:1.000000\n",
      "Epoch:15 [28|160] loss:0.023597 acc:1.000000\n",
      "Epoch:15 [29|160] loss:0.014197 acc:1.000000\n",
      "Epoch:15 [30|160] loss:0.007466 acc:1.000000\n",
      "Epoch:15 [31|160] loss:0.104447 acc:0.937500\n",
      "Epoch:15 [32|160] loss:0.011567 acc:1.000000\n",
      "Epoch:15 [33|160] loss:0.018750 acc:1.000000\n",
      "Epoch:15 [34|160] loss:0.008941 acc:1.000000\n",
      "Epoch:15 [35|160] loss:0.021671 acc:1.000000\n",
      "Epoch:15 [36|160] loss:0.009132 acc:1.000000\n",
      "Epoch:15 [37|160] loss:0.015599 acc:1.000000\n",
      "Epoch:15 [38|160] loss:0.008836 acc:1.000000\n",
      "Epoch:15 [39|160] loss:0.011241 acc:1.000000\n",
      "Epoch:15 [40|160] loss:0.011201 acc:1.000000\n",
      "Epoch:15 [41|160] loss:0.019132 acc:1.000000\n",
      "Epoch:15 [42|160] loss:0.008217 acc:1.000000\n",
      "Epoch:15 [43|160] loss:0.018044 acc:1.000000\n",
      "Epoch:15 [44|160] loss:0.025769 acc:1.000000\n",
      "Epoch:15 [45|160] loss:0.118665 acc:0.937500\n",
      "Epoch:15 [46|160] loss:0.027309 acc:1.000000\n",
      "Epoch:15 [47|160] loss:0.005922 acc:1.000000\n",
      "Epoch:15 [48|160] loss:0.014734 acc:1.000000\n",
      "Epoch:15 [49|160] loss:0.029112 acc:1.000000\n",
      "Epoch:15 [50|160] loss:0.090319 acc:0.937500\n",
      "Epoch:15 [51|160] loss:0.007208 acc:1.000000\n",
      "Epoch:15 [52|160] loss:0.059459 acc:1.000000\n",
      "Epoch:15 [53|160] loss:0.017061 acc:1.000000\n",
      "Epoch:15 [54|160] loss:0.016128 acc:1.000000\n",
      "Epoch:15 [55|160] loss:0.262912 acc:0.937500\n",
      "Epoch:15 [56|160] loss:0.073835 acc:0.937500\n",
      "Epoch:15 [57|160] loss:0.049358 acc:1.000000\n",
      "Epoch:15 [58|160] loss:0.006692 acc:1.000000\n",
      "Epoch:15 [59|160] loss:0.155565 acc:0.937500\n",
      "Epoch:15 [60|160] loss:0.009735 acc:1.000000\n",
      "Epoch:15 [61|160] loss:0.008721 acc:1.000000\n",
      "Epoch:15 [62|160] loss:0.138642 acc:0.937500\n",
      "Epoch:15 [63|160] loss:0.035233 acc:1.000000\n",
      "Epoch:15 [64|160] loss:0.022316 acc:1.000000\n",
      "Epoch:15 [65|160] loss:0.009290 acc:1.000000\n",
      "Epoch:15 [66|160] loss:0.013561 acc:1.000000\n",
      "Epoch:15 [67|160] loss:0.132915 acc:0.937500\n",
      "Epoch:15 [68|160] loss:0.009004 acc:1.000000\n",
      "Epoch:15 [69|160] loss:0.017573 acc:1.000000\n",
      "Epoch:15 [70|160] loss:0.010263 acc:1.000000\n",
      "Epoch:15 [71|160] loss:0.019447 acc:1.000000\n",
      "Epoch:15 [72|160] loss:0.044090 acc:1.000000\n",
      "Epoch:15 [73|160] loss:0.011689 acc:1.000000\n",
      "Epoch:15 [74|160] loss:0.013311 acc:1.000000\n",
      "Epoch:15 [75|160] loss:0.008355 acc:1.000000\n",
      "Epoch:15 [76|160] loss:0.011671 acc:1.000000\n",
      "Epoch:15 [77|160] loss:0.014568 acc:1.000000\n",
      "Epoch:15 [78|160] loss:0.015538 acc:1.000000\n",
      "Epoch:15 [79|160] loss:0.023740 acc:1.000000\n",
      "Epoch:15 [80|160] loss:0.016802 acc:1.000000\n",
      "Epoch:15 [81|160] loss:0.093497 acc:0.937500\n",
      "Epoch:15 [82|160] loss:0.051765 acc:0.937500\n",
      "Epoch:15 [83|160] loss:0.021081 acc:1.000000\n",
      "Epoch:15 [84|160] loss:0.014157 acc:1.000000\n",
      "Epoch:15 [85|160] loss:0.040724 acc:1.000000\n",
      "Epoch:15 [86|160] loss:0.012888 acc:1.000000\n",
      "Epoch:15 [87|160] loss:0.010587 acc:1.000000\n",
      "Epoch:15 [88|160] loss:0.014276 acc:1.000000\n",
      "Epoch:15 [89|160] loss:0.013054 acc:1.000000\n",
      "Epoch:15 [90|160] loss:0.019328 acc:1.000000\n",
      "Epoch:15 [91|160] loss:0.010233 acc:1.000000\n",
      "Epoch:15 [92|160] loss:0.037179 acc:1.000000\n",
      "Epoch:15 [93|160] loss:0.061634 acc:1.000000\n",
      "Epoch:15 [94|160] loss:0.359418 acc:0.937500\n",
      "Epoch:15 [95|160] loss:0.023288 acc:1.000000\n",
      "Epoch:15 [96|160] loss:0.010241 acc:1.000000\n",
      "Epoch:15 [97|160] loss:0.159277 acc:0.937500\n",
      "Epoch:15 [98|160] loss:0.011719 acc:1.000000\n",
      "Epoch:15 [99|160] loss:0.262098 acc:0.875000\n",
      "Epoch:15 [100|160] loss:0.060105 acc:0.937500\n",
      "Epoch:15 [101|160] loss:0.012260 acc:1.000000\n",
      "Epoch:15 [102|160] loss:0.017557 acc:1.000000\n",
      "Epoch:15 [103|160] loss:0.014790 acc:1.000000\n",
      "Epoch:15 [104|160] loss:0.012008 acc:1.000000\n",
      "Epoch:15 [105|160] loss:0.022243 acc:1.000000\n",
      "Epoch:15 [106|160] loss:0.007560 acc:1.000000\n",
      "Epoch:15 [107|160] loss:0.055654 acc:1.000000\n",
      "Epoch:15 [108|160] loss:0.018417 acc:1.000000\n",
      "Epoch:15 [109|160] loss:0.010939 acc:1.000000\n",
      "Epoch:15 [110|160] loss:0.008547 acc:1.000000\n",
      "Epoch:15 [111|160] loss:0.219091 acc:0.937500\n",
      "Epoch:15 [112|160] loss:0.007477 acc:1.000000\n",
      "Epoch:15 [113|160] loss:0.013168 acc:1.000000\n",
      "Epoch:15 [114|160] loss:0.035537 acc:1.000000\n",
      "Epoch:15 [115|160] loss:0.016902 acc:1.000000\n",
      "Epoch:15 [116|160] loss:0.028148 acc:1.000000\n",
      "Epoch:15 [117|160] loss:0.022168 acc:1.000000\n",
      "Epoch:15 [118|160] loss:0.013962 acc:1.000000\n",
      "Epoch:15 [119|160] loss:0.011956 acc:1.000000\n",
      "Epoch:15 [120|160] loss:0.009640 acc:1.000000\n",
      "Epoch:15 [121|160] loss:0.035083 acc:1.000000\n",
      "Epoch:15 [122|160] loss:0.026594 acc:1.000000\n",
      "Epoch:15 [123|160] loss:0.006340 acc:1.000000\n",
      "Epoch:15 [124|160] loss:0.009601 acc:1.000000\n",
      "Epoch:15 [125|160] loss:0.016461 acc:1.000000\n",
      "Epoch:15 [126|160] loss:0.104091 acc:0.937500\n",
      "Epoch:15 [127|160] loss:0.020107 acc:1.000000\n",
      "Epoch:15 [128|160] loss:0.028558 acc:1.000000\n",
      "Epoch:15 [129|160] loss:0.011914 acc:1.000000\n",
      "Epoch:15 [130|160] loss:0.026496 acc:1.000000\n",
      "Epoch:15 [131|160] loss:0.008938 acc:1.000000\n",
      "Epoch:15 [132|160] loss:0.009317 acc:1.000000\n",
      "Epoch:15 [133|160] loss:0.027517 acc:1.000000\n",
      "Epoch:15 [134|160] loss:0.015653 acc:1.000000\n",
      "Epoch:15 [135|160] loss:0.208314 acc:0.937500\n",
      "Epoch:15 [136|160] loss:0.015924 acc:1.000000\n",
      "Epoch:15 [137|160] loss:0.022087 acc:1.000000\n",
      "Epoch:15 [138|160] loss:0.004690 acc:1.000000\n",
      "Epoch:15 [139|160] loss:0.024044 acc:1.000000\n",
      "Epoch:15 [140|160] loss:0.017018 acc:1.000000\n",
      "Epoch:15 [141|160] loss:0.008961 acc:1.000000\n",
      "Epoch:15 [142|160] loss:0.010229 acc:1.000000\n",
      "Epoch:15 [143|160] loss:0.052454 acc:1.000000\n",
      "Epoch:15 [144|160] loss:0.024798 acc:1.000000\n",
      "Epoch:15 [145|160] loss:0.023329 acc:1.000000\n",
      "Epoch:15 [146|160] loss:0.006246 acc:1.000000\n",
      "Epoch:15 [147|160] loss:0.010958 acc:1.000000\n",
      "Epoch:15 [148|160] loss:0.053999 acc:1.000000\n",
      "Epoch:15 [149|160] loss:0.007758 acc:1.000000\n",
      "Epoch:15 [150|160] loss:0.009241 acc:1.000000\n",
      "Epoch:15 [151|160] loss:0.139722 acc:0.937500\n",
      "Epoch:15 [152|160] loss:0.020182 acc:1.000000\n",
      "Epoch:15 [153|160] loss:0.017662 acc:1.000000\n",
      "Epoch:15 [154|160] loss:0.007852 acc:1.000000\n",
      "Epoch:15 [155|160] loss:0.014516 acc:1.000000\n",
      "Epoch:15 [156|160] loss:0.234539 acc:0.937500\n",
      "Epoch:15 [157|160] loss:0.025853 acc:1.000000\n",
      "Epoch:15 [158|160] loss:0.032393 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15 [159|160] loss:0.008568 acc:1.000000\n",
      "\n",
      "Validation Epoch: 15\n",
      "Acc: 0.973396 \n",
      "\n",
      "Epoch: 16\n",
      "Epoch:16 [0|160] loss:0.031683 acc:1.000000\n",
      "Epoch:16 [1|160] loss:0.013251 acc:1.000000\n",
      "Epoch:16 [2|160] loss:0.007385 acc:1.000000\n",
      "Epoch:16 [3|160] loss:0.030781 acc:1.000000\n",
      "Epoch:16 [4|160] loss:0.014942 acc:1.000000\n",
      "Epoch:16 [5|160] loss:0.018223 acc:1.000000\n",
      "Epoch:16 [6|160] loss:0.010329 acc:1.000000\n",
      "Epoch:16 [7|160] loss:0.033916 acc:1.000000\n",
      "Epoch:16 [8|160] loss:0.035492 acc:1.000000\n",
      "Epoch:16 [9|160] loss:0.018873 acc:1.000000\n",
      "Epoch:16 [10|160] loss:0.012699 acc:1.000000\n",
      "Epoch:16 [11|160] loss:0.055862 acc:0.937500\n",
      "Epoch:16 [12|160] loss:0.009998 acc:1.000000\n",
      "Epoch:16 [13|160] loss:0.017654 acc:1.000000\n",
      "Epoch:16 [14|160] loss:0.008373 acc:1.000000\n",
      "Epoch:16 [15|160] loss:0.007118 acc:1.000000\n",
      "Epoch:16 [16|160] loss:0.008349 acc:1.000000\n",
      "Epoch:16 [17|160] loss:0.012351 acc:1.000000\n",
      "Epoch:16 [18|160] loss:0.037682 acc:1.000000\n",
      "Epoch:16 [19|160] loss:0.014881 acc:1.000000\n",
      "Epoch:16 [20|160] loss:0.011636 acc:1.000000\n",
      "Epoch:16 [21|160] loss:0.010442 acc:1.000000\n",
      "Epoch:16 [22|160] loss:0.020721 acc:1.000000\n",
      "Epoch:16 [23|160] loss:0.015615 acc:1.000000\n",
      "Epoch:16 [24|160] loss:0.012325 acc:1.000000\n",
      "Epoch:16 [25|160] loss:0.048554 acc:1.000000\n",
      "Epoch:16 [26|160] loss:0.011457 acc:1.000000\n",
      "Epoch:16 [27|160] loss:0.005714 acc:1.000000\n",
      "Epoch:16 [28|160] loss:0.014663 acc:1.000000\n",
      "Epoch:16 [29|160] loss:0.024968 acc:1.000000\n",
      "Epoch:16 [30|160] loss:0.175554 acc:0.875000\n",
      "Epoch:16 [31|160] loss:0.014144 acc:1.000000\n",
      "Epoch:16 [32|160] loss:0.008329 acc:1.000000\n",
      "Epoch:16 [33|160] loss:0.010432 acc:1.000000\n",
      "Epoch:16 [34|160] loss:0.070239 acc:0.937500\n",
      "Epoch:16 [35|160] loss:0.013229 acc:1.000000\n",
      "Epoch:16 [36|160] loss:0.159461 acc:0.937500\n",
      "Epoch:16 [37|160] loss:0.011411 acc:1.000000\n",
      "Epoch:16 [38|160] loss:0.010193 acc:1.000000\n",
      "Epoch:16 [39|160] loss:0.011053 acc:1.000000\n",
      "Epoch:16 [40|160] loss:0.018590 acc:1.000000\n",
      "Epoch:16 [41|160] loss:0.013323 acc:1.000000\n",
      "Epoch:16 [42|160] loss:0.026568 acc:1.000000\n",
      "Epoch:16 [43|160] loss:0.024627 acc:1.000000\n",
      "Epoch:16 [44|160] loss:0.012508 acc:1.000000\n",
      "Epoch:16 [45|160] loss:0.074349 acc:1.000000\n",
      "Epoch:16 [46|160] loss:0.087029 acc:0.937500\n",
      "Epoch:16 [47|160] loss:0.012291 acc:1.000000\n",
      "Epoch:16 [48|160] loss:0.008485 acc:1.000000\n",
      "Epoch:16 [49|160] loss:0.054272 acc:1.000000\n",
      "Epoch:16 [50|160] loss:0.007006 acc:1.000000\n",
      "Epoch:16 [51|160] loss:0.293569 acc:0.875000\n",
      "Epoch:16 [52|160] loss:0.010156 acc:1.000000\n",
      "Epoch:16 [53|160] loss:0.030868 acc:1.000000\n",
      "Epoch:16 [54|160] loss:0.021569 acc:1.000000\n",
      "Epoch:16 [55|160] loss:0.029719 acc:1.000000\n",
      "Epoch:16 [56|160] loss:0.029691 acc:1.000000\n",
      "Epoch:16 [57|160] loss:0.027356 acc:1.000000\n",
      "Epoch:16 [58|160] loss:0.015183 acc:1.000000\n",
      "Epoch:16 [59|160] loss:0.058872 acc:1.000000\n",
      "Epoch:16 [60|160] loss:0.143509 acc:0.937500\n",
      "Epoch:16 [61|160] loss:0.011354 acc:1.000000\n",
      "Epoch:16 [62|160] loss:0.007520 acc:1.000000\n",
      "Epoch:16 [63|160] loss:0.016320 acc:1.000000\n",
      "Epoch:16 [64|160] loss:0.075743 acc:0.937500\n",
      "Epoch:16 [65|160] loss:0.021541 acc:1.000000\n",
      "Epoch:16 [66|160] loss:0.017800 acc:1.000000\n",
      "Epoch:16 [67|160] loss:0.011654 acc:1.000000\n",
      "Epoch:16 [68|160] loss:0.012769 acc:1.000000\n",
      "Epoch:16 [69|160] loss:0.110041 acc:0.937500\n",
      "Epoch:16 [70|160] loss:0.171076 acc:0.937500\n",
      "Epoch:16 [71|160] loss:0.068172 acc:1.000000\n",
      "Epoch:16 [72|160] loss:0.016323 acc:1.000000\n",
      "Epoch:16 [73|160] loss:0.022393 acc:1.000000\n",
      "Epoch:16 [74|160] loss:0.020890 acc:1.000000\n",
      "Epoch:16 [75|160] loss:0.009695 acc:1.000000\n",
      "Epoch:16 [76|160] loss:0.009187 acc:1.000000\n",
      "Epoch:16 [77|160] loss:0.009703 acc:1.000000\n",
      "Epoch:16 [78|160] loss:0.056172 acc:0.937500\n",
      "Epoch:16 [79|160] loss:0.005794 acc:1.000000\n",
      "Epoch:16 [80|160] loss:0.083798 acc:0.937500\n",
      "Epoch:16 [81|160] loss:0.007631 acc:1.000000\n",
      "Epoch:16 [82|160] loss:0.008509 acc:1.000000\n",
      "Epoch:16 [83|160] loss:0.014716 acc:1.000000\n",
      "Epoch:16 [84|160] loss:0.047774 acc:1.000000\n",
      "Epoch:16 [85|160] loss:0.009784 acc:1.000000\n",
      "Epoch:16 [86|160] loss:0.084959 acc:0.937500\n",
      "Epoch:16 [87|160] loss:0.025102 acc:1.000000\n",
      "Epoch:16 [88|160] loss:0.014251 acc:1.000000\n",
      "Epoch:16 [89|160] loss:0.013893 acc:1.000000\n",
      "Epoch:16 [90|160] loss:0.016686 acc:1.000000\n",
      "Epoch:16 [91|160] loss:0.005301 acc:1.000000\n",
      "Epoch:16 [92|160] loss:0.010637 acc:1.000000\n",
      "Epoch:16 [93|160] loss:0.048580 acc:1.000000\n",
      "Epoch:16 [94|160] loss:0.008072 acc:1.000000\n",
      "Epoch:16 [95|160] loss:0.268683 acc:0.937500\n",
      "Epoch:16 [96|160] loss:0.010345 acc:1.000000\n",
      "Epoch:16 [97|160] loss:0.013250 acc:1.000000\n",
      "Epoch:16 [98|160] loss:0.090445 acc:0.937500\n",
      "Epoch:16 [99|160] loss:0.015603 acc:1.000000\n",
      "Epoch:16 [100|160] loss:0.020216 acc:1.000000\n",
      "Epoch:16 [101|160] loss:0.030405 acc:1.000000\n",
      "Epoch:16 [102|160] loss:0.014127 acc:1.000000\n",
      "Epoch:16 [103|160] loss:0.007665 acc:1.000000\n",
      "Epoch:16 [104|160] loss:0.012367 acc:1.000000\n",
      "Epoch:16 [105|160] loss:0.019823 acc:1.000000\n",
      "Epoch:16 [106|160] loss:0.039167 acc:1.000000\n",
      "Epoch:16 [107|160] loss:0.009215 acc:1.000000\n",
      "Epoch:16 [108|160] loss:0.004616 acc:1.000000\n",
      "Epoch:16 [109|160] loss:0.042184 acc:1.000000\n",
      "Epoch:16 [110|160] loss:0.014644 acc:1.000000\n",
      "Epoch:16 [111|160] loss:0.017082 acc:1.000000\n",
      "Epoch:16 [112|160] loss:0.233413 acc:0.937500\n",
      "Epoch:16 [113|160] loss:0.009713 acc:1.000000\n",
      "Epoch:16 [114|160] loss:0.046719 acc:1.000000\n",
      "Epoch:16 [115|160] loss:0.009964 acc:1.000000\n",
      "Epoch:16 [116|160] loss:0.015765 acc:1.000000\n",
      "Epoch:16 [117|160] loss:0.035205 acc:1.000000\n",
      "Epoch:16 [118|160] loss:0.012260 acc:1.000000\n",
      "Epoch:16 [119|160] loss:0.008530 acc:1.000000\n",
      "Epoch:16 [120|160] loss:0.014403 acc:1.000000\n",
      "Epoch:16 [121|160] loss:0.022837 acc:1.000000\n",
      "Epoch:16 [122|160] loss:0.011750 acc:1.000000\n",
      "Epoch:16 [123|160] loss:0.021680 acc:1.000000\n",
      "Epoch:16 [124|160] loss:0.008171 acc:1.000000\n",
      "Epoch:16 [125|160] loss:0.006681 acc:1.000000\n",
      "Epoch:16 [126|160] loss:0.052793 acc:1.000000\n",
      "Epoch:16 [127|160] loss:0.005616 acc:1.000000\n",
      "Epoch:16 [128|160] loss:0.005637 acc:1.000000\n",
      "Epoch:16 [129|160] loss:0.008263 acc:1.000000\n",
      "Epoch:16 [130|160] loss:0.011822 acc:1.000000\n",
      "Epoch:16 [131|160] loss:0.017026 acc:1.000000\n",
      "Epoch:16 [132|160] loss:0.016028 acc:1.000000\n",
      "Epoch:16 [133|160] loss:0.010582 acc:1.000000\n",
      "Epoch:16 [134|160] loss:0.017719 acc:1.000000\n",
      "Epoch:16 [135|160] loss:0.006865 acc:1.000000\n",
      "Epoch:16 [136|160] loss:0.061720 acc:0.937500\n",
      "Epoch:16 [137|160] loss:0.015637 acc:1.000000\n",
      "Epoch:16 [138|160] loss:0.011734 acc:1.000000\n",
      "Epoch:16 [139|160] loss:0.295053 acc:0.812500\n",
      "Epoch:16 [140|160] loss:0.037125 acc:1.000000\n",
      "Epoch:16 [141|160] loss:0.006238 acc:1.000000\n",
      "Epoch:16 [142|160] loss:0.007942 acc:1.000000\n",
      "Epoch:16 [143|160] loss:0.012420 acc:1.000000\n",
      "Epoch:16 [144|160] loss:0.018932 acc:1.000000\n",
      "Epoch:16 [145|160] loss:0.147179 acc:0.937500\n",
      "Epoch:16 [146|160] loss:0.004902 acc:1.000000\n",
      "Epoch:16 [147|160] loss:0.011924 acc:1.000000\n",
      "Epoch:16 [148|160] loss:0.008349 acc:1.000000\n",
      "Epoch:16 [149|160] loss:0.034751 acc:1.000000\n",
      "Epoch:16 [150|160] loss:0.145761 acc:0.937500\n",
      "Epoch:16 [151|160] loss:0.026398 acc:1.000000\n",
      "Epoch:16 [152|160] loss:0.245464 acc:0.937500\n",
      "Epoch:16 [153|160] loss:0.014378 acc:1.000000\n",
      "Epoch:16 [154|160] loss:0.007887 acc:1.000000\n",
      "Epoch:16 [155|160] loss:0.012889 acc:1.000000\n",
      "Epoch:16 [156|160] loss:0.135700 acc:0.937500\n",
      "Epoch:16 [157|160] loss:0.009378 acc:1.000000\n",
      "Epoch:16 [158|160] loss:0.013770 acc:1.000000\n",
      "Epoch:16 [159|160] loss:0.009536 acc:1.000000\n",
      "\n",
      "Validation Epoch: 16\n",
      "Acc: 0.968701 \n",
      "\n",
      "Epoch: 17\n",
      "Epoch:17 [0|160] loss:0.008517 acc:1.000000\n",
      "Epoch:17 [1|160] loss:0.010940 acc:1.000000\n",
      "Epoch:17 [2|160] loss:0.020407 acc:1.000000\n",
      "Epoch:17 [3|160] loss:0.007984 acc:1.000000\n",
      "Epoch:17 [4|160] loss:0.025387 acc:1.000000\n",
      "Epoch:17 [5|160] loss:0.032302 acc:1.000000\n",
      "Epoch:17 [6|160] loss:0.043644 acc:1.000000\n",
      "Epoch:17 [7|160] loss:0.007472 acc:1.000000\n",
      "Epoch:17 [8|160] loss:0.016595 acc:1.000000\n",
      "Epoch:17 [9|160] loss:0.011242 acc:1.000000\n",
      "Epoch:17 [10|160] loss:0.083363 acc:0.937500\n",
      "Epoch:17 [11|160] loss:0.008169 acc:1.000000\n",
      "Epoch:17 [12|160] loss:0.013724 acc:1.000000\n",
      "Epoch:17 [13|160] loss:0.010759 acc:1.000000\n",
      "Epoch:17 [14|160] loss:0.012085 acc:1.000000\n",
      "Epoch:17 [15|160] loss:0.007448 acc:1.000000\n",
      "Epoch:17 [16|160] loss:0.008216 acc:1.000000\n",
      "Epoch:17 [17|160] loss:0.023222 acc:1.000000\n",
      "Epoch:17 [18|160] loss:0.045616 acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17 [19|160] loss:0.022638 acc:1.000000\n",
      "Epoch:17 [20|160] loss:0.062127 acc:0.937500\n",
      "Epoch:17 [21|160] loss:0.011461 acc:1.000000\n",
      "Epoch:17 [22|160] loss:0.011599 acc:1.000000\n",
      "Epoch:17 [23|160] loss:0.005426 acc:1.000000\n",
      "Epoch:17 [24|160] loss:0.007857 acc:1.000000\n",
      "Epoch:17 [25|160] loss:0.041190 acc:1.000000\n",
      "Epoch:17 [26|160] loss:0.012628 acc:1.000000\n",
      "Epoch:17 [27|160] loss:0.011809 acc:1.000000\n",
      "Epoch:17 [28|160] loss:0.014634 acc:1.000000\n",
      "Epoch:17 [29|160] loss:0.016831 acc:1.000000\n",
      "Epoch:17 [30|160] loss:0.010155 acc:1.000000\n",
      "Epoch:17 [31|160] loss:0.006152 acc:1.000000\n",
      "Epoch:17 [32|160] loss:0.021508 acc:1.000000\n",
      "Epoch:17 [33|160] loss:0.231054 acc:0.937500\n",
      "Epoch:17 [34|160] loss:0.043510 acc:1.000000\n",
      "Epoch:17 [35|160] loss:0.087096 acc:0.937500\n",
      "Epoch:17 [36|160] loss:0.017692 acc:1.000000\n",
      "Epoch:17 [37|160] loss:0.019328 acc:1.000000\n",
      "Epoch:17 [38|160] loss:0.008789 acc:1.000000\n",
      "Epoch:17 [39|160] loss:0.008038 acc:1.000000\n",
      "Epoch:17 [40|160] loss:0.015814 acc:1.000000\n",
      "Epoch:17 [41|160] loss:0.015276 acc:1.000000\n",
      "Epoch:17 [42|160] loss:0.013004 acc:1.000000\n",
      "Epoch:17 [43|160] loss:0.135662 acc:0.937500\n",
      "Epoch:17 [44|160] loss:0.009345 acc:1.000000\n",
      "Epoch:17 [45|160] loss:0.022124 acc:1.000000\n",
      "Epoch:17 [46|160] loss:0.018735 acc:1.000000\n",
      "Epoch:17 [47|160] loss:0.033677 acc:1.000000\n",
      "Epoch:17 [48|160] loss:0.012229 acc:1.000000\n",
      "Epoch:17 [49|160] loss:0.006544 acc:1.000000\n",
      "Epoch:17 [50|160] loss:0.011874 acc:1.000000\n",
      "Epoch:17 [51|160] loss:0.102957 acc:0.937500\n",
      "Epoch:17 [52|160] loss:0.010515 acc:1.000000\n",
      "Epoch:17 [53|160] loss:0.012241 acc:1.000000\n",
      "Epoch:17 [54|160] loss:0.006002 acc:1.000000\n",
      "Epoch:17 [55|160] loss:0.006089 acc:1.000000\n",
      "Epoch:17 [56|160] loss:0.007550 acc:1.000000\n",
      "Epoch:17 [57|160] loss:0.023287 acc:1.000000\n",
      "Epoch:17 [58|160] loss:0.021079 acc:1.000000\n",
      "Epoch:17 [59|160] loss:0.009501 acc:1.000000\n",
      "Epoch:17 [60|160] loss:0.005485 acc:1.000000\n",
      "Epoch:17 [61|160] loss:0.131134 acc:0.937500\n",
      "Epoch:17 [62|160] loss:0.013732 acc:1.000000\n",
      "Epoch:17 [63|160] loss:0.101064 acc:0.937500\n",
      "Epoch:17 [64|160] loss:0.012039 acc:1.000000\n",
      "Epoch:17 [65|160] loss:0.014903 acc:1.000000\n",
      "Epoch:17 [66|160] loss:0.029879 acc:1.000000\n",
      "Epoch:17 [67|160] loss:0.016267 acc:1.000000\n",
      "Epoch:17 [68|160] loss:0.008849 acc:1.000000\n",
      "Epoch:17 [69|160] loss:0.033192 acc:1.000000\n",
      "Epoch:17 [70|160] loss:0.016066 acc:1.000000\n",
      "Epoch:17 [71|160] loss:0.013040 acc:1.000000\n",
      "Epoch:17 [72|160] loss:0.095305 acc:0.937500\n",
      "Epoch:17 [73|160] loss:0.015605 acc:1.000000\n",
      "Epoch:17 [74|160] loss:0.071752 acc:0.937500\n",
      "Epoch:17 [75|160] loss:0.018845 acc:1.000000\n",
      "Epoch:17 [76|160] loss:0.111772 acc:0.937500\n",
      "Epoch:17 [77|160] loss:0.007256 acc:1.000000\n",
      "Epoch:17 [78|160] loss:0.014738 acc:1.000000\n",
      "Epoch:17 [79|160] loss:0.008010 acc:1.000000\n",
      "Epoch:17 [80|160] loss:0.028221 acc:1.000000\n",
      "Epoch:17 [81|160] loss:0.008708 acc:1.000000\n",
      "Epoch:17 [82|160] loss:0.021977 acc:1.000000\n",
      "Epoch:17 [83|160] loss:0.029461 acc:1.000000\n",
      "Epoch:17 [84|160] loss:0.009331 acc:1.000000\n",
      "Epoch:17 [85|160] loss:0.021046 acc:1.000000\n",
      "Epoch:17 [86|160] loss:0.106228 acc:0.937500\n",
      "Epoch:17 [87|160] loss:0.032198 acc:1.000000\n",
      "Epoch:17 [88|160] loss:0.006061 acc:1.000000\n",
      "Epoch:17 [89|160] loss:0.143657 acc:0.937500\n",
      "Epoch:17 [90|160] loss:0.024183 acc:1.000000\n",
      "Epoch:17 [91|160] loss:0.008695 acc:1.000000\n",
      "Epoch:17 [92|160] loss:0.012525 acc:1.000000\n",
      "Epoch:17 [93|160] loss:0.319690 acc:0.875000\n",
      "Epoch:17 [94|160] loss:0.015805 acc:1.000000\n",
      "Epoch:17 [95|160] loss:0.006308 acc:1.000000\n",
      "Epoch:17 [96|160] loss:0.011557 acc:1.000000\n",
      "Epoch:17 [97|160] loss:0.017627 acc:1.000000\n",
      "Epoch:17 [98|160] loss:0.016778 acc:1.000000\n",
      "Epoch:17 [99|160] loss:0.006730 acc:1.000000\n",
      "Epoch:17 [100|160] loss:0.017095 acc:1.000000\n",
      "Epoch:17 [101|160] loss:0.013669 acc:1.000000\n",
      "Epoch:17 [102|160] loss:0.103871 acc:0.937500\n",
      "Epoch:17 [103|160] loss:0.059971 acc:0.937500\n",
      "Epoch:17 [104|160] loss:0.070959 acc:0.937500\n",
      "Epoch:17 [105|160] loss:0.033158 acc:1.000000\n",
      "Epoch:17 [106|160] loss:0.007727 acc:1.000000\n",
      "Epoch:17 [107|160] loss:0.025509 acc:1.000000\n",
      "Epoch:17 [108|160] loss:0.031780 acc:1.000000\n",
      "Epoch:17 [109|160] loss:0.016577 acc:1.000000\n",
      "Epoch:17 [110|160] loss:0.351966 acc:0.937500\n",
      "Epoch:17 [111|160] loss:0.012653 acc:1.000000\n",
      "Epoch:17 [112|160] loss:0.007355 acc:1.000000\n",
      "Epoch:17 [113|160] loss:0.021873 acc:1.000000\n",
      "Epoch:17 [114|160] loss:0.023690 acc:1.000000\n",
      "Epoch:17 [115|160] loss:0.008999 acc:1.000000\n",
      "Epoch:17 [116|160] loss:0.005748 acc:1.000000\n",
      "Epoch:17 [117|160] loss:0.024403 acc:1.000000\n",
      "Epoch:17 [118|160] loss:0.012219 acc:1.000000\n",
      "Epoch:17 [119|160] loss:0.014546 acc:1.000000\n",
      "Epoch:17 [120|160] loss:0.114772 acc:0.937500\n",
      "Epoch:17 [121|160] loss:0.016707 acc:1.000000\n",
      "Epoch:17 [122|160] loss:0.013058 acc:1.000000\n",
      "Epoch:17 [123|160] loss:0.013512 acc:1.000000\n",
      "Epoch:17 [124|160] loss:0.097915 acc:0.937500\n",
      "Epoch:17 [125|160] loss:0.017237 acc:1.000000\n",
      "Epoch:17 [126|160] loss:0.046136 acc:1.000000\n",
      "Epoch:17 [127|160] loss:0.061008 acc:0.937500\n",
      "Epoch:17 [128|160] loss:0.065390 acc:0.937500\n",
      "Epoch:17 [129|160] loss:0.010721 acc:1.000000\n",
      "Epoch:17 [130|160] loss:0.014958 acc:1.000000\n",
      "Epoch:17 [131|160] loss:0.025617 acc:1.000000\n",
      "Epoch:17 [132|160] loss:0.019860 acc:1.000000\n",
      "Epoch:17 [133|160] loss:0.013560 acc:1.000000\n",
      "Epoch:17 [134|160] loss:0.011059 acc:1.000000\n",
      "Epoch:17 [135|160] loss:0.008644 acc:1.000000\n",
      "Epoch:17 [136|160] loss:0.070801 acc:0.937500\n",
      "Epoch:17 [137|160] loss:0.013651 acc:1.000000\n",
      "Epoch:17 [138|160] loss:0.072417 acc:0.937500\n",
      "Epoch:17 [139|160] loss:0.014111 acc:1.000000\n",
      "Epoch:17 [140|160] loss:0.020600 acc:1.000000\n",
      "Epoch:17 [141|160] loss:0.013452 acc:1.000000\n",
      "Epoch:17 [142|160] loss:0.025182 acc:1.000000\n",
      "Epoch:17 [143|160] loss:0.010028 acc:1.000000\n",
      "Epoch:17 [144|160] loss:0.016125 acc:1.000000\n",
      "Epoch:17 [145|160] loss:0.012830 acc:1.000000\n",
      "Epoch:17 [146|160] loss:0.014731 acc:1.000000\n",
      "Epoch:17 [147|160] loss:0.131575 acc:0.937500\n",
      "Epoch:17 [148|160] loss:0.013882 acc:1.000000\n",
      "Epoch:17 [149|160] loss:0.010255 acc:1.000000\n",
      "Epoch:17 [150|160] loss:0.014161 acc:1.000000\n",
      "Epoch:17 [151|160] loss:0.141739 acc:0.875000\n",
      "Epoch:17 [152|160] loss:0.011242 acc:1.000000\n",
      "Epoch:17 [153|160] loss:0.078662 acc:0.937500\n",
      "Epoch:17 [154|160] loss:0.009380 acc:1.000000\n",
      "Epoch:17 [155|160] loss:0.011122 acc:1.000000\n",
      "Epoch:17 [156|160] loss:0.035025 acc:1.000000\n",
      "Epoch:17 [157|160] loss:0.010889 acc:1.000000\n",
      "Epoch:17 [158|160] loss:0.018711 acc:1.000000\n",
      "Epoch:17 [159|160] loss:0.032856 acc:1.000000\n",
      "\n",
      "Validation Epoch: 17\n",
      "Acc: 0.973396 \n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model = Net(resnet)\n",
    "model = model.to(device)\n",
    "optimizer1 = torch.optim.SGD(model.parameters(), lr = 0.001, momentum = 0.8, weight_decay = 3e-3) # Set training details\n",
    "optimizer2 = optim.Adam(model.parameters(), lr = 1e-4, betas = (0.9, 0.999), eps = 1e-8, weight_decay = 5e-4, amsgrad = True)\n",
    "scheduler = StepLR(optimizer2, step_size = 4, gamma = 0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 14\n",
    "if useNet == 18:\n",
    "    epochs = 24\n",
    "elif useNet == 34:\n",
    "    epochs = 14\n",
    "elif useNet == 50:\n",
    "    epochs = 18\n",
    "\n",
    "pauseTime = 10 # to have a rest, e.g. 10s, 30s, 60s, 0 for no rests\n",
    "assert((type(pauseTime) == int or type(pauseTime) == float) and pauseTime >= 0)\n",
    "results_x = [epoch for epoch in range(epochs)]\n",
    "startTime = datetime.datetime.now()\n",
    "results_y = []\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    results_y.append(val(epoch))\n",
    "    if epoch != epochs - 1:\n",
    "        sleep(pauseTime)\n",
    "endTime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_acc: 97.80907668231612%, epoch: 4, time: 454.701217s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\program files\\python36\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Acc of ResNet\" + str(useNet))\n",
    "plt.plot(results_x, results_y, color = plt_color)\n",
    "plt.show()\n",
    "with open(rootPath + \"data.txt\", \"a\", encoding = \"utf-8\") as f:\n",
    "    f.write(str({useNet:[results_x, results_y]}) + \"\\n\")\n",
    "print(\"max_acc: {0}%, epoch: {1}, time: {2:.6f}s\".format(max(results_y) * 100, results_y.index(max(results_y)),\\\n",
    "    ((endTime - startTime).total_seconds() - pauseTime * epochs) * (results_y.index(max(results_y)) + 1) / (epochs - 1)))\n",
    "torch.save(model, 'modelcatdog.pth') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('modelcatdog.pth') # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (resnet_layer): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (Linear_layer): Linear(in_features=2048, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = torch.load('modelcatdog.pth')\n",
    "else:\n",
    "    model = torch.load('modelcatdog.pth', map_location = 'cpu')\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average maximum accuracy: 96.25 %\n"
     ]
    }
   ],
   "source": [
    "# verification\n",
    "class_correct = list(0. for i in range(class_count))\n",
    "class_total = list(0. for i in range(class_count))\n",
    "class_rate = list(0. for i in range(class_count))\n",
    "F1_rate = list(0. for i in range(class_count))\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(class_count):\n",
    "            label = labels[i]\n",
    "            try:\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            except IndexError:\n",
    "                pass\n",
    "        #print(class_correct, class_total)\n",
    "\n",
    "for i in range(class_count):\n",
    "    if class_total[i] == 0:\n",
    "        if sum(class_total) == 0:\n",
    "            print(\"This model is not available on the questions you are trying to solve.\")\n",
    "        else:\n",
    "            print(\"Average maximum accuracy: %.2f %%\" % (100 * sum(class_correct) / sum(class_total)))\n",
    "        break\n",
    "else: # naturally break\n",
    "    for i in range(class_count):\n",
    "        print(\"Number of correct:\", class_correct[i], \"Number of total:\", class_total[i])\n",
    "        class_rate[i] = class_correct[i] / class_total[i]\n",
    "        print(\"Accuracy of %5s : %.2f %%\" % (classes[i], class_rate[i] * 100))\n",
    "        F1_rate[i] = 1 / class_rate[i]\n",
    "    print(\"F1 Score: %.2f %%\" % (class_count / sum(F1_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
